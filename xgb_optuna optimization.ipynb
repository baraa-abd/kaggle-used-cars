{"cells":[{"cellId":"0cd5dffb1c2e426486f455a5017a0680","cell_type":"code","metadata":{"source_hash":"ba6a0eeb","execution_start":1727382059878,"execution_millis":7864,"execution_context_id":"8355a963-0fdd-46c0-8b7b-84608fc2838b","deepnote_to_be_reexecuted":false,"cell_id":"0cd5dffb1c2e426486f455a5017a0680","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler,LabelEncoder\nimport optuna\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\n\ncat_types = [\"model\", \"brand\", \"ext_col\", \"int_col\", \"accident\", \n             \"clean_title\", \"body_style\",\n             'engine','fuel_type']\ndf = pd.read_csv('cars_train_enriched_acc_noassumption.csv')\ndf['miles_per_year'] = df['milage']\ndf['miles_per_year'] = df.apply(lambda x: x['miles_per_year'] / x['age'] if x['age']>0 else 0, axis=1)\ndf = df.astype({col: \"category\" for col in cat_types})","block_group":"290985a9439a461a9fc0dcab77558cb0","execution_count":2,"outputs":[{"name":"stderr","text":"/shared-libs/python3.11/py/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/90b1cac8-dfc7-446b-9a1e-b2ccc5966048","content_dependencies":null},{"cellId":"69441ae47059479cafc96d96a60310df","cell_type":"code","metadata":{"source_hash":"f804c160","execution_start":1727376703689,"execution_millis":26,"execution_context_id":"5f75d612-7b5f-42ab-b178-48f19d47eef9","cell_id":"69441ae47059479cafc96d96a60310df","deepnote_cell_type":"code"},"source":"df","block_group":"77bd46dc40df4ae09c786de6259e73f6","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":15,"row_count":188533,"columns":[{"name":"brand","dtype":"category"},{"name":"model","dtype":"category"},{"name":"model_year","dtype":"int64"},{"name":"fuel_type","dtype":"category"},{"name":"engine","dtype":"category"},{"name":"ext_col","dtype":"category"},{"name":"int_col","dtype":"category"},{"name":"accident","dtype":"category"},{"name":"clean_title","dtype":"category"},{"name":"price","dtype":"int64"},{"name":"body_style","dtype":"category"},{"name":"age","dtype":"int64"},{"name":"reliability","dtype":"float64"},{"name":"adjusted_msrp","dtype":"float64"},{"name":"miles_per_year","dtype":"float64"},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"brand":"mini","model":"coopersbase","model_year":2007,"fuel_type":"gasoline","engine":"1720hp16l4cylinderenginegasolinefuel","ext_col":"yellow","int_col":"gray","accident":"nonereported","clean_title":"yes","price":4200,"body_style":"hatchback","age":17,"reliability":0.2153597883952331,"adjusted_msrp":38563.52569132368,"miles_per_year":12529.411764705883,"_deepnote_index_column":0},{"brand":"lincoln","model":"lsv8","model_year":2002,"fuel_type":"gasoline","engine":"2520hp39l8cylinderenginegasolinefuel","ext_col":"silver","int_col":"beige","accident":"atleast1accidentordamagereported","clean_title":"yes","price":4999,"body_style":"sedan","age":22,"reliability":-0.4329579299432494,"adjusted_msrp":65723.56690690854,"miles_per_year":6511.363636363636,"_deepnote_index_column":1},{"brand":"chevrolet","model":"silverado2500lt","model_year":2002,"fuel_type":"e85flexfuel","engine":"3200hp53l8cylinderengineflexfuelcapability","ext_col":"blue","int_col":"gray","accident":"nonereported","clean_title":"yes","price":13900,"body_style":"truck","age":22,"reliability":0.4614811374320764,"adjusted_msrp":47927.80877476637,"miles_per_year":6215.045454545455,"_deepnote_index_column":2},{"brand":"genesis","model":"g9050ultimate","model_year":2017,"fuel_type":"gasoline","engine":"4200hp50l8cylinderenginegasolinefuel","ext_col":"black","int_col":"black","accident":"nonereported","clean_title":"yes","price":45000,"body_style":"sedan","age":7,"reliability":0.7811585101759647,"adjusted_msrp":87971.24899436846,"miles_per_year":2785.714285714286,"_deepnote_index_column":3},{"brand":"mercedesbenz","model":"metrisbase","model_year":2021,"fuel_type":"gasoline","engine":"2080hp20l4cylinderenginegasolinefuel","ext_col":"black","int_col":"beige","accident":"nonereported","clean_title":"yes","price":97500,"body_style":"cargovan","age":3,"reliability":-0.4695514853626108,"adjusted_msrp":36466.51753875263,"miles_per_year":2462.6666666666665,"_deepnote_index_column":4},{"brand":"audi","model":"a620tsport","model_year":2018,"fuel_type":"gasoline","engine":"2520hp20l4cylinderenginegasolinefuel","ext_col":"white","int_col":"unknown","accident":"nonereported","clean_title":"yes","price":29950,"body_style":"sedan","age":6,"reliability":-0.9333619154247376,"adjusted_msrp":70044.20612649385,"miles_per_year":6825,"_deepnote_index_column":5},{"brand":"audi","model":"a8l30t","model_year":2016,"fuel_type":"gasoline","engine":"3330hp30lv6cylinderenginegasolinefuel","ext_col":"black","int_col":"black","accident":"nonereported","clean_title":"yes","price":28500,"body_style":"sedan","age":8,"reliability":-0.9333619154247376,"adjusted_msrp":116470.76802990776,"miles_per_year":7775,"_deepnote_index_column":6},{"brand":"chevrolet","model":"silverado15001lz","model_year":2016,"fuel_type":"e85flexfuel","engine":"3550hp53l8cylinderengineflexfuelcapability","ext_col":"white","int_col":"gray","accident":"nonereported","clean_title":"yes","price":12500,"body_style":"truck","age":8,"reliability":0.4614811374320764,"adjusted_msrp":52247.894644947926,"miles_per_year":12825.5,"_deepnote_index_column":7},{"brand":"ford","model":"f150xlt","model_year":2020,"fuel_type":"gasoline","engine":"27lv624vpdidohctwinturbo","ext_col":"white","int_col":"black","accident":"nonereported","clean_title":"yes","price":62890,"body_style":"truck","age":4,"reliability":-0.5208584362627138,"adjusted_msrp":49455.45421643141,"miles_per_year":9588,"_deepnote_index_column":8},{"brand":"bmw","model":"m4base","model_year":2015,"fuel_type":"gasoline","engine":"4250hp30lstraight6cylinderenginegasolinefuel","ext_col":"black","int_col":"blue","accident":"nonereported","clean_title":"yes","price":4000,"body_style":"coupe","age":9,"reliability":0.2578044523867858,"adjusted_msrp":94432.73774856476,"miles_per_year":8316.666666666666,"_deepnote_index_column":9}]},"text/plain":"               brand                model  model_year    fuel_type  \\\n0               mini          coopersbase        2007     gasoline   \n1            lincoln                 lsv8        2002     gasoline   \n2          chevrolet      silverado2500lt        2002  e85flexfuel   \n3            genesis        g9050ultimate        2017     gasoline   \n4       mercedesbenz           metrisbase        2021     gasoline   \n...              ...                  ...         ...          ...   \n188528      cadillac  escaladeesvplatinum        2017     gasoline   \n188529  mercedesbenz   amgc43amgc434matic        2018     gasoline   \n188530  mercedesbenz   amgglc63base4matic        2021     gasoline   \n188531          audi        s530tprestige        2022     gasoline   \n188532       porsche            macanbase        2016     gasoline   \n\n                                            engine ext_col int_col  \\\n0             1720hp16l4cylinderenginegasolinefuel  yellow    gray   \n1             2520hp39l8cylinderenginegasolinefuel  silver   beige   \n2       3200hp53l8cylinderengineflexfuelcapability    blue    gray   \n3             4200hp50l8cylinderenginegasolinefuel   black   black   \n4             2080hp20l4cylinderenginegasolinefuel   black   beige   \n...                                            ...     ...     ...   \n188528        4200hp62l8cylinderenginegasolinefuel   white   beige   \n188529       3850hp30lv6cylinderenginegasolinefuel   white   black   \n188530        4690hp40l8cylinderenginegasolinefuel   white   black   \n188531                                         30l   white   black   \n188532        2520hp20l4cylinderenginegasolinefuel   white   black   \n\n                                accident clean_title  price body_style  age  \\\n0                           nonereported         yes   4200  hatchback   17   \n1       atleast1accidentordamagereported         yes   4999      sedan   22   \n2                           nonereported         yes  13900      truck   22   \n3                           nonereported         yes  45000      sedan    7   \n4                           nonereported         yes  97500   cargovan    3   \n...                                  ...         ...    ...        ...  ...   \n188528                      nonereported         yes  27500        suv    7   \n188529  atleast1accidentordamagereported         yes  30000      sedan    6   \n188530                      nonereported         yes  86900        suv    3   \n188531                      nonereported          no  84900      coupe    2   \n188532                      nonereported         yes  28995        suv    8   \n\n        reliability  adjusted_msrp  miles_per_year  \n0          0.215360   38563.525691    12529.411765  \n1         -0.432958   65723.566907     6511.363636  \n2          0.461481   47927.808775     6215.045455  \n3          0.781159   87971.248994     2785.714286  \n4         -0.469551   36466.517539     2462.666667  \n...             ...            ...             ...  \n188528     0.105448  106920.384453     7000.000000  \n188529    -0.469551   66911.638768     4766.666667  \n188530    -0.469551   87535.906230     4550.000000  \n188531    -0.933362   65937.618342     6947.500000  \n188532     0.566201   61514.403385     7437.500000  \n\n[188533 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brand</th>\n      <th>model</th>\n      <th>model_year</th>\n      <th>fuel_type</th>\n      <th>engine</th>\n      <th>ext_col</th>\n      <th>int_col</th>\n      <th>accident</th>\n      <th>clean_title</th>\n      <th>price</th>\n      <th>body_style</th>\n      <th>age</th>\n      <th>reliability</th>\n      <th>adjusted_msrp</th>\n      <th>miles_per_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mini</td>\n      <td>coopersbase</td>\n      <td>2007</td>\n      <td>gasoline</td>\n      <td>1720hp16l4cylinderenginegasolinefuel</td>\n      <td>yellow</td>\n      <td>gray</td>\n      <td>nonereported</td>\n      <td>yes</td>\n      <td>4200</td>\n      <td>hatchback</td>\n      <td>17</td>\n      <td>0.215360</td>\n      <td>38563.525691</td>\n      <td>12529.411765</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>lincoln</td>\n      <td>lsv8</td>\n      <td>2002</td>\n      <td>gasoline</td>\n      <td>2520hp39l8cylinderenginegasolinefuel</td>\n      <td>silver</td>\n      <td>beige</td>\n      <td>atleast1accidentordamagereported</td>\n      <td>yes</td>\n      <td>4999</td>\n      <td>sedan</td>\n      <td>22</td>\n      <td>-0.432958</td>\n      <td>65723.566907</td>\n      <td>6511.363636</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>chevrolet</td>\n      <td>silverado2500lt</td>\n      <td>2002</td>\n      <td>e85flexfuel</td>\n      <td>3200hp53l8cylinderengineflexfuelcapability</td>\n      <td>blue</td>\n      <td>gray</td>\n      <td>nonereported</td>\n      <td>yes</td>\n      <td>13900</td>\n      <td>truck</td>\n      <td>22</td>\n      <td>0.461481</td>\n      <td>47927.808775</td>\n      <td>6215.045455</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>genesis</td>\n      <td>g9050ultimate</td>\n      <td>2017</td>\n      <td>gasoline</td>\n      <td>4200hp50l8cylinderenginegasolinefuel</td>\n      <td>black</td>\n      <td>black</td>\n      <td>nonereported</td>\n      <td>yes</td>\n      <td>45000</td>\n      <td>sedan</td>\n      <td>7</td>\n      <td>0.781159</td>\n      <td>87971.248994</td>\n      <td>2785.714286</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mercedesbenz</td>\n      <td>metrisbase</td>\n      <td>2021</td>\n      <td>gasoline</td>\n      <td>2080hp20l4cylinderenginegasolinefuel</td>\n      <td>black</td>\n      <td>beige</td>\n      <td>nonereported</td>\n      <td>yes</td>\n      <td>97500</td>\n      <td>cargovan</td>\n      <td>3</td>\n      <td>-0.469551</td>\n      <td>36466.517539</td>\n      <td>2462.666667</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>188528</th>\n      <td>cadillac</td>\n      <td>escaladeesvplatinum</td>\n      <td>2017</td>\n      <td>gasoline</td>\n      <td>4200hp62l8cylinderenginegasolinefuel</td>\n      <td>white</td>\n      <td>beige</td>\n      <td>nonereported</td>\n      <td>yes</td>\n      <td>27500</td>\n      <td>suv</td>\n      <td>7</td>\n      <td>0.105448</td>\n      <td>106920.384453</td>\n      <td>7000.000000</td>\n    </tr>\n    <tr>\n      <th>188529</th>\n      <td>mercedesbenz</td>\n      <td>amgc43amgc434matic</td>\n      <td>2018</td>\n      <td>gasoline</td>\n      <td>3850hp30lv6cylinderenginegasolinefuel</td>\n      <td>white</td>\n      <td>black</td>\n      <td>atleast1accidentordamagereported</td>\n      <td>yes</td>\n      <td>30000</td>\n      <td>sedan</td>\n      <td>6</td>\n      <td>-0.469551</td>\n      <td>66911.638768</td>\n      <td>4766.666667</td>\n    </tr>\n    <tr>\n      <th>188530</th>\n      <td>mercedesbenz</td>\n      <td>amgglc63base4matic</td>\n      <td>2021</td>\n      <td>gasoline</td>\n      <td>4690hp40l8cylinderenginegasolinefuel</td>\n      <td>white</td>\n      <td>black</td>\n      <td>nonereported</td>\n      <td>yes</td>\n      <td>86900</td>\n      <td>suv</td>\n      <td>3</td>\n      <td>-0.469551</td>\n      <td>87535.906230</td>\n      <td>4550.000000</td>\n    </tr>\n    <tr>\n      <th>188531</th>\n      <td>audi</td>\n      <td>s530tprestige</td>\n      <td>2022</td>\n      <td>gasoline</td>\n      <td>30l</td>\n      <td>white</td>\n      <td>black</td>\n      <td>nonereported</td>\n      <td>no</td>\n      <td>84900</td>\n      <td>coupe</td>\n      <td>2</td>\n      <td>-0.933362</td>\n      <td>65937.618342</td>\n      <td>6947.500000</td>\n    </tr>\n    <tr>\n      <th>188532</th>\n      <td>porsche</td>\n      <td>macanbase</td>\n      <td>2016</td>\n      <td>gasoline</td>\n      <td>2520hp20l4cylinderenginegasolinefuel</td>\n      <td>white</td>\n      <td>black</td>\n      <td>nonereported</td>\n      <td>yes</td>\n      <td>28995</td>\n      <td>suv</td>\n      <td>8</td>\n      <td>0.566201</td>\n      <td>61514.403385</td>\n      <td>7437.500000</td>\n    </tr>\n  </tbody>\n</table>\n<p>188533 rows × 15 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/ae710bea-86c5-4636-88d9-f7f661b0c0f8","content_dependencies":null},{"cellId":"318909406b3c4618ba5dd88670e93f6f","cell_type":"code","metadata":{"source_hash":"b7be3bb1","execution_start":1727376915749,"execution_millis":374139,"execution_context_id":"5f75d612-7b5f-42ab-b178-48f19d47eef9","deepnote_to_be_reexecuted":false,"cell_id":"318909406b3c4618ba5dd88670e93f6f","deepnote_cell_type":"code"},"source":"import xgboost as xgb\n\ny = df['price']\nX = df.drop(['price'], axis=1)\nfeature_importances = []\nthreshold_opt_cats = [\"model\", \"ext_col\", \"accident\", \n             \"clean_title\", \"body_style\",\n             'engine','fuel_type']\ndef objective(trial):\n    # Suggest hyperparameters for tuning\n    params = {\n        'objective': 'reg:squarederror',\n        'eval_metric': 'rmse',\n        'booster': 'gbtree',\n        'n_estimators': trial.suggest_int('n_estimators', 50, 1200),\n        'eta':0.3, #trial.suggest_float('eta', 0.0001, 0.5, log = True),  # learning rate\n        'max_depth': 7, #trial.suggest_int('max_depth', 3, 8),\n        'min_child_weight': trial.suggest_float('min_child_weight', 1e-4, 10, log = True),\n        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.05, 1.0),\n        'lambda': trial.suggest_float('lambda', 0.1, 50, log = True),\n        'alpha': trial.suggest_float('alpha', 1e-4, 10, log = True),\n        'tree_method': 'hist',  \n        'device':'cuda'\n    }\n    threshold = {cat:trial.suggest_int(f'{cat}_threshold', 1, 1000) for cat in cat_types}\n    threshold['brand'] = 1\n    threshold['int_col'] = 1\n    \n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=1219)\n    \n\n    for cat in cat_types:\n        value_counts = X_train[cat].value_counts().to_dict()\n        X_train[cat] = X_train[cat].apply(lambda x: x if value_counts[x] > threshold[cat] else \"unknown\")\n        X_valid[cat] = X_valid[cat].apply(lambda x: x if (x in value_counts) and (value_counts[x] > threshold[cat]) else \"unknown\")\n\n    X_train = X_train.astype({col: \"category\" for col in cat_types})\n    X_valid = X_valid.astype({col: \"category\" for col in cat_types})\n    \n    dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n    dvalid = xgb.DMatrix(X_valid, label=y_valid, enable_categorical=True)\n    \n    # Train the model\n    model = xgb.train(params, dtrain, evals=[(dvalid, 'validation')], num_boost_round=1500, early_stopping_rounds=35, verbose_eval=False)\n    feature_importances.append(model.get_score(importance_type='gain'))  # get feature importance\n    # Predict on the validation set\n    y_pred_valid = model.predict(dvalid)\n    \n    # Calculate RMSE on the validation set\n    rmse = mean_squared_error(y_valid, y_pred_valid, squared=False)\n    \n    return rmse\n\n\n\nstudy = optuna.create_study(sampler = optuna.samplers.GPSampler(), direction='minimize')\nstudy.optimize(objective, n_trials=50)\n\n\nbest_params = study.best_params\nprint(f\"Best hyperparameters: {best_params}\")\n\nprint(\"Parameter importance:\\n\", optuna.importance.get_param_importances(study))\n","block_group":"186256ca1e2b41b7a681121ad674df6c","execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_82/943196115.py:57: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n  study = optuna.create_study(sampler = optuna.samplers.GPSampler(), direction='minimize')\n[I 2024-09-26 18:55:17,720] A new study created in memory with name: no-name-57760fa9-6131-4b83-9176-b4c04a7856ae\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:17] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:17] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:17] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:18,882] Trial 0 finished with value: 83323.4427389309 and parameters: {'n_estimators': 1188, 'min_child_weight': 2.063692996459721, 'subsample': 0.32836061630749247, 'colsample_bytree': 0.7487972365209301, 'lambda': 8.383793665032995, 'alpha': 0.00022390733975486123, 'model_threshold': 435, 'brand_threshold': 119, 'ext_col_threshold': 366, 'int_col_threshold': 626, 'accident_threshold': 85, 'clean_title_threshold': 582, 'body_style_threshold': 461, 'engine_threshold': 196, 'fuel_type_threshold': 790}. Best is trial 0 with value: 83323.4427389309.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:19] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:19] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:19] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:20,024] Trial 1 finished with value: 82091.09269780238 and parameters: {'n_estimators': 1027, 'min_child_weight': 0.0007844250010755278, 'subsample': 0.557808307510446, 'colsample_bytree': 0.6919800036792996, 'lambda': 30.829838151909424, 'alpha': 0.00037360084340778933, 'model_threshold': 662, 'brand_threshold': 376, 'ext_col_threshold': 510, 'int_col_threshold': 652, 'accident_threshold': 107, 'clean_title_threshold': 526, 'body_style_threshold': 656, 'engine_threshold': 326, 'fuel_type_threshold': 68}. Best is trial 1 with value: 82091.09269780238.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:20] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:20] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:20] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:22,081] Trial 2 finished with value: 81376.09867223298 and parameters: {'n_estimators': 625, 'min_child_weight': 0.00015364419410319975, 'subsample': 0.8834674950293389, 'colsample_bytree': 0.1899247160503333, 'lambda': 8.625307502821968, 'alpha': 0.062070253984589235, 'model_threshold': 943, 'brand_threshold': 182, 'ext_col_threshold': 751, 'int_col_threshold': 546, 'accident_threshold': 935, 'clean_title_threshold': 925, 'body_style_threshold': 470, 'engine_threshold': 217, 'fuel_type_threshold': 523}. Best is trial 2 with value: 81376.09867223298.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:22] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:22] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:22] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:23,356] Trial 3 finished with value: 82270.57022605416 and parameters: {'n_estimators': 994, 'min_child_weight': 0.7618275691498081, 'subsample': 0.6417153271670021, 'colsample_bytree': 0.30863095977160665, 'lambda': 11.461780397831879, 'alpha': 0.04447548959960756, 'model_threshold': 16, 'brand_threshold': 469, 'ext_col_threshold': 474, 'int_col_threshold': 944, 'accident_threshold': 648, 'clean_title_threshold': 229, 'body_style_threshold': 77, 'engine_threshold': 494, 'fuel_type_threshold': 45}. Best is trial 2 with value: 81376.09867223298.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:23] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:23] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:23] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:24,753] Trial 4 finished with value: 82014.59890801481 and parameters: {'n_estimators': 136, 'min_child_weight': 8.7010658734934, 'subsample': 0.4833753838133815, 'colsample_bytree': 0.26945422706429656, 'lambda': 0.492908853020772, 'alpha': 2.07080919772611, 'model_threshold': 161, 'brand_threshold': 525, 'ext_col_threshold': 579, 'int_col_threshold': 235, 'accident_threshold': 350, 'clean_title_threshold': 382, 'body_style_threshold': 360, 'engine_threshold': 274, 'fuel_type_threshold': 889}. Best is trial 2 with value: 81376.09867223298.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:24] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:24] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:24] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:25,850] Trial 5 finished with value: 82022.32812502072 and parameters: {'n_estimators': 1179, 'min_child_weight': 9.993492954084658, 'subsample': 0.8805272889387079, 'colsample_bytree': 0.7334436963278878, 'lambda': 4.7674134760989935, 'alpha': 0.06894397964718531, 'model_threshold': 861, 'brand_threshold': 293, 'ext_col_threshold': 670, 'int_col_threshold': 706, 'accident_threshold': 408, 'clean_title_threshold': 772, 'body_style_threshold': 177, 'engine_threshold': 130, 'fuel_type_threshold': 818}. Best is trial 2 with value: 81376.09867223298.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:25] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:25] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:25] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:26,771] Trial 6 finished with value: 85906.53461337129 and parameters: {'n_estimators': 651, 'min_child_weight': 0.0035722943996153427, 'subsample': 0.7321789518907751, 'colsample_bytree': 0.8305205321402834, 'lambda': 0.14680486189675968, 'alpha': 0.00019119203321317344, 'model_threshold': 789, 'brand_threshold': 289, 'ext_col_threshold': 855, 'int_col_threshold': 748, 'accident_threshold': 763, 'clean_title_threshold': 386, 'body_style_threshold': 686, 'engine_threshold': 899, 'fuel_type_threshold': 376}. Best is trial 2 with value: 81376.09867223298.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:26] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:26] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:26] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:27,853] Trial 7 finished with value: 81827.56673758394 and parameters: {'n_estimators': 929, 'min_child_weight': 7.265068700189479, 'subsample': 0.49391467768248243, 'colsample_bytree': 0.6446403991777337, 'lambda': 31.74450912536286, 'alpha': 2.189179707298641, 'model_threshold': 924, 'brand_threshold': 540, 'ext_col_threshold': 330, 'int_col_threshold': 820, 'accident_threshold': 303, 'clean_title_threshold': 982, 'body_style_threshold': 927, 'engine_threshold': 742, 'fuel_type_threshold': 627}. Best is trial 2 with value: 81376.09867223298.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:27] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:27] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:27] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:29,092] Trial 8 finished with value: 81613.46072230661 and parameters: {'n_estimators': 108, 'min_child_weight': 9.155335697574264, 'subsample': 0.614636355537006, 'colsample_bytree': 0.32594244521604654, 'lambda': 5.027459107513931, 'alpha': 1.4525907429649139, 'model_threshold': 605, 'brand_threshold': 261, 'ext_col_threshold': 576, 'int_col_threshold': 284, 'accident_threshold': 807, 'clean_title_threshold': 828, 'body_style_threshold': 11, 'engine_threshold': 631, 'fuel_type_threshold': 505}. Best is trial 2 with value: 81376.09867223298.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:29] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:29] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:29] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:30,229] Trial 9 finished with value: 82841.20094618679 and parameters: {'n_estimators': 308, 'min_child_weight': 4.043129951151901, 'subsample': 0.8449866713345443, 'colsample_bytree': 0.8280782889802815, 'lambda': 7.007206487847021, 'alpha': 2.211384818479306, 'model_threshold': 86, 'brand_threshold': 248, 'ext_col_threshold': 693, 'int_col_threshold': 507, 'accident_threshold': 848, 'clean_title_threshold': 335, 'body_style_threshold': 904, 'engine_threshold': 348, 'fuel_type_threshold': 724}. Best is trial 2 with value: 81376.09867223298.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:33] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:33] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:33] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:35,463] Trial 10 finished with value: 81243.64550648116 and parameters: {'n_estimators': 714, 'min_child_weight': 0.017468530281165625, 'subsample': 0.8157798199694365, 'colsample_bytree': 0.17010284275939158, 'lambda': 27.70204838973703, 'alpha': 1.263475041636143, 'model_threshold': 987, 'brand_threshold': 422, 'ext_col_threshold': 605, 'int_col_threshold': 474, 'accident_threshold': 502, 'clean_title_threshold': 1000, 'body_style_threshold': 176, 'engine_threshold': 130, 'fuel_type_threshold': 453}. Best is trial 10 with value: 81243.64550648116.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:41] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:41] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:41] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:43,186] Trial 11 finished with value: 83060.63618977243 and parameters: {'n_estimators': 623, 'min_child_weight': 0.08719673812333491, 'subsample': 0.8830805598044267, 'colsample_bytree': 0.05, 'lambda': 6.76563037997296, 'alpha': 9.999999999999993, 'model_threshold': 947, 'brand_threshold': 186, 'ext_col_threshold': 643, 'int_col_threshold': 518, 'accident_threshold': 1000, 'clean_title_threshold': 1000, 'body_style_threshold': 42, 'engine_threshold': 17, 'fuel_type_threshold': 1000}. Best is trial 10 with value: 81243.64550648116.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:46] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:46] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:46] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:47,664] Trial 12 finished with value: 81303.94161551654 and parameters: {'n_estimators': 614, 'min_child_weight': 0.0015896086427764696, 'subsample': 0.7643169667455522, 'colsample_bytree': 0.25516739885230844, 'lambda': 49.68603554947085, 'alpha': 0.08583886467031442, 'model_threshold': 968, 'brand_threshold': 360, 'ext_col_threshold': 627, 'int_col_threshold': 411, 'accident_threshold': 485, 'clean_title_threshold': 1000, 'body_style_threshold': 365, 'engine_threshold': 289, 'fuel_type_threshold': 177}. Best is trial 10 with value: 81243.64550648116.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:54] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:54] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:55:54] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:55:56,007] Trial 13 finished with value: 82233.04932909265 and parameters: {'n_estimators': 1199, 'min_child_weight': 0.00011320079665581113, 'subsample': 0.9928813831416213, 'colsample_bytree': 0.27887055888404727, 'lambda': 23.815545239207808, 'alpha': 0.22866410187528324, 'model_threshold': 1000, 'brand_threshold': 612, 'ext_col_threshold': 719, 'int_col_threshold': 773, 'accident_threshold': 315, 'clean_title_threshold': 1000, 'body_style_threshold': 480, 'engine_threshold': 1, 'fuel_type_threshold': 302}. Best is trial 10 with value: 81243.64550648116.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:02] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:02] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:02] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:56:04,745] Trial 14 finished with value: 81361.66253288437 and parameters: {'n_estimators': 262, 'min_child_weight': 0.026744999287765747, 'subsample': 0.5953419629489716, 'colsample_bytree': 0.06813881317410604, 'lambda': 28.769674632375917, 'alpha': 0.19821961865053248, 'model_threshold': 1000, 'brand_threshold': 244, 'ext_col_threshold': 536, 'int_col_threshold': 217, 'accident_threshold': 629, 'clean_title_threshold': 900, 'body_style_threshold': 268, 'engine_threshold': 321, 'fuel_type_threshold': 372}. Best is trial 10 with value: 81243.64550648116.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:12] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:12] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:12] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:56:13,475] Trial 15 finished with value: 81417.00982397787 and parameters: {'n_estimators': 655, 'min_child_weight': 0.13422866612684575, 'subsample': 0.8982634942766012, 'colsample_bytree': 0.4408148413227691, 'lambda': 49.99999999999999, 'alpha': 0.4544004794155024, 'model_threshold': 1000, 'brand_threshold': 166, 'ext_col_threshold': 667, 'int_col_threshold': 404, 'accident_threshold': 729, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 413, 'fuel_type_threshold': 321}. Best is trial 10 with value: 81243.64550648116.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:19] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:19] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:19] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:56:20,973] Trial 16 finished with value: 81356.36612273313 and parameters: {'n_estimators': 375, 'min_child_weight': 2.0650886514158038, 'subsample': 0.5905747718967826, 'colsample_bytree': 0.25575210252157404, 'lambda': 18.74968018763622, 'alpha': 2.3846467054870164, 'model_threshold': 666, 'brand_threshold': 676, 'ext_col_threshold': 524, 'int_col_threshold': 224, 'accident_threshold': 38, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 366, 'fuel_type_threshold': 253}. Best is trial 10 with value: 81243.64550648116.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:34] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:34] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:34] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:56:36,816] Trial 17 finished with value: 81362.53520506273 and parameters: {'n_estimators': 220, 'min_child_weight': 0.00010000000000000009, 'subsample': 0.6631515675145382, 'colsample_bytree': 0.11228573003649464, 'lambda': 32.538318599532644, 'alpha': 0.33017659720718406, 'model_threshold': 509, 'brand_threshold': 505, 'ext_col_threshold': 701, 'int_col_threshold': 510, 'accident_threshold': 697, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 316, 'fuel_type_threshold': 338}. Best is trial 10 with value: 81243.64550648116.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:58] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:58] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:56:58] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:56:59,936] Trial 18 finished with value: 81386.20744828097 and parameters: {'n_estimators': 634, 'min_child_weight': 0.0004022052825952996, 'subsample': 0.6334576628591062, 'colsample_bytree': 0.23728377546294144, 'lambda': 10.085089141667373, 'alpha': 0.7509464579115392, 'model_threshold': 810, 'brand_threshold': 182, 'ext_col_threshold': 175, 'int_col_threshold': 244, 'accident_threshold': 609, 'clean_title_threshold': 1000, 'body_style_threshold': 5, 'engine_threshold': 91, 'fuel_type_threshold': 182}. Best is trial 10 with value: 81243.64550648116.\n[W 2024-09-26 18:57:06,475] local_search_mixed: Local search did not converge.\n[W 2024-09-26 18:57:12,352] local_search_mixed: Local search did not converge.\n[W 2024-09-26 18:57:23,676] local_search_mixed: Local search did not converge.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:57:25] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:57:25] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:57:25] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:57:28,153] Trial 19 finished with value: 81153.16102522673 and parameters: {'n_estimators': 332, 'min_child_weight': 2.271920130865519, 'subsample': 0.9859554278782161, 'colsample_bytree': 0.10236948797613452, 'lambda': 25.116087840591984, 'alpha': 0.12085926946810567, 'model_threshold': 963, 'brand_threshold': 689, 'ext_col_threshold': 88, 'int_col_threshold': 421, 'accident_threshold': 607, 'clean_title_threshold': 1000, 'body_style_threshold': 4, 'engine_threshold': 145, 'fuel_type_threshold': 332}. Best is trial 19 with value: 81153.16102522673.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:57:42] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:57:42] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:57:42] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:57:43,893] Trial 20 finished with value: 82510.6896631628 and parameters: {'n_estimators': 80, 'min_child_weight': 9.999999999999993, 'subsample': 0.8420485340725843, 'colsample_bytree': 0.05459002748306739, 'lambda': 33.111255539004496, 'alpha': 0.2876721169486455, 'model_threshold': 1000, 'brand_threshold': 25, 'ext_col_threshold': 221, 'int_col_threshold': 790, 'accident_threshold': 115, 'clean_title_threshold': 1000, 'body_style_threshold': 92, 'engine_threshold': 1, 'fuel_type_threshold': 217}. Best is trial 19 with value: 81153.16102522673.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:57:47] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:57:47] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:57:47] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:57:49,470] Trial 21 finished with value: 81350.34287304127 and parameters: {'n_estimators': 848, 'min_child_weight': 0.014894479596914183, 'subsample': 0.8314388420345658, 'colsample_bytree': 0.17535780496231257, 'lambda': 22.21293304358247, 'alpha': 0.16970000165403124, 'model_threshold': 923, 'brand_threshold': 902, 'ext_col_threshold': 412, 'int_col_threshold': 237, 'accident_threshold': 792, 'clean_title_threshold': 1000, 'body_style_threshold': 148, 'engine_threshold': 319, 'fuel_type_threshold': 409}. Best is trial 19 with value: 81153.16102522673.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:01] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:01] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:01] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:58:02,286] Trial 22 finished with value: 81942.84870530001 and parameters: {'n_estimators': 50, 'min_child_weight': 0.0004730264532142418, 'subsample': 1.0, 'colsample_bytree': 0.34394833183499757, 'lambda': 19.099378829767698, 'alpha': 0.12199367098090208, 'model_threshold': 1000, 'brand_threshold': 702, 'ext_col_threshold': 498, 'int_col_threshold': 313, 'accident_threshold': 313, 'clean_title_threshold': 1000, 'body_style_threshold': 156, 'engine_threshold': 1, 'fuel_type_threshold': 444}. Best is trial 19 with value: 81153.16102522673.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:07] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:07] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:07] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:58:09,969] Trial 23 finished with value: 81392.72218762946 and parameters: {'n_estimators': 885, 'min_child_weight': 2.4932708080928547, 'subsample': 0.7007659082196109, 'colsample_bytree': 0.05, 'lambda': 28.022531501883567, 'alpha': 0.5463369881741227, 'model_threshold': 845, 'brand_threshold': 570, 'ext_col_threshold': 250, 'int_col_threshold': 182, 'accident_threshold': 842, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 357, 'fuel_type_threshold': 222}. Best is trial 19 with value: 81153.16102522673.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:19] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:19] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:19] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:58:22,351] Trial 24 finished with value: 81349.68412525246 and parameters: {'n_estimators': 451, 'min_child_weight': 0.03419784264395816, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 3.8323821107504505, 'alpha': 2.1832568155398993, 'model_threshold': 1000, 'brand_threshold': 680, 'ext_col_threshold': 219, 'int_col_threshold': 481, 'accident_threshold': 500, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 309, 'fuel_type_threshold': 281}. Best is trial 19 with value: 81153.16102522673.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:27] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:27] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:27] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:58:29,269] Trial 25 finished with value: 81284.84856852258 and parameters: {'n_estimators': 626, 'min_child_weight': 0.32852043719191143, 'subsample': 0.9885593639146747, 'colsample_bytree': 0.24869428090117435, 'lambda': 31.055623973453056, 'alpha': 0.3560031241230773, 'model_threshold': 1000, 'brand_threshold': 593, 'ext_col_threshold': 841, 'int_col_threshold': 73, 'accident_threshold': 787, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 182, 'fuel_type_threshold': 211}. Best is trial 19 with value: 81153.16102522673.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:35] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:35] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:35] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:58:36,659] Trial 26 finished with value: 81374.68533020922 and parameters: {'n_estimators': 597, 'min_child_weight': 0.045016874511105934, 'subsample': 0.5584452807592365, 'colsample_bytree': 0.4999718548324073, 'lambda': 49.99999999999999, 'alpha': 0.6519172601547455, 'model_threshold': 1000, 'brand_threshold': 723, 'ext_col_threshold': 22, 'int_col_threshold': 486, 'accident_threshold': 698, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 212, 'fuel_type_threshold': 333}. Best is trial 19 with value: 81153.16102522673.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:41] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:41] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:41] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:58:43,805] Trial 27 finished with value: 81324.22056647121 and parameters: {'n_estimators': 1200, 'min_child_weight': 9.999999999999993, 'subsample': 0.42964521014738943, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 9.999999999999975, 'model_threshold': 677, 'brand_threshold': 826, 'ext_col_threshold': 1000, 'int_col_threshold': 1, 'accident_threshold': 289, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 528, 'fuel_type_threshold': 433}. Best is trial 19 with value: 81153.16102522673.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:48] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:48] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:48] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:58:50,391] Trial 28 finished with value: 82123.46708256556 and parameters: {'n_estimators': 50, 'min_child_weight': 9.999999999999993, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'model_threshold': 1, 'brand_threshold': 410, 'ext_col_threshold': 1, 'int_col_threshold': 1, 'accident_threshold': 247, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 684, 'fuel_type_threshold': 244}. Best is trial 19 with value: 81153.16102522673.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:59] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:59] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:58:59] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:59:01,609] Trial 29 finished with value: 81350.80090816229 and parameters: {'n_estimators': 1200, 'min_child_weight': 9.999999999999993, 'subsample': 0.43597801000428316, 'colsample_bytree': 0.05, 'lambda': 10.028093583341164, 'alpha': 0.8349697685995735, 'model_threshold': 1000, 'brand_threshold': 691, 'ext_col_threshold': 1000, 'int_col_threshold': 344, 'accident_threshold': 423, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 279, 'fuel_type_threshold': 369}. Best is trial 19 with value: 81153.16102522673.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:07] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:07] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:07] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:59:10,576] Trial 30 finished with value: 81144.21817245235 and parameters: {'n_estimators': 1167, 'min_child_weight': 0.007467366197256593, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 0.2717690924251904, 'model_threshold': 910, 'brand_threshold': 264, 'ext_col_threshold': 208, 'int_col_threshold': 134, 'accident_threshold': 537, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 223, 'fuel_type_threshold': 415}. Best is trial 30 with value: 81144.21817245235.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:15] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:15] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:15] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:59:18,571] Trial 31 finished with value: 81194.81420802335 and parameters: {'n_estimators': 610, 'min_child_weight': 0.00010000000000000009, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 0.00511174028497753, 'model_threshold': 1000, 'brand_threshold': 231, 'ext_col_threshold': 1, 'int_col_threshold': 232, 'accident_threshold': 1000, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 137, 'fuel_type_threshold': 42}. Best is trial 30 with value: 81144.21817245235.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:26] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:26] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:26] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:59:29,292] Trial 32 finished with value: 81413.9787356466 and parameters: {'n_estimators': 50, 'min_child_weight': 9.999999999999975, 'subsample': 0.1, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'model_threshold': 1000, 'brand_threshold': 1000, 'ext_col_threshold': 1000, 'int_col_threshold': 389, 'accident_threshold': 1, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 577, 'fuel_type_threshold': 951}. Best is trial 30 with value: 81144.21817245235.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:35] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:35] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:35] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:59:36,657] Trial 33 finished with value: 81804.22486710857 and parameters: {'n_estimators': 1200, 'min_child_weight': 0.00010000000000000009, 'subsample': 0.1, 'colsample_bytree': 0.36424007230574224, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'model_threshold': 1000, 'brand_threshold': 1, 'ext_col_threshold': 1000, 'int_col_threshold': 1, 'accident_threshold': 1, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 430, 'fuel_type_threshold': 552}. Best is trial 30 with value: 81144.21817245235.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:44] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:44] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:44] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:59:47,127] Trial 34 finished with value: 81152.70331635607 and parameters: {'n_estimators': 544, 'min_child_weight': 0.00021757722946965418, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 0.15437480016475957, 'model_threshold': 1000, 'brand_threshold': 665, 'ext_col_threshold': 296, 'int_col_threshold': 351, 'accident_threshold': 538, 'clean_title_threshold': 815, 'body_style_threshold': 1, 'engine_threshold': 189, 'fuel_type_threshold': 294}. Best is trial 30 with value: 81144.21817245235.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:51] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:51] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:51] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 18:59:54,347] Trial 35 finished with value: 81439.6952997637 and parameters: {'n_estimators': 50, 'min_child_weight': 9.999999999999993, 'subsample': 0.1, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'model_threshold': 1000, 'brand_threshold': 1000, 'ext_col_threshold': 1000, 'int_col_threshold': 1000, 'accident_threshold': 715, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 594, 'fuel_type_threshold': 311}. Best is trial 30 with value: 81144.21817245235.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:58] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:58] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [18:59:58] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:00:01,600] Trial 36 finished with value: 81217.27936351782 and parameters: {'n_estimators': 50, 'min_child_weight': 0.00010000000000000009, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 0.2043109213086133, 'alpha': 0.005736394293449802, 'model_threshold': 1000, 'brand_threshold': 997, 'ext_col_threshold': 1, 'int_col_threshold': 1, 'accident_threshold': 1000, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 180, 'fuel_type_threshold': 1}. Best is trial 30 with value: 81144.21817245235.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:07] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:07] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:07] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:00:09,590] Trial 37 finished with value: 81198.02186544315 and parameters: {'n_estimators': 284, 'min_child_weight': 0.0013737728207820759, 'subsample': 0.8827498957482429, 'colsample_bytree': 0.05, 'lambda': 5.7824341950790314, 'alpha': 0.2142511838656384, 'model_threshold': 997, 'brand_threshold': 725, 'ext_col_threshold': 194, 'int_col_threshold': 1, 'accident_threshold': 217, 'clean_title_threshold': 1000, 'body_style_threshold': 222, 'engine_threshold': 180, 'fuel_type_threshold': 360}. Best is trial 30 with value: 81144.21817245235.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:13] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:13] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:13] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:00:15,211] Trial 38 finished with value: 81181.31068317423 and parameters: {'n_estimators': 50, 'min_child_weight': 0.00010000000000000009, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 0.011118673738042139, 'model_threshold': 129, 'brand_threshold': 1000, 'ext_col_threshold': 1, 'int_col_threshold': 1, 'accident_threshold': 1000, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 165, 'fuel_type_threshold': 1}. Best is trial 30 with value: 81144.21817245235.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:19] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:19] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:19] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:00:22,125] Trial 39 finished with value: 81204.88497846884 and parameters: {'n_estimators': 50, 'min_child_weight': 0.00023914129110288513, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 0.04099518618776703, 'model_threshold': 1000, 'brand_threshold': 540, 'ext_col_threshold': 1, 'int_col_threshold': 135, 'accident_threshold': 1000, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 190, 'fuel_type_threshold': 274}. Best is trial 30 with value: 81144.21817245235.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:28] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:28] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:28] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:00:31,124] Trial 40 finished with value: 81152.36237082382 and parameters: {'n_estimators': 756, 'min_child_weight': 0.011207735265384842, 'subsample': 0.9967138628025853, 'colsample_bytree': 0.05, 'lambda': 9.503061689384936, 'alpha': 0.14848286111635378, 'model_threshold': 711, 'brand_threshold': 609, 'ext_col_threshold': 402, 'int_col_threshold': 459, 'accident_threshold': 491, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 189, 'fuel_type_threshold': 323}. Best is trial 30 with value: 81144.21817245235.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:34] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:34] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:34] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:00:36,855] Trial 41 finished with value: 81464.14223623894 and parameters: {'n_estimators': 1200, 'min_child_weight': 9.999999999999993, 'subsample': 0.1, 'colsample_bytree': 0.05, 'lambda': 49.99999999999995, 'alpha': 9.999999999999993, 'model_threshold': 1000, 'brand_threshold': 1000, 'ext_col_threshold': 1, 'int_col_threshold': 1, 'accident_threshold': 1000, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 677, 'fuel_type_threshold': 1000}. Best is trial 30 with value: 81144.21817245235.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:42] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:42] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:42] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:00:45,493] Trial 42 finished with value: 81138.96981295316 and parameters: {'n_estimators': 50, 'min_child_weight': 0.00010000000000000009, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'model_threshold': 1000, 'brand_threshold': 1000, 'ext_col_threshold': 1000, 'int_col_threshold': 1, 'accident_threshold': 1000, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 198, 'fuel_type_threshold': 1}. Best is trial 42 with value: 81138.96981295316.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:48] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:48] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:48] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:00:51,778] Trial 43 finished with value: 81389.57883692565 and parameters: {'n_estimators': 50, 'min_child_weight': 0.00010000000000000009, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'model_threshold': 1000, 'brand_threshold': 1000, 'ext_col_threshold': 1, 'int_col_threshold': 949, 'accident_threshold': 1000, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 246, 'fuel_type_threshold': 1}. Best is trial 42 with value: 81138.96981295316.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:55] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:55] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:00:55] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:00:58,333] Trial 44 finished with value: 81336.63451358686 and parameters: {'n_estimators': 1200, 'min_child_weight': 9.999999999999993, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'model_threshold': 1000, 'brand_threshold': 1000, 'ext_col_threshold': 1000, 'int_col_threshold': 1000, 'accident_threshold': 845, 'clean_title_threshold': 1000, 'body_style_threshold': 1000, 'engine_threshold': 507, 'fuel_type_threshold': 1000}. Best is trial 42 with value: 81138.96981295316.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:02] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:02] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:02] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:01:05,586] Trial 45 finished with value: 81328.99780703861 and parameters: {'n_estimators': 1200, 'min_child_weight': 9.999999999999993, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 49.99999999999995, 'alpha': 9.999999999999993, 'model_threshold': 1000, 'brand_threshold': 1000, 'ext_col_threshold': 1000, 'int_col_threshold': 794, 'accident_threshold': 1, 'clean_title_threshold': 674, 'body_style_threshold': 1, 'engine_threshold': 351, 'fuel_type_threshold': 1}. Best is trial 42 with value: 81138.96981295316.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:09] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:09] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:09] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:01:11,518] Trial 46 finished with value: 81190.3227093567 and parameters: {'n_estimators': 1200, 'min_child_weight': 0.00010000000000000009, 'subsample': 1.0, 'colsample_bytree': 0.09932118804310386, 'lambda': 49.99999999999999, 'alpha': 0.0006787071780973627, 'model_threshold': 1000, 'brand_threshold': 1000, 'ext_col_threshold': 1, 'int_col_threshold': 1, 'accident_threshold': 69, 'clean_title_threshold': 1000, 'body_style_threshold': 1, 'engine_threshold': 162, 'fuel_type_threshold': 1}. Best is trial 42 with value: 81138.96981295316.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:15] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:15] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:15] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:01:19,148] Trial 47 finished with value: 81509.94425617336 and parameters: {'n_estimators': 50, 'min_child_weight': 9.999999999999993, 'subsample': 0.2415681739805907, 'colsample_bytree': 0.05, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'model_threshold': 1000, 'brand_threshold': 1000, 'ext_col_threshold': 1000, 'int_col_threshold': 1, 'accident_threshold': 1000, 'clean_title_threshold': 1000, 'body_style_threshold': 1000, 'engine_threshold': 519, 'fuel_type_threshold': 482}. Best is trial 42 with value: 81138.96981295316.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:23] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:23] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:23] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:01:24,894] Trial 48 finished with value: 81191.09568752022 and parameters: {'n_estimators': 1200, 'min_child_weight': 9.999999999999993, 'subsample': 1.0, 'colsample_bytree': 0.05, 'lambda': 49.99999999999995, 'alpha': 9.999999999999993, 'model_threshold': 1000, 'brand_threshold': 1000, 'ext_col_threshold': 1, 'int_col_threshold': 566, 'accident_threshold': 1, 'clean_title_threshold': 953, 'body_style_threshold': 1000, 'engine_threshold': 223, 'fuel_type_threshold': 194}. Best is trial 42 with value: 81138.96981295316.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:28] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:28] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:01:28] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:01:29,150] Trial 49 finished with value: 81108.91073494995 and parameters: {'n_estimators': 878, 'min_child_weight': 0.0075215738262210995, 'subsample': 1.0, 'colsample_bytree': 0.22869678188393772, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'model_threshold': 1000, 'brand_threshold': 604, 'ext_col_threshold': 1, 'int_col_threshold': 542, 'accident_threshold': 1, 'clean_title_threshold': 974, 'body_style_threshold': 1, 'engine_threshold': 179, 'fuel_type_threshold': 249}. Best is trial 49 with value: 81108.91073494995.\nBest hyperparameters: {'n_estimators': 878, 'min_child_weight': 0.0075215738262210995, 'subsample': 1.0, 'colsample_bytree': 0.22869678188393772, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'model_threshold': 1000, 'brand_threshold': 604, 'ext_col_threshold': 1, 'int_col_threshold': 542, 'accident_threshold': 1, 'clean_title_threshold': 974, 'body_style_threshold': 1, 'engine_threshold': 179, 'fuel_type_threshold': 249}\nParameter importance:\n {'colsample_bytree': 0.4144579344187628, 'engine_threshold': 0.31475432598435404, 'brand_threshold': 0.061805385100053845, 'model_threshold': 0.042546870426147194, 'fuel_type_threshold': 0.04254038183657825, 'clean_title_threshold': 0.039737374242651405, 'int_col_threshold': 0.025841356085599287, 'accident_threshold': 0.022550638654602308, 'lambda': 0.011394401528707682, 'ext_col_threshold': 0.006190990230773002, 'subsample': 0.006063166882046892, 'n_estimators': 0.005933781730134086, 'min_child_weight': 0.003222212496670466, 'body_style_threshold': 0.0015942380615864122, 'alpha': 0.0013669423213325041}\n","output_type":"stream"},{"output_type":"error","ename":"NameError","evalue":"name 'cat' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 66\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter importance:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, optuna\u001b[38;5;241m.\u001b[39mimportance\u001b[38;5;241m.\u001b[39mget_param_importances(study))\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature importance: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[43m{\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature_importances\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature_importances\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m)\n","Cell \u001b[0;32mIn[7], line 66\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter importance:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, optuna\u001b[38;5;241m.\u001b[39mimportance\u001b[38;5;241m.\u001b[39mget_param_importances(study))\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature importance: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, {feature: \u001b[38;5;28msum\u001b[39m(\u001b[43m[\u001b[49m\u001b[43mfi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature_importances\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m feature_importances[\u001b[38;5;241m0\u001b[39m]})\n","Cell \u001b[0;32mIn[7], line 66\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter importance:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, optuna\u001b[38;5;241m.\u001b[39mimportance\u001b[38;5;241m.\u001b[39mget_param_importances(study))\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature importance: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, {feature: \u001b[38;5;28msum\u001b[39m([fi[\u001b[43mcat\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m fi \u001b[38;5;129;01min\u001b[39;00m feature_importances])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m feature_importances[\u001b[38;5;241m0\u001b[39m]})\n","\u001b[0;31mNameError\u001b[0m: name 'cat' is not defined"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/16f55ccb-83b0-42c8-b9cd-98e999d0013f","content_dependencies":null},{"cellId":"c1958585a9674a81ae9dea5a6bab1c31","cell_type":"code","metadata":{"source_hash":"e9d993ef","execution_start":1727377445814,"execution_millis":38,"execution_context_id":"5f75d612-7b5f-42ab-b178-48f19d47eef9","cell_id":"c1958585a9674a81ae9dea5a6bab1c31","deepnote_cell_type":"code"},"source":"f_importances = {feature: sum([fi[feature] for fi in feature_importances if feature in fi])/100 for feature in feature_importances[0]}\ntotal = sum(f_importances.values())\nf_importances_standard = {feature: f_importances[feature]/total for feature in f_importances}\nprint(\"Feature importance: \\n\", f_importances_standard)","block_group":"ab135f37daf441048478de1c07e01100","execution_count":9,"outputs":[{"name":"stdout","text":"Feature importance: \n {'brand': 0.07200130657595478, 'model': 0.03599074756328742, 'model_year': 0.10793240908349448, 'fuel_type': 0.022526260745851383, 'engine': 0.057558793656742706, 'ext_col': 0.02189535043553052, 'int_col': 0.07208678545350937, 'accident': 0.08620985953568445, 'clean_title': 0.33842225132696374, 'body_style': 0.028619161087551467, 'age': 0.03034336200104892, 'reliability': 0.011735095806003293, 'adjusted_msrp': 0.06584348721771022, 'miles_per_year': 0.048835129510667215}\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/cb55d8a0-60c6-4e29-ad34-444e2cfa33aa","content_dependencies":null},{"cellId":"dae1ce98a1594014b92e87a216373a5d","cell_type":"code","metadata":{"source_hash":"8fbaf097","execution_start":1727377440302,"execution_millis":2328,"execution_context_id":"5f75d612-7b5f-42ab-b178-48f19d47eef9","deepnote_to_be_reexecuted":false,"cell_id":"dae1ce98a1594014b92e87a216373a5d","deepnote_cell_type":"code"},"source":"optuna.visualization.plot_param_importances(study)","block_group":"3cb104398f304b7a8eceb5c6c99fcc29","execution_count":8,"outputs":[{"data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.30.0.min.js\"></script>                <div id=\"cb79a583-3d4e-4166-803b-53f7d25597fc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cb79a583-3d4e-4166-803b-53f7d25597fc\")) {                    Plotly.newPlot(                        \"cb79a583-3d4e-4166-803b-53f7d25597fc\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"n_estimators (IntDistribution): 0.0006374225470636356\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"ext_col_threshold (IntDistribution): 0.00130996957279092\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"alpha (FloatDistribution): 0.0015178633767862733\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"subsample (FloatDistribution): 0.0026897690729344274\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"min_child_weight (FloatDistribution): 0.003145226374462816\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"body_style_threshold (IntDistribution): 0.003192209087014861\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"accident_threshold (IntDistribution): 0.0054602330638836\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"int_col_threshold (IntDistribution): 0.014868891939003169\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"lambda (FloatDistribution): 0.020981282540884164\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"model_threshold (IntDistribution): 0.03764315068771183\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"clean_title_threshold (IntDistribution): 0.03931791790446218\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"fuel_type_threshold (IntDistribution): 0.042695307390972256\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"brand_threshold (IntDistribution): 0.04609738221413767\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"engine_threshold (IntDistribution): 0.20145149478663418\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"colsample_bytree (FloatDistribution): 0.578991879441258\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"0.01\",\"0.02\",\"0.04\",\"0.04\",\"0.04\",\"0.05\",\"0.20\",\"0.58\"],\"textposition\":\"outside\",\"x\":[0.0006374225470636356,0.00130996957279092,0.0015178633767862733,0.0026897690729344274,0.003145226374462816,0.003192209087014861,0.0054602330638836,0.014868891939003169,0.020981282540884164,0.03764315068771183,0.03931791790446218,0.042695307390972256,0.04609738221413767,0.20145149478663418,0.578991879441258],\"y\":[\"n_estimators\",\"ext_col_threshold\",\"alpha\",\"subsample\",\"min_child_weight\",\"body_style_threshold\",\"accident_threshold\",\"int_col_threshold\",\"lambda\",\"model_threshold\",\"clean_title_threshold\",\"fuel_type_threshold\",\"brand_threshold\",\"engine_threshold\",\"colsample_bytree\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('cb79a583-3d4e-4166-803b-53f7d25597fc');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{},"output_type":"display_data"}],"outputs_reference":"s3:deepnote-cell-outputs-production/378b970c-ea3f-4278-be61-34ac4c5b7e7a","content_dependencies":null},{"cellId":"c4c24c1744334afd98ebdaa7508e5686","cell_type":"code","metadata":{"source_hash":"22488153","execution_start":1727379567598,"execution_millis":1974827,"execution_context_id":"d256476e-e514-4e9d-9d56-8ebd71ef0b35","cell_id":"c4c24c1744334afd98ebdaa7508e5686","deepnote_cell_type":"code"},"source":"import xgboost as xgb\n\ndrop_cols = ['id', 'price_diff', 'adjusted_price_diff', 'transmission', 'full_name', 'brand_model']\ny = df['price']\nX = df.drop(['price'], axis=1).drop(drop_cols, axis=1)\nfeature_importances = []\nthreshold_opt_cats = [\"model\", \"ext_col\", \"accident\", \n             \"clean_title\", \"body_style\",\n             'engine','fuel_type', 'int_col', 'brand']\ndef objective(trial):\n    # Suggest hyperparameters for tuning\n    params = {\n        'include_mileage': trial.suggest_int('include_mileage', 0, 1),\n        'include_msrp': trial.suggest_int('include_msrp', 0, 1),\n        'objective': 'reg:squarederror',\n        'eval_metric': 'rmse',\n        'booster': 'gbtree',\n        'n_estimators': trial.suggest_int('n_estimators', 50, 1200),\n        'eta':trial.suggest_float('eta', 0.0001, 0.5, log = True),  # learning rate\n        'max_depth': trial.suggest_int('max_depth', 4, 8),\n        'min_child_weight': trial.suggest_float('min_child_weight', 1e-5, 100, log = True),\n        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.05, 1.0),\n        'lambda': trial.suggest_float('lambda', 0.1, 1000, log = True),\n        'alpha': trial.suggest_float('alpha', 1e-4, 100, log = True),\n        'tree_method': 'hist',  \n        'device':'cpu'\n    }\n    threshold = {cat:trial.suggest_int(f'{cat}_threshold', 1, 1000) for cat in threshold_opt_cats}\n\n    \n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=1219)\n    \n\n    for cat in cat_types:\n        value_counts = X_train[cat].value_counts().to_dict()\n        X_train[cat] = X_train[cat].apply(lambda x: x if value_counts[x] > threshold[cat] else \"unknown\")\n        X_valid[cat] = X_valid[cat].apply(lambda x: x if (x in value_counts) and (value_counts[x] > threshold[cat]) else \"unknown\")\n\n    X_train = X_train.astype({col: \"category\" for col in cat_types})\n    X_valid = X_valid.astype({col: \"category\" for col in cat_types})\n\n    if params['include_mileage'] == 1:\n        X_train.drop(['milage'], axis=1, inplace=True)\n        X_valid.drop(['milage'], axis=1, inplace=True)\n    \n    if params['include_msrp'] == 1:\n        X_train.drop(['msrp'], axis=1, inplace=True)\n        X_valid.drop(['msrp'], axis=1, inplace=True)\n    \n\n    dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n    dvalid = xgb.DMatrix(X_valid, label=y_valid, enable_categorical=True)\n    \n    # Train the model\n    model = xgb.train(params, dtrain, evals=[(dvalid, 'validation')], num_boost_round=1500, early_stopping_rounds=35, verbose_eval=False)\n    feature_importances.append(model.get_score(importance_type='gain'))  # get feature importance\n    # Predict on the validation set\n    y_pred_valid = model.predict(dvalid)\n    \n    # Calculate RMSE on the validation set\n    rmse = mean_squared_error(y_valid, y_pred_valid, squared=False)\n    \n    return rmse\n\n\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=250)\n\n\nbest_params = study.best_params\nprint(f\"Best hyperparameters: {best_params}\")\n\nprint(\"Parameter importance:\\n\", optuna.importance.get_param_importances(study))\n","block_group":"490c2596f6674c1494748204bd6d936b","execution_count":2,"outputs":[{"name":"stderr","text":"[I 2024-09-26 19:39:27,649] A new study created in memory with name: no-name-659e1cfa-489a-4d51-a0aa-cd09d5af9b73\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:39:27] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:39:43,762] Trial 0 finished with value: 80961.05602314687 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 583, 'eta': 0.004934075484535698, 'max_depth': 7, 'min_child_weight': 9.076982728045543e-05, 'subsample': 0.46898673043348904, 'colsample_bytree': 0.4798163301945596, 'lambda': 1.207834293296568, 'alpha': 0.0007443984556959671, 'model_threshold': 286, 'ext_col_threshold': 959, 'accident_threshold': 428, 'clean_title_threshold': 911, 'body_style_threshold': 842, 'engine_threshold': 67, 'fuel_type_threshold': 327, 'int_col_threshold': 177, 'brand_threshold': 911}. Best is trial 0 with value: 80961.05602314687.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:39:43] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:40:10,959] Trial 1 finished with value: 82400.28995047792 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 988, 'eta': 0.0008508673657044119, 'max_depth': 6, 'min_child_weight': 3.9232780387151003, 'subsample': 0.6670290916802163, 'colsample_bytree': 0.2396203483059175, 'lambda': 0.28286096724942006, 'alpha': 5.059182761003315, 'model_threshold': 485, 'ext_col_threshold': 66, 'accident_threshold': 544, 'clean_title_threshold': 958, 'body_style_threshold': 727, 'engine_threshold': 754, 'fuel_type_threshold': 784, 'int_col_threshold': 647, 'brand_threshold': 777}. Best is trial 0 with value: 80961.05602314687.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:40:11] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:40:17,310] Trial 2 finished with value: 80941.79203449615 and parameters: {'include_mileage': 1, 'include_msrp': 1, 'n_estimators': 371, 'eta': 0.029381459734978282, 'max_depth': 6, 'min_child_weight': 0.002071170503052973, 'subsample': 0.2797994083869294, 'colsample_bytree': 0.30666995559877624, 'lambda': 11.530969931211917, 'alpha': 0.07379411870156359, 'model_threshold': 137, 'ext_col_threshold': 467, 'accident_threshold': 789, 'clean_title_threshold': 872, 'body_style_threshold': 168, 'engine_threshold': 903, 'fuel_type_threshold': 743, 'int_col_threshold': 168, 'brand_threshold': 906}. Best is trial 2 with value: 80941.79203449615.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:40:17] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:40:19,790] Trial 3 finished with value: 82591.57398231051 and parameters: {'include_mileage': 1, 'include_msrp': 0, 'n_estimators': 153, 'eta': 0.046544617223152444, 'max_depth': 8, 'min_child_weight': 0.0002841433207610959, 'subsample': 0.8735395764681801, 'colsample_bytree': 0.8144843983468385, 'lambda': 0.13549564170537673, 'alpha': 0.2190904906529607, 'model_threshold': 594, 'ext_col_threshold': 190, 'accident_threshold': 713, 'clean_title_threshold': 870, 'body_style_threshold': 890, 'engine_threshold': 722, 'fuel_type_threshold': 165, 'int_col_threshold': 487, 'brand_threshold': 99}. Best is trial 2 with value: 80941.79203449615.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:40:20] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:40:23,470] Trial 4 finished with value: 81061.97278555477 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 485, 'eta': 0.05078753475506997, 'max_depth': 8, 'min_child_weight': 0.0006140326208600321, 'subsample': 0.14713169732112477, 'colsample_bytree': 0.2738893270414391, 'lambda': 4.3435577954387465, 'alpha': 23.637962064284334, 'model_threshold': 849, 'ext_col_threshold': 392, 'accident_threshold': 373, 'clean_title_threshold': 873, 'body_style_threshold': 489, 'engine_threshold': 160, 'fuel_type_threshold': 37, 'int_col_threshold': 733, 'brand_threshold': 423}. Best is trial 2 with value: 80941.79203449615.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:40:23] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:40:25,891] Trial 5 finished with value: 81028.95575523161 and parameters: {'include_mileage': 1, 'include_msrp': 1, 'n_estimators': 595, 'eta': 0.06522674989150759, 'max_depth': 5, 'min_child_weight': 1.2186129531208894e-05, 'subsample': 0.8801128114947276, 'colsample_bytree': 0.48943082894604334, 'lambda': 10.288149527379373, 'alpha': 0.15917494210422248, 'model_threshold': 211, 'ext_col_threshold': 68, 'accident_threshold': 974, 'clean_title_threshold': 122, 'body_style_threshold': 328, 'engine_threshold': 865, 'fuel_type_threshold': 166, 'int_col_threshold': 443, 'brand_threshold': 15}. Best is trial 2 with value: 80941.79203449615.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:40:26] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:40:29,580] Trial 6 finished with value: 80880.56368828514 and parameters: {'include_mileage': 1, 'include_msrp': 1, 'n_estimators': 629, 'eta': 0.07552570641717812, 'max_depth': 7, 'min_child_weight': 66.55593554618244, 'subsample': 0.9640987038948685, 'colsample_bytree': 0.2682231387178406, 'lambda': 47.8703359809338, 'alpha': 5.233432527403548, 'model_threshold': 92, 'ext_col_threshold': 381, 'accident_threshold': 495, 'clean_title_threshold': 723, 'body_style_threshold': 786, 'engine_threshold': 181, 'fuel_type_threshold': 456, 'int_col_threshold': 932, 'brand_threshold': 101}. Best is trial 6 with value: 80880.56368828514.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:40:29] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:40:37,656] Trial 7 finished with value: 80754.37383752693 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 111, 'eta': 0.021837962965455357, 'max_depth': 6, 'min_child_weight': 0.004685967878592736, 'subsample': 0.45146950748881853, 'colsample_bytree': 0.7807561726346489, 'lambda': 117.94796357108936, 'alpha': 1.3615170629911517, 'model_threshold': 320, 'ext_col_threshold': 614, 'accident_threshold': 608, 'clean_title_threshold': 443, 'body_style_threshold': 426, 'engine_threshold': 147, 'fuel_type_threshold': 884, 'int_col_threshold': 875, 'brand_threshold': 922}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:40:37] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:40:39,243] Trial 8 finished with value: 80999.00550362493 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1014, 'eta': 0.07862703817248007, 'max_depth': 4, 'min_child_weight': 10.759901894611156, 'subsample': 0.6453595815744513, 'colsample_bytree': 0.9497835586901294, 'lambda': 0.3345641738679744, 'alpha': 0.20663084074589197, 'model_threshold': 179, 'ext_col_threshold': 783, 'accident_threshold': 307, 'clean_title_threshold': 950, 'body_style_threshold': 215, 'engine_threshold': 100, 'fuel_type_threshold': 74, 'int_col_threshold': 552, 'brand_threshold': 230}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:40:39] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:40:55,332] Trial 9 finished with value: 81540.27967474108 and parameters: {'include_mileage': 1, 'include_msrp': 1, 'n_estimators': 476, 'eta': 0.001154110731464722, 'max_depth': 4, 'min_child_weight': 0.02237517133772345, 'subsample': 0.9822974746436195, 'colsample_bytree': 0.6075327297828761, 'lambda': 22.224090978635598, 'alpha': 0.3935946055523617, 'model_threshold': 189, 'ext_col_threshold': 676, 'accident_threshold': 541, 'clean_title_threshold': 435, 'body_style_threshold': 590, 'engine_threshold': 769, 'fuel_type_threshold': 780, 'int_col_threshold': 308, 'brand_threshold': 12}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:40:55] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:40:56,782] Trial 10 finished with value: 81210.80567678632 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 51, 'eta': 0.40027211192659723, 'max_depth': 5, 'min_child_weight': 0.1402643092711639, 'subsample': 0.4151354651849217, 'colsample_bytree': 0.7298419892615652, 'lambda': 668.7531289254513, 'alpha': 0.0024486141591100762, 'model_threshold': 525, 'ext_col_threshold': 669, 'accident_threshold': 95, 'clean_title_threshold': 379, 'body_style_threshold': 34, 'engine_threshold': 396, 'fuel_type_threshold': 977, 'int_col_threshold': 973, 'brand_threshold': 659}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:40:57] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:41:17,757] Trial 11 finished with value: 81445.9094423745 and parameters: {'include_mileage': 1, 'include_msrp': 0, 'n_estimators': 906, 'eta': 0.0075632730444307695, 'max_depth': 7, 'min_child_weight': 84.08553200020143, 'subsample': 0.6407757052728822, 'colsample_bytree': 0.08897903931749984, 'lambda': 161.0839783983337, 'alpha': 71.63597255930078, 'model_threshold': 376, 'ext_col_threshold': 302, 'accident_threshold': 681, 'clean_title_threshold': 629, 'body_style_threshold': 459, 'engine_threshold': 319, 'fuel_type_threshold': 506, 'int_col_threshold': 985, 'brand_threshold': 432}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:41:18] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:42:21,652] Trial 12 finished with value: 85197.93900497456 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 787, 'eta': 0.00011121010585412858, 'max_depth': 7, 'min_child_weight': 0.13098293417422452, 'subsample': 0.30944330111387947, 'colsample_bytree': 0.9841679719059759, 'lambda': 82.38407052120404, 'alpha': 3.7661362259074425, 'model_threshold': 21, 'ext_col_threshold': 591, 'accident_threshold': 243, 'clean_title_threshold': 607, 'body_style_threshold': 697, 'engine_threshold': 257, 'fuel_type_threshold': 523, 'int_col_threshold': 768, 'brand_threshold': 602}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:42:21] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:42:24,042] Trial 13 finished with value: 81586.09320400037 and parameters: {'include_mileage': 1, 'include_msrp': 1, 'n_estimators': 295, 'eta': 0.32046421425870975, 'max_depth': 6, 'min_child_weight': 0.00885898760209441, 'subsample': 0.7670004033322587, 'colsample_bytree': 0.05333358301326216, 'lambda': 87.36683658563645, 'alpha': 2.567757681016665, 'model_threshold': 20, 'ext_col_threshold': 339, 'accident_threshold': 600, 'clean_title_threshold': 245, 'body_style_threshold': 947, 'engine_threshold': 509, 'fuel_type_threshold': 371, 'int_col_threshold': 858, 'brand_threshold': 265}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:42:24] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:42:48,503] Trial 14 finished with value: 80850.61920045727 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1195, 'eta': 0.012599784752125042, 'max_depth': 7, 'min_child_weight': 0.9298722235625221, 'subsample': 0.4970039953711804, 'colsample_bytree': 0.6627377343436868, 'lambda': 999.513529236232, 'alpha': 1.497004327803143, 'model_threshold': 714, 'ext_col_threshold': 528, 'accident_threshold': 897, 'clean_title_threshold': 642, 'body_style_threshold': 391, 'engine_threshold': 520, 'fuel_type_threshold': 596, 'int_col_threshold': 845, 'brand_threshold': 988}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:42:48] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:43:07,838] Trial 15 finished with value: 80900.26772726988 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1157, 'eta': 0.008486737862437315, 'max_depth': 5, 'min_child_weight': 0.7386045727111772, 'subsample': 0.5171734426269848, 'colsample_bytree': 0.7012878816176845, 'lambda': 773.6996620344189, 'alpha': 0.020888325874356392, 'model_threshold': 748, 'ext_col_threshold': 845, 'accident_threshold': 936, 'clean_title_threshold': 320, 'body_style_threshold': 377, 'engine_threshold': 538, 'fuel_type_threshold': 984, 'int_col_threshold': 820, 'brand_threshold': 993}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:43:08] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:43:52,541] Trial 16 finished with value: 80993.14928955075 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 732, 'eta': 0.002239238527924542, 'max_depth': 8, 'min_child_weight': 0.5283815620507869, 'subsample': 0.33656034737818186, 'colsample_bytree': 0.8385920507213724, 'lambda': 321.15269973260916, 'alpha': 0.015270351165567972, 'model_threshold': 975, 'ext_col_threshold': 555, 'accident_threshold': 844, 'clean_title_threshold': 538, 'body_style_threshold': 595, 'engine_threshold': 598, 'fuel_type_threshold': 676, 'int_col_threshold': 649, 'brand_threshold': 800}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:43:52] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:44:04,664] Trial 17 finished with value: 80916.56265776705 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 206, 'eta': 0.014931728970625542, 'max_depth': 7, 'min_child_weight': 0.0076655503382945306, 'subsample': 0.19116140089707329, 'colsample_bytree': 0.5870718233048888, 'lambda': 267.2904024491529, 'alpha': 1.2584670223673364, 'model_threshold': 685, 'ext_col_threshold': 702, 'accident_threshold': 848, 'clean_title_threshold': 709, 'body_style_threshold': 287, 'engine_threshold': 419, 'fuel_type_threshold': 638, 'int_col_threshold': 664, 'brand_threshold': 747}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:44:04] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:44:31,757] Trial 18 finished with value: 84547.38150668512 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1176, 'eta': 0.00019036232451286316, 'max_depth': 6, 'min_child_weight': 3.3392063915865298, 'subsample': 0.5711131369642104, 'colsample_bytree': 0.8343528229781086, 'lambda': 988.8809285222268, 'alpha': 14.446877117358142, 'model_threshold': 338, 'ext_col_threshold': 495, 'accident_threshold': 678, 'clean_title_threshold': 11, 'body_style_threshold': 42, 'engine_threshold': 633, 'fuel_type_threshold': 884, 'int_col_threshold': 887, 'brand_threshold': 993}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:44:32] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:44:33,868] Trial 19 finished with value: 81020.14857778826 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 814, 'eta': 0.15012715711636593, 'max_depth': 6, 'min_child_weight': 0.07369825379634216, 'subsample': 0.3973462240940867, 'colsample_bytree': 0.41023037346245095, 'lambda': 291.0220370369746, 'alpha': 0.0001782564316054363, 'model_threshold': 846, 'ext_col_threshold': 229, 'accident_threshold': 77, 'clean_title_threshold': 464, 'body_style_threshold': 415, 'engine_threshold': 396, 'fuel_type_threshold': 874, 'int_col_threshold': 65, 'brand_threshold': 864}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:44:34] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:44:38,141] Trial 20 finished with value: 82036.04504613894 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1065, 'eta': 0.018347225474059037, 'max_depth': 5, 'min_child_weight': 0.002768693821199331, 'subsample': 0.5648916157976721, 'colsample_bytree': 0.6467913966678104, 'lambda': 39.25934091090874, 'alpha': 0.5747450597779268, 'model_threshold': 427, 'ext_col_threshold': 606, 'accident_threshold': 898, 'clean_title_threshold': 261, 'body_style_threshold': 574, 'engine_threshold': 16, 'fuel_type_threshold': 583, 'int_col_threshold': 392, 'brand_threshold': 692}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:44:38] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:44:39,909] Trial 21 finished with value: 80999.92825783756 and parameters: {'include_mileage': 1, 'include_msrp': 1, 'n_estimators': 398, 'eta': 0.17248790493303454, 'max_depth': 7, 'min_child_weight': 66.31703491590059, 'subsample': 0.7297125383319678, 'colsample_bytree': 0.7499993527426292, 'lambda': 61.31174089035449, 'alpha': 6.993525588486306, 'model_threshold': 599, 'ext_col_threshold': 435, 'accident_threshold': 464, 'clean_title_threshold': 742, 'body_style_threshold': 750, 'engine_threshold': 216, 'fuel_type_threshold': 384, 'int_col_threshold': 912, 'brand_threshold': 541}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:44:40] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:45:09,812] Trial 22 finished with value: 81219.92674216656 and parameters: {'include_mileage': 1, 'include_msrp': 1, 'n_estimators': 674, 'eta': 0.003370781367046384, 'max_depth': 7, 'min_child_weight': 8.797004059455412, 'subsample': 0.4694336759498797, 'colsample_bytree': 0.1701224310750054, 'lambda': 30.979682528734266, 'alpha': 1.0466246306786202, 'model_threshold': 116, 'ext_col_threshold': 529, 'accident_threshold': 199, 'clean_title_threshold': 768, 'body_style_threshold': 531, 'engine_threshold': 284, 'fuel_type_threshold': 414, 'int_col_threshold': 779, 'brand_threshold': 267}. Best is trial 7 with value: 80754.37383752693.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:45:10] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:45:22,124] Trial 23 finished with value: 80673.88599564061 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 839, 'eta': 0.0185415206220248, 'max_depth': 8, 'min_child_weight': 0.7053004928372689, 'subsample': 0.7939903446615666, 'colsample_bytree': 0.38473967935821246, 'lambda': 153.5695977522292, 'alpha': 70.43813370305249, 'model_threshold': 279, 'ext_col_threshold': 369, 'accident_threshold': 755, 'clean_title_threshold': 555, 'body_style_threshold': 238, 'engine_threshold': 135, 'fuel_type_threshold': 253, 'int_col_threshold': 995, 'brand_threshold': 352}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:45:22] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:45:37,303] Trial 24 finished with value: 80842.81372469367 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 913, 'eta': 0.0129042649723769, 'max_depth': 8, 'min_child_weight': 0.2073905908926328, 'subsample': 0.7968850749310759, 'colsample_bytree': 0.430166006009154, 'lambda': 162.19035594263505, 'alpha': 74.69383636892428, 'model_threshold': 290, 'ext_col_threshold': 228, 'accident_threshold': 759, 'clean_title_threshold': 559, 'body_style_threshold': 158, 'engine_threshold': 348, 'fuel_type_threshold': 245, 'int_col_threshold': 984, 'brand_threshold': 425}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:45:37] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:45:45,112] Trial 25 finished with value: 80728.39301871425 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 884, 'eta': 0.0237888611830778, 'max_depth': 8, 'min_child_weight': 0.4251480825326538, 'subsample': 0.8066587491096859, 'colsample_bytree': 0.3902340815782297, 'lambda': 166.77464684314955, 'alpha': 73.54190243878038, 'model_threshold': 268, 'ext_col_threshold': 216, 'accident_threshold': 734, 'clean_title_threshold': 537, 'body_style_threshold': 138, 'engine_threshold': 152, 'fuel_type_threshold': 273, 'int_col_threshold': 978, 'brand_threshold': 375}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:45:45] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:45:49,746] Trial 26 finished with value: 80910.41210104545 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 868, 'eta': 0.02667246880908411, 'max_depth': 8, 'min_child_weight': 0.029751071415065822, 'subsample': 0.8663104133691527, 'colsample_bytree': 0.3646384291035024, 'lambda': 3.153115018449765, 'alpha': 26.04473955269062, 'model_threshold': 246, 'ext_col_threshold': 143, 'accident_threshold': 596, 'clean_title_threshold': 490, 'body_style_threshold': 247, 'engine_threshold': 120, 'fuel_type_threshold': 264, 'int_col_threshold': 899, 'brand_threshold': 352}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:45:50] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:45:56,023] Trial 27 finished with value: 81526.03381075093 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 762, 'eta': 0.033642786681780515, 'max_depth': 8, 'min_child_weight': 0.40965789823668575, 'subsample': 0.6990758044516352, 'colsample_bytree': 0.5443586498053534, 'lambda': 157.4191847784028, 'alpha': 64.85573195494418, 'model_threshold': 396, 'ext_col_threshold': 303, 'accident_threshold': 602, 'clean_title_threshold': 368, 'body_style_threshold': 117, 'engine_threshold': 7, 'fuel_type_threshold': 269, 'int_col_threshold': 709, 'brand_threshold': 534}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:45:56] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:45:58,063] Trial 28 finished with value: 81024.69531276458 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 987, 'eta': 0.14016126270668403, 'max_depth': 8, 'min_child_weight': 2.0342581222811456, 'subsample': 0.8156627190051767, 'colsample_bytree': 0.35415547469830844, 'lambda': 17.529586631526428, 'alpha': 16.48230819579183, 'model_threshold': 456, 'ext_col_threshold': 173, 'accident_threshold': 772, 'clean_title_threshold': 405, 'body_style_threshold': 90, 'engine_threshold': 225, 'fuel_type_threshold': 213, 'int_col_threshold': 573, 'brand_threshold': 321}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:45:58] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:46:13,025] Trial 29 finished with value: 80716.37907450572 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1094, 'eta': 0.006673812358043329, 'max_depth': 7, 'min_child_weight': 0.04121774890710283, 'subsample': 0.5945543476675754, 'colsample_bytree': 0.4516281442645414, 'lambda': 4.359062409528185, 'alpha': 0.03718877267005663, 'model_threshold': 288, 'ext_col_threshold': 942, 'accident_threshold': 402, 'clean_title_threshold': 557, 'body_style_threshold': 315, 'engine_threshold': 70, 'fuel_type_threshold': 326, 'int_col_threshold': 989, 'brand_threshold': 180}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:46:13] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:46:40,826] Trial 30 finished with value: 80984.44215689784 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1086, 'eta': 0.0037808460964150296, 'max_depth': 8, 'min_child_weight': 0.04958024250488829, 'subsample': 0.6036704666173408, 'colsample_bytree': 0.45567089287322954, 'lambda': 1.3716286007014207, 'alpha': 0.0033020800459910913, 'model_threshold': 279, 'ext_col_threshold': 999, 'accident_threshold': 383, 'clean_title_threshold': 555, 'body_style_threshold': 308, 'engine_threshold': 66, 'fuel_type_threshold': 307, 'int_col_threshold': 985, 'brand_threshold': 176}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:46:41] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:47:00,342] Trial 31 finished with value: 80726.09268603689 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 874, 'eta': 0.005813142871816944, 'max_depth': 7, 'min_child_weight': 0.011320768271813263, 'subsample': 0.4080000918224831, 'colsample_bytree': 0.4993615742008131, 'lambda': 5.005136637908362, 'alpha': 0.04252093582503305, 'model_threshold': 294, 'ext_col_threshold': 875, 'accident_threshold': 674, 'clean_title_threshold': 502, 'body_style_threshold': 215, 'engine_threshold': 142, 'fuel_type_threshold': 125, 'int_col_threshold': 818, 'brand_threshold': 358}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:47:00] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:47:40,578] Trial 32 finished with value: 80827.36783545345 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 950, 'eta': 0.0017796530033715985, 'max_depth': 7, 'min_child_weight': 0.022787803728261124, 'subsample': 0.9352431331569446, 'colsample_bytree': 0.5488704080401119, 'lambda': 3.840281510269866, 'alpha': 0.04285653864645965, 'model_threshold': 359, 'ext_col_threshold': 884, 'accident_threshold': 679, 'clean_title_threshold': 527, 'body_style_threshold': 219, 'engine_threshold': 92, 'fuel_type_threshold': 129, 'int_col_threshold': 935, 'brand_threshold': 350}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:47:40] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:47:59,432] Trial 33 finished with value: 80900.85846577039 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 853, 'eta': 0.005489440314900357, 'max_depth': 8, 'min_child_weight': 0.29400424527668184, 'subsample': 0.7279830216632653, 'colsample_bytree': 0.35874072052985573, 'lambda': 1.0414007313704514, 'alpha': 0.005778199217708033, 'model_threshold': 244, 'ext_col_threshold': 903, 'accident_threshold': 825, 'clean_title_threshold': 665, 'body_style_threshold': 135, 'engine_threshold': 47, 'fuel_type_threshold': 329, 'int_col_threshold': 818, 'brand_threshold': 174}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:47:59] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:48:17,586] Trial 34 finished with value: 80759.63776616802 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1051, 'eta': 0.008771523595195002, 'max_depth': 8, 'min_child_weight': 0.0006311291929550311, 'subsample': 0.24715736139526995, 'colsample_bytree': 0.19003910127623796, 'lambda': 7.063670955652526, 'alpha': 0.06143214571915957, 'model_threshold': 532, 'ext_col_threshold': 944, 'accident_threshold': 440, 'clean_title_threshold': 582, 'body_style_threshold': 218, 'engine_threshold': 205, 'fuel_type_threshold': 110, 'int_col_threshold': 933, 'brand_threshold': 449}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:48:17] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:48:39,203] Trial 35 finished with value: 80920.07615804578 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 727, 'eta': 0.003533014573689434, 'max_depth': 7, 'min_child_weight': 0.0011040725360791557, 'subsample': 0.6767623203347835, 'colsample_bytree': 0.39356312488109146, 'lambda': 1.3901523311128325, 'alpha': 0.0007200508790445805, 'model_threshold': 151, 'ext_col_threshold': 787, 'accident_threshold': 729, 'clean_title_threshold': 790, 'body_style_threshold': 290, 'engine_threshold': 117, 'fuel_type_threshold': 192, 'int_col_threshold': 995, 'brand_threshold': 324}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:48:39] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:49:31,624] Trial 36 finished with value: 82616.75234405817 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1126, 'eta': 0.0004665967306228979, 'max_depth': 8, 'min_child_weight': 1.8427175813541758, 'subsample': 0.36348026940904826, 'colsample_bytree': 0.4991671325412008, 'lambda': 7.7961052430324465, 'alpha': 0.024404030822084494, 'model_threshold': 84, 'ext_col_threshold': 24, 'accident_threshold': 545, 'clean_title_threshold': 487, 'body_style_threshold': 355, 'engine_threshold': 279, 'fuel_type_threshold': 53, 'int_col_threshold': 773, 'brand_threshold': 491}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:49:31] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:49:35,749] Trial 37 finished with value: 80961.4066031258 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 963, 'eta': 0.033847157259827454, 'max_depth': 7, 'min_child_weight': 4.5430236004233636e-05, 'subsample': 0.8330634306357323, 'colsample_bytree': 0.2884568385962465, 'lambda': 2.1349939272337815, 'alpha': 0.007158817958310312, 'model_threshold': 240, 'ext_col_threshold': 112, 'accident_threshold': 652, 'clean_title_threshold': 292, 'body_style_threshold': 184, 'engine_threshold': 997, 'fuel_type_threshold': 326, 'int_col_threshold': 715, 'brand_threshold': 192}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:49:35] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:49:54,541] Trial 38 finished with value: 80676.56017491208 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 534, 'eta': 0.0050928318928405115, 'max_depth': 6, 'min_child_weight': 0.011896802751032186, 'subsample': 0.9049643882250884, 'colsample_bytree': 0.47035365746943236, 'lambda': 13.340308719763621, 'alpha': 0.0011648218367746484, 'model_threshold': 295, 'ext_col_threshold': 434, 'accident_threshold': 364, 'clean_title_threshold': 681, 'body_style_threshold': 2, 'engine_threshold': 159, 'fuel_type_threshold': 5, 'int_col_threshold': 290, 'brand_threshold': 125}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:49:54] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:50:24,206] Trial 39 finished with value: 82412.30495512544 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 554, 'eta': 0.0004943743005010691, 'max_depth': 6, 'min_child_weight': 0.00010118741252156086, 'subsample': 0.8857808487434566, 'colsample_bytree': 0.46738116394018636, 'lambda': 0.537552717191839, 'alpha': 0.001011903834990004, 'model_threshold': 471, 'ext_col_threshold': 431, 'accident_threshold': 367, 'clean_title_threshold': 804, 'body_style_threshold': 78, 'engine_threshold': 64, 'fuel_type_threshold': 25, 'int_col_threshold': 275, 'brand_threshold': 77}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:50:24] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:50:51,485] Trial 40 finished with value: 80942.80846424376 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 670, 'eta': 0.0015527700033860284, 'max_depth': 6, 'min_child_weight': 0.013380003884302188, 'subsample': 0.9227540611192986, 'colsample_bytree': 0.31830740080508824, 'lambda': 14.209798729537667, 'alpha': 0.15145818730768815, 'model_threshold': 317, 'ext_col_threshold': 801, 'accident_threshold': 185, 'clean_title_threshold': 859, 'body_style_threshold': 25, 'engine_threshold': 160, 'fuel_type_threshold': 111, 'int_col_threshold': 216, 'brand_threshold': 119}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:50:51] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:51:02,417] Trial 41 finished with value: 80853.44643367668 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 491, 'eta': 0.006472086483265157, 'max_depth': 7, 'min_child_weight': 0.09055390488993836, 'subsample': 0.7684929017678584, 'colsample_bytree': 0.5096864266141029, 'lambda': 5.759523200076667, 'alpha': 0.000649912549312635, 'model_threshold': 205, 'ext_col_threshold': 358, 'accident_threshold': 280, 'clean_title_threshold': 682, 'body_style_threshold': 85, 'engine_threshold': 167, 'fuel_type_threshold': 14, 'int_col_threshold': 2, 'brand_threshold': 369}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:51:02] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:51:14,379] Trial 42 finished with value: 80776.24969365723 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 542, 'eta': 0.011258152984596365, 'max_depth': 6, 'min_child_weight': 0.0018781584346015793, 'subsample': 0.9171764814720336, 'colsample_bytree': 0.2335731120048462, 'lambda': 2.4411079714650947, 'alpha': 0.00013285695573767074, 'model_threshold': 404, 'ext_col_threshold': 441, 'accident_threshold': 525, 'clean_title_threshold': 608, 'body_style_threshold': 166, 'engine_threshold': 127, 'fuel_type_threshold': 146, 'int_col_threshold': 408, 'brand_threshold': 274}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:51:14] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:51:28,250] Trial 43 finished with value: 81505.66644472389 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 834, 'eta': 0.004244228046926451, 'max_depth': 8, 'min_child_weight': 0.04877945002697878, 'subsample': 0.9819600822399627, 'colsample_bytree': 0.5763843714857978, 'lambda': 0.13179419185546665, 'alpha': 0.0002998336884362679, 'model_threshold': 276, 'ext_col_threshold': 274, 'accident_threshold': 377, 'clean_title_threshold': 518, 'body_style_threshold': 263, 'engine_threshold': 227, 'fuel_type_threshold': 209, 'int_col_threshold': 571, 'brand_threshold': 56}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:51:28] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:51:31,521] Trial 44 finished with value: 80881.77634710824 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 624, 'eta': 0.04989716435164634, 'max_depth': 5, 'min_child_weight': 0.0042775692796535505, 'subsample': 0.8369626171508999, 'colsample_bytree': 0.4426760850246206, 'lambda': 25.449060176652683, 'alpha': 29.896531659479617, 'model_threshold': 157, 'ext_col_threshold': 721, 'accident_threshold': 998, 'clean_title_threshold': 441, 'body_style_threshold': 3, 'engine_threshold': 338, 'fuel_type_threshold': 67, 'int_col_threshold': 133, 'brand_threshold': 141}. Best is trial 23 with value: 80673.88599564061.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:51:31] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:51:43,361] Trial 45 finished with value: 80631.03843864669 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 907, 'eta': 0.021498969089694918, 'max_depth': 6, 'min_child_weight': 8.27944358203926, 'subsample': 0.6055411179144143, 'colsample_bytree': 0.4963974763232091, 'lambda': 449.726812602832, 'alpha': 0.0841004418771983, 'model_threshold': 341, 'ext_col_threshold': 979, 'accident_threshold': 333, 'clean_title_threshold': 681, 'body_style_threshold': 329, 'engine_threshold': 47, 'fuel_type_threshold': 449, 'int_col_threshold': 502, 'brand_threshold': 373}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:51:43] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:52:11,442] Trial 46 finished with value: 81575.7068034574 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1030, 'eta': 0.0028039844450692512, 'max_depth': 6, 'min_child_weight': 8.338229501795041, 'subsample': 0.6147455572988499, 'colsample_bytree': 0.5307741815536094, 'lambda': 9.081205725391541, 'alpha': 0.09403507337984343, 'model_threshold': 335, 'ext_col_threshold': 970, 'accident_threshold': 301, 'clean_title_threshold': 685, 'body_style_threshold': 466, 'engine_threshold': 25, 'fuel_type_threshold': 470, 'int_col_threshold': 485, 'brand_threshold': 225}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:52:11] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:52:42,817] Trial 47 finished with value: 81586.83575482872 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 408, 'eta': 0.000998756737215192, 'max_depth': 6, 'min_child_weight': 36.96836385046464, 'subsample': 0.5314964305033285, 'colsample_bytree': 0.6318576802661806, 'lambda': 553.8903317062413, 'alpha': 0.32186954549477764, 'model_threshold': 209, 'ext_col_threshold': 915, 'accident_threshold': 8, 'clean_title_threshold': 593, 'body_style_threshold': 342, 'engine_threshold': 83, 'fuel_type_threshold': 425, 'int_col_threshold': 336, 'brand_threshold': 293}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:52:43] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:53:05,329] Trial 48 finished with value: 80850.60681826343 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1109, 'eta': 0.006194418955809237, 'max_depth': 6, 'min_child_weight': 22.003565837608537, 'subsample': 0.45313611679405263, 'colsample_bytree': 0.4875718408237323, 'lambda': 430.18597573095207, 'alpha': 0.03863044076987268, 'model_threshold': 75, 'ext_col_threshold': 837, 'accident_threshold': 338, 'clean_title_threshold': 846, 'body_style_threshold': 332, 'engine_threshold': 454, 'fuel_type_threshold': 371, 'int_col_threshold': 527, 'brand_threshold': 225}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:53:05] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:53:12,620] Trial 49 finished with value: 80849.53478645331 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 949, 'eta': 0.01029103743800551, 'max_depth': 5, 'min_child_weight': 0.012203554484185877, 'subsample': 0.4050241307629191, 'colsample_bytree': 0.3426442793887927, 'lambda': 0.7790909255100502, 'alpha': 0.010108995541675747, 'model_threshold': 424, 'ext_col_threshold': 950, 'accident_threshold': 416, 'clean_title_threshold': 919, 'body_style_threshold': 422, 'engine_threshold': 180, 'fuel_type_threshold': 165, 'int_col_threshold': 229, 'brand_threshold': 44}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:53:12] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:53:17,477] Trial 50 finished with value: 82185.92805892757 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 786, 'eta': 0.017636479884883337, 'max_depth': 7, 'min_child_weight': 4.698994785294308, 'subsample': 0.5958649331707564, 'colsample_bytree': 0.5752368804937484, 'lambda': 5.546809181366847, 'alpha': 0.0036178914107719705, 'model_threshold': 520, 'ext_col_threshold': 872, 'accident_threshold': 467, 'clean_title_threshold': 646, 'body_style_threshold': 193, 'engine_threshold': 4, 'fuel_type_threshold': 73, 'int_col_threshold': 139, 'brand_threshold': 469}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:53:17] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:53:26,282] Trial 51 finished with value: 80679.72436275097 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 879, 'eta': 0.02276466571607591, 'max_depth': 6, 'min_child_weight': 1.1658294322292526, 'subsample': 0.6503935543835827, 'colsample_bytree': 0.4082250131687364, 'lambda': 224.55358847371727, 'alpha': 0.0018170682249534242, 'model_threshold': 290, 'ext_col_threshold': 396, 'accident_threshold': 249, 'clean_title_threshold': 712, 'body_style_threshold': 243, 'engine_threshold': 150, 'fuel_type_threshold': 299, 'int_col_threshold': 935, 'brand_threshold': 398}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:53:26] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:53:30,925] Trial 52 finished with value: 80680.29806695691 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 918, 'eta': 0.078885412465921, 'max_depth': 6, 'min_child_weight': 1.3964420713549777, 'subsample': 0.6318607462163857, 'colsample_bytree': 0.437246790874934, 'lambda': 401.5184385285344, 'alpha': 0.13936349126899422, 'model_threshold': 315, 'ext_col_threshold': 386, 'accident_threshold': 337, 'clean_title_threshold': 748, 'body_style_threshold': 249, 'engine_threshold': 94, 'fuel_type_threshold': 346, 'int_col_threshold': 843, 'brand_threshold': 407}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:53:31] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:53:35,291] Trial 53 finished with value: 80656.52463183267 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1000, 'eta': 0.07186499969021105, 'max_depth': 6, 'min_child_weight': 0.9946522912838596, 'subsample': 0.6456255893284133, 'colsample_bytree': 0.3071741379144588, 'lambda': 242.86775541189277, 'alpha': 0.0013816374458816957, 'model_threshold': 374, 'ext_col_threshold': 391, 'accident_threshold': 197, 'clean_title_threshold': 752, 'body_style_threshold': 283, 'engine_threshold': 50, 'fuel_type_threshold': 518, 'int_col_threshold': 945, 'brand_threshold': 520}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:53:35] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:53:39,296] Trial 54 finished with value: 80663.34924599687 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 921, 'eta': 0.09680411319385965, 'max_depth': 5, 'min_child_weight': 1.4893710495948558, 'subsample': 0.6472265965444909, 'colsample_bytree': 0.2436744293458774, 'lambda': 439.0854716789141, 'alpha': 0.001418797664088971, 'model_threshold': 362, 'ext_col_threshold': 476, 'accident_threshold': 220, 'clean_title_threshold': 740, 'body_style_threshold': 257, 'engine_threshold': 47, 'fuel_type_threshold': 538, 'int_col_threshold': 860, 'brand_threshold': 572}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:53:39] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:53:42,252] Trial 55 finished with value: 80672.6248393345 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 687, 'eta': 0.10676722117354592, 'max_depth': 5, 'min_child_weight': 17.79545731529333, 'subsample': 0.6555870841836561, 'colsample_bytree': 0.2560388648034624, 'lambda': 224.634723648935, 'alpha': 0.0016278027278752807, 'model_threshold': 349, 'ext_col_threshold': 461, 'accident_threshold': 220, 'clean_title_threshold': 717, 'body_style_threshold': 369, 'engine_threshold': 44, 'fuel_type_threshold': 545, 'int_col_threshold': 937, 'brand_threshold': 584}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:53:42] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:53:44,395] Trial 56 finished with value: 80744.81108711589 and parameters: {'include_mileage': 1, 'include_msrp': 0, 'n_estimators': 695, 'eta': 0.2527841743942943, 'max_depth': 4, 'min_child_weight': 20.593400958971824, 'subsample': 0.7043501589530297, 'colsample_bytree': 0.22473446566778893, 'lambda': 106.76089859278193, 'alpha': 0.0003683761507287009, 'model_threshold': 375, 'ext_col_threshold': 488, 'accident_threshold': 197, 'clean_title_threshold': 818, 'body_style_threshold': 364, 'engine_threshold': 39, 'fuel_type_threshold': 540, 'int_col_threshold': 612, 'brand_threshold': 622}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:53:44] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:53:47,833] Trial 57 finished with value: 80760.87136134531 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 814, 'eta': 0.11153372249165297, 'max_depth': 5, 'min_child_weight': 4.3091170481586945, 'subsample': 0.7669057328220623, 'colsample_bytree': 0.14564231542242162, 'lambda': 60.66537248809159, 'alpha': 0.0014960255247794291, 'model_threshold': 595, 'ext_col_threshold': 563, 'accident_threshold': 138, 'clean_title_threshold': 896, 'body_style_threshold': 506, 'engine_threshold': 49, 'fuel_type_threshold': 700, 'int_col_threshold': 344, 'brand_threshold': 562}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:53:48] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:53:55,199] Trial 58 finished with value: 81094.50882937873 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 320, 'eta': 0.06657832027790515, 'max_depth': 5, 'min_child_weight': 2.7993585376533843, 'subsample': 0.6781262432518693, 'colsample_bytree': 0.1229972029834272, 'lambda': 645.0632734946679, 'alpha': 0.0011270141744681116, 'model_threshold': 357, 'ext_col_threshold': 467, 'accident_threshold': 131, 'clean_title_threshold': 997, 'body_style_threshold': 434, 'engine_threshold': 250, 'fuel_type_threshold': 567, 'int_col_threshold': 943, 'brand_threshold': 656}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:53:55] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:53:59,328] Trial 59 finished with value: 80749.01643816472 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 611, 'eta': 0.09379379318779259, 'max_depth': 5, 'min_child_weight': 12.565654077416042, 'subsample': 0.7398246425574695, 'colsample_bytree': 0.25996308846211863, 'lambda': 230.7180820270583, 'alpha': 0.00042434042944411454, 'model_threshold': 441, 'ext_col_threshold': 313, 'accident_threshold': 248, 'clean_title_threshold': 752, 'body_style_threshold': 392, 'engine_threshold': 196, 'fuel_type_threshold': 642, 'int_col_threshold': 875, 'brand_threshold': 602}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:53:59] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:54:03,666] Trial 60 finished with value: 80928.23086075867 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 990, 'eta': 0.057815351553564806, 'max_depth': 4, 'min_child_weight': 0.8035478658909694, 'subsample': 0.5534366716383364, 'colsample_bytree': 0.31181309719748906, 'lambda': 454.43364998085707, 'alpha': 0.005856359377920054, 'model_threshold': 505, 'ext_col_threshold': 645, 'accident_threshold': 224, 'clean_title_threshold': 707, 'body_style_threshold': 994, 'engine_threshold': 805, 'fuel_type_threshold': 471, 'int_col_threshold': 437, 'brand_threshold': 711}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:54:03] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:54:09,706] Trial 61 finished with value: 80674.68598333643 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 747, 'eta': 0.041991981279609854, 'max_depth': 6, 'min_child_weight': 1.2194926268485013, 'subsample': 0.6529063431305574, 'colsample_bytree': 0.20305049459575086, 'lambda': 208.38178490780822, 'alpha': 0.0026641784517395174, 'model_threshold': 372, 'ext_col_threshold': 399, 'accident_threshold': 277, 'clean_title_threshold': 712, 'body_style_threshold': 273, 'engine_threshold': 110, 'fuel_type_threshold': 518, 'int_col_threshold': 955, 'brand_threshold': 511}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:54:09] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:54:17,602] Trial 62 finished with value: 80676.22239589083 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 754, 'eta': 0.0405057647566187, 'max_depth': 5, 'min_child_weight': 7.906672998074747, 'subsample': 0.49448635080132547, 'colsample_bytree': 0.20338112026378657, 'lambda': 355.8452545255411, 'alpha': 0.003178255808424429, 'model_threshold': 372, 'ext_col_threshold': 354, 'accident_threshold': 281, 'clean_title_threshold': 632, 'body_style_threshold': 285, 'engine_threshold': 101, 'fuel_type_threshold': 537, 'int_col_threshold': 949, 'brand_threshold': 511}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:54:17] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:54:19,009] Trial 63 finished with value: 81464.7917757978 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 735, 'eta': 0.22481620145196624, 'max_depth': 5, 'min_child_weight': 5.717745093657566, 'subsample': 0.5105490043514367, 'colsample_bytree': 0.20000462386558937, 'lambda': 343.4189032505765, 'alpha': 0.0030660933169273288, 'model_threshold': 561, 'ext_col_threshold': 348, 'accident_threshold': 159, 'clean_title_threshold': 638, 'body_style_threshold': 259, 'engine_threshold': 1, 'fuel_type_threshold': 500, 'int_col_threshold': 892, 'brand_threshold': 515}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:54:19] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:54:24,045] Trial 64 finished with value: 80701.5342818049 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 775, 'eta': 0.03801537886012978, 'max_depth': 5, 'min_child_weight': 39.43972087827241, 'subsample': 0.6504273789935856, 'colsample_bytree': 0.26416311000746495, 'lambda': 132.98649533809956, 'alpha': 0.002132524702458503, 'model_threshold': 407, 'ext_col_threshold': 266, 'accident_threshold': 87, 'clean_title_threshold': 772, 'body_style_threshold': 284, 'engine_threshold': 97, 'fuel_type_threshold': 609, 'int_col_threshold': 945, 'brand_threshold': 565}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:54:24] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:54:33,627] Trial 65 finished with value: 81115.86807533035 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 658, 'eta': 0.04475058745720351, 'max_depth': 4, 'min_child_weight': 18.039989198827985, 'subsample': 0.5678403525491831, 'colsample_bytree': 0.09220641840595034, 'lambda': 233.73373143995457, 'alpha': 0.015237553217979597, 'model_threshold': 384, 'ext_col_threshold': 530, 'accident_threshold': 294, 'clean_title_threshold': 832, 'body_style_threshold': 307, 'engine_threshold': 676, 'fuel_type_threshold': 561, 'int_col_threshold': 852, 'brand_threshold': 457}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:54:33] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:54:35,064] Trial 66 finished with value: 81158.5073634453 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 827, 'eta': 0.47730544227293686, 'max_depth': 5, 'min_child_weight': 2.4703608747631747, 'subsample': 0.4719422687922645, 'colsample_bytree': 0.15563923298882415, 'lambda': 79.46936336663569, 'alpha': 0.00421501120430031, 'model_threshold': 466, 'ext_col_threshold': 405, 'accident_threshold': 257, 'clean_title_threshold': 622, 'body_style_threshold': 396, 'engine_threshold': 38, 'fuel_type_threshold': 510, 'int_col_threshold': 910, 'brand_threshold': 498}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:54:35] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:54:39,039] Trial 67 finished with value: 80748.10484254875 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 719, 'eta': 0.10941987590860056, 'max_depth': 5, 'min_child_weight': 0.5668448888593631, 'subsample': 0.7030722996603685, 'colsample_bytree': 0.21738640680385768, 'lambda': 692.042870913579, 'alpha': 0.000553856861702616, 'model_threshold': 373, 'ext_col_threshold': 330, 'accident_threshold': 55, 'clean_title_threshold': 731, 'body_style_threshold': 332, 'engine_threshold': 126, 'fuel_type_threshold': 624, 'int_col_threshold': 796, 'brand_threshold': 594}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:54:39] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:54:48,184] Trial 68 finished with value: 80689.31418232534 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 756, 'eta': 0.02825287233920549, 'max_depth': 5, 'min_child_weight': 0.1862795152898129, 'subsample': 0.5358291760923621, 'colsample_bytree': 0.25355135575395327, 'lambda': 920.7259333610565, 'alpha': 0.00022308016758037567, 'model_threshold': 338, 'ext_col_threshold': 471, 'accident_threshold': 219, 'clean_title_threshold': 783, 'body_style_threshold': 274, 'engine_threshold': 74, 'fuel_type_threshold': 433, 'int_col_threshold': 952, 'brand_threshold': 641}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:54:48] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:54:49,992] Trial 69 finished with value: 80795.20857584843 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 930, 'eta': 0.18502686944847369, 'max_depth': 6, 'min_child_weight': 7.218084341242419, 'subsample': 0.5909842385852491, 'colsample_bytree': 0.29547282452232204, 'lambda': 194.78118975007945, 'alpha': 0.010727470335993926, 'model_threshold': 634, 'ext_col_threshold': 273, 'accident_threshold': 333, 'clean_title_threshold': 712, 'body_style_threshold': 841, 'engine_threshold': 107, 'fuel_type_threshold': 672, 'int_col_threshold': 963, 'brand_threshold': 561}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:54:50] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:55:07,423] Trial 70 finished with value: 81011.40996095038 and parameters: {'include_mileage': 1, 'include_msrp': 0, 'n_estimators': 991, 'eta': 0.016374131651437997, 'max_depth': 4, 'min_child_weight': 40.700075323929966, 'subsample': 0.10958018964610738, 'colsample_bytree': 0.18650101148959794, 'lambda': 341.1898845345709, 'alpha': 0.0021571159008605934, 'model_threshold': 237, 'ext_col_threshold': 369, 'accident_threshold': 164, 'clean_title_threshold': 144, 'body_style_threshold': 368, 'engine_threshold': 31, 'fuel_type_threshold': 734, 'int_col_threshold': 907, 'brand_threshold': 684}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:55:07] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:55:17,989] Trial 71 finished with value: 80697.16293900585 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 555, 'eta': 0.04135158082938257, 'max_depth': 6, 'min_child_weight': 12.545352608906402, 'subsample': 0.62301689517558, 'colsample_bytree': 0.12837223463865463, 'lambda': 511.6572187213858, 'alpha': 0.0007797089780689851, 'model_threshold': 345, 'ext_col_threshold': 410, 'accident_threshold': 268, 'clean_title_threshold': 669, 'body_style_threshold': 639, 'engine_threshold': 68, 'fuel_type_threshold': 490, 'int_col_threshold': 865, 'brand_threshold': 521}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:55:18] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:55:21,112] Trial 72 finished with value: 80713.58031615523 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 698, 'eta': 0.07952422922652966, 'max_depth': 6, 'min_child_weight': 1.5247723250780147, 'subsample': 0.6694126997135378, 'colsample_bytree': 0.33649770247760746, 'lambda': 117.23383756941425, 'alpha': 0.0012832194590489045, 'model_threshold': 308, 'ext_col_threshold': 421, 'accident_threshold': 309, 'clean_title_threshold': 580, 'body_style_threshold': 225, 'engine_threshold': 177, 'fuel_type_threshold': 555, 'int_col_threshold': 962, 'brand_threshold': 471}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:55:21] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:55:25,033] Trial 73 finished with value: 80685.83921418861 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 649, 'eta': 0.057110405068079385, 'max_depth': 6, 'min_child_weight': 0.30511304790951255, 'subsample': 0.494093547312856, 'colsample_bytree': 0.3714297183555341, 'lambda': 89.12964902961377, 'alpha': 0.0016897274175683842, 'model_threshold': 421, 'ext_col_threshold': 467, 'accident_threshold': 214, 'clean_title_threshold': 659, 'body_style_threshold': 191, 'engine_threshold': 126, 'fuel_type_threshold': 438, 'int_col_threshold': 999, 'brand_threshold': 587}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:55:25] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:55:27,982] Trial 74 finished with value: 80712.35842410382 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 506, 'eta': 0.12736650518563075, 'max_depth': 6, 'min_child_weight': 3.4003246392541793, 'subsample': 0.7501375904200449, 'colsample_bytree': 0.2876112808890002, 'lambda': 291.5300825565461, 'alpha': 0.0009560779922086391, 'model_threshold': 180, 'ext_col_threshold': 563, 'accident_threshold': 354, 'clean_title_threshold': 697, 'body_style_threshold': 299, 'engine_threshold': 101, 'fuel_type_threshold': 396, 'int_col_threshold': 669, 'brand_threshold': 434}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:55:28] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:55:33,362] Trial 75 finished with value: 80633.70565551089 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 896, 'eta': 0.0311201470319374, 'max_depth': 5, 'min_child_weight': 0.6634009030831427, 'subsample': 0.7833718889378204, 'colsample_bytree': 0.3219241328421281, 'lambda': 42.98157858361979, 'alpha': 0.7420898289634952, 'model_threshold': 445, 'ext_col_threshold': 518, 'accident_threshold': 114, 'clean_title_threshold': 733, 'body_style_threshold': 470, 'engine_threshold': 47, 'fuel_type_threshold': 525, 'int_col_threshold': 916, 'brand_threshold': 541}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:55:33] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:55:38,997] Trial 76 finished with value: 80636.51759259382 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 796, 'eta': 0.020050293628260163, 'max_depth': 5, 'min_child_weight': 0.9496251805525344, 'subsample': 0.7112774979663788, 'colsample_bytree': 0.32632565663663393, 'lambda': 45.25730232563219, 'alpha': 3.1488798260308086, 'model_threshold': 488, 'ext_col_threshold': 517, 'accident_threshold': 123, 'clean_title_threshold': 745, 'body_style_threshold': 456, 'engine_threshold': 55, 'fuel_type_threshold': 592, 'int_col_threshold': 744, 'brand_threshold': 544}. Best is trial 45 with value: 80631.03843864669.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:55:39] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:55:46,483] Trial 77 finished with value: 80616.71108180642 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 846, 'eta': 0.020153559747057497, 'max_depth': 5, 'min_child_weight': 0.8702612706311004, 'subsample': 0.7919488658447335, 'colsample_bytree': 0.31920351043035605, 'lambda': 41.88203742035941, 'alpha': 2.8236623457245087, 'model_threshold': 480, 'ext_col_threshold': 507, 'accident_threshold': 114, 'clean_title_threshold': 756, 'body_style_threshold': 534, 'engine_threshold': 48, 'fuel_type_threshold': 604, 'int_col_threshold': 818, 'brand_threshold': 541}. Best is trial 77 with value: 80616.71108180642.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:55:46] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:55:52,298] Trial 78 finished with value: 80648.30381366251 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 844, 'eta': 0.018824984522706492, 'max_depth': 5, 'min_child_weight': 0.5939977786175118, 'subsample': 0.7990841968781178, 'colsample_bytree': 0.3183193659878342, 'lambda': 41.526534274446114, 'alpha': 2.3934323435735676, 'model_threshold': 487, 'ext_col_threshold': 509, 'accident_threshold': 39, 'clean_title_threshold': 761, 'body_style_threshold': 553, 'engine_threshold': 44, 'fuel_type_threshold': 587, 'int_col_threshold': 734, 'brand_threshold': 621}. Best is trial 77 with value: 80616.71108180642.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:55:52] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:56:00,978] Trial 79 finished with value: 80603.61828831786 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 887, 'eta': 0.013923770740898107, 'max_depth': 5, 'min_child_weight': 0.2947154197858793, 'subsample': 0.8584602483120563, 'colsample_bytree': 0.32173253739034946, 'lambda': 45.1733781685951, 'alpha': 3.473755637351466, 'model_threshold': 549, 'ext_col_threshold': 509, 'accident_threshold': 40, 'clean_title_threshold': 804, 'body_style_threshold': 539, 'engine_threshold': 51, 'fuel_type_threshold': 596, 'int_col_threshold': 745, 'brand_threshold': 629}. Best is trial 79 with value: 80603.61828831786.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:56:01] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:56:05,099] Trial 80 finished with value: 81728.48647143113 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 911, 'eta': 0.020792387218872284, 'max_depth': 5, 'min_child_weight': 0.12227892359427918, 'subsample': 0.8569147804250754, 'colsample_bytree': 0.3316202385809638, 'lambda': 37.9722905871435, 'alpha': 2.2752772167329405, 'model_threshold': 556, 'ext_col_threshold': 508, 'accident_threshold': 34, 'clean_title_threshold': 800, 'body_style_threshold': 555, 'engine_threshold': 4, 'fuel_type_threshold': 667, 'int_col_threshold': 754, 'brand_threshold': 734}. Best is trial 79 with value: 80603.61828831786.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:56:05] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:56:09,738] Trial 81 finished with value: 80628.01431903754 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 884, 'eta': 0.03005563317822039, 'max_depth': 5, 'min_child_weight': 0.2625596155047046, 'subsample': 0.7194810459620921, 'colsample_bytree': 0.3128253018571785, 'lambda': 51.84730710076516, 'alpha': 4.81369763324532, 'model_threshold': 488, 'ext_col_threshold': 611, 'accident_threshold': 115, 'clean_title_threshold': 872, 'body_style_threshold': 508, 'engine_threshold': 52, 'fuel_type_threshold': 605, 'int_col_threshold': 740, 'brand_threshold': 637}. Best is trial 79 with value: 80603.61828831786.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:56:10] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:56:14,551] Trial 82 finished with value: 80627.55198449836 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 884, 'eta': 0.030331176818894048, 'max_depth': 5, 'min_child_weight': 0.25848707630970486, 'subsample': 0.7807100441871228, 'colsample_bytree': 0.3004304041035381, 'lambda': 22.23676973487486, 'alpha': 4.640282882545477, 'model_threshold': 493, 'ext_col_threshold': 593, 'accident_threshold': 111, 'clean_title_threshold': 895, 'body_style_threshold': 500, 'engine_threshold': 55, 'fuel_type_threshold': 586, 'int_col_threshold': 700, 'brand_threshold': 626}. Best is trial 79 with value: 80603.61828831786.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:56:14] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:56:23,484] Trial 83 finished with value: 80653.83572217671 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 889, 'eta': 0.012764576749409347, 'max_depth': 5, 'min_child_weight': 0.37389539038310954, 'subsample': 0.775688751884525, 'colsample_bytree': 0.316436258806216, 'lambda': 50.09507081923608, 'alpha': 6.377839082462376, 'model_threshold': 491, 'ext_col_threshold': 610, 'accident_threshold': 111, 'clean_title_threshold': 897, 'body_style_threshold': 501, 'engine_threshold': 74, 'fuel_type_threshold': 592, 'int_col_threshold': 688, 'brand_threshold': 629}. Best is trial 79 with value: 80603.61828831786.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:56:23] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:56:32,032] Trial 84 finished with value: 80646.63672486531 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 811, 'eta': 0.014680034838845533, 'max_depth': 5, 'min_child_weight': 0.2724831401014859, 'subsample': 0.783942367952915, 'colsample_bytree': 0.3847502503245329, 'lambda': 52.78534054207756, 'alpha': 6.710447636722231, 'model_threshold': 500, 'ext_col_threshold': 593, 'accident_threshold': 115, 'clean_title_threshold': 883, 'body_style_threshold': 616, 'engine_threshold': 76, 'fuel_type_threshold': 594, 'int_col_threshold': 700, 'brand_threshold': 630}. Best is trial 79 with value: 80603.61828831786.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:56:32] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:56:35,658] Trial 85 finished with value: 80683.27672743531 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 799, 'eta': 0.02780905152450722, 'max_depth': 5, 'min_child_weight': 0.07507305932447278, 'subsample': 0.7943188522835649, 'colsample_bytree': 0.41364455934961797, 'lambda': 23.631765276326217, 'alpha': 3.6058930489982957, 'model_threshold': 552, 'ext_col_threshold': 639, 'accident_threshold': 65, 'clean_title_threshold': 931, 'body_style_threshold': 617, 'engine_threshold': 28, 'fuel_type_threshold': 644, 'int_col_threshold': 733, 'brand_threshold': 783}. Best is trial 79 with value: 80603.61828831786.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:56:35] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:56:44,572] Trial 86 finished with value: 80875.7598614148 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 854, 'eta': 0.014218054887769, 'max_depth': 5, 'min_child_weight': 0.2233874058156097, 'subsample': 0.8289519927514314, 'colsample_bytree': 0.38565633169195235, 'lambda': 31.873483879493747, 'alpha': 9.575877870362879, 'model_threshold': 620, 'ext_col_threshold': 585, 'accident_threshold': 2, 'clean_title_threshold': 867, 'body_style_threshold': 668, 'engine_threshold': 582, 'fuel_type_threshold': 589, 'int_col_threshold': 629, 'brand_threshold': 665}. Best is trial 79 with value: 80603.61828831786.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:56:44] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:56:50,752] Trial 87 finished with value: 81641.4846713083 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 959, 'eta': 0.007932487428260427, 'max_depth': 5, 'min_child_weight': 0.14454129449337885, 'subsample': 0.7191984310133174, 'colsample_bytree': 0.3592994214588333, 'lambda': 18.854165494552714, 'alpha': 0.6244943412935544, 'model_threshold': 479, 'ext_col_threshold': 726, 'accident_threshold': 38, 'clean_title_threshold': 977, 'body_style_threshold': 530, 'engine_threshold': 17, 'fuel_type_threshold': 621, 'int_col_threshold': 699, 'brand_threshold': 542}. Best is trial 79 with value: 80603.61828831786.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:56:51] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:56:58,907] Trial 88 finished with value: 80628.02572073117 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 857, 'eta': 0.01842559732110579, 'max_depth': 5, 'min_child_weight': 0.5714904880387395, 'subsample': 0.8480396957017563, 'colsample_bytree': 0.2835033905991659, 'lambda': 46.709440951850674, 'alpha': 1.939644812978357, 'model_threshold': 513, 'ext_col_threshold': 514, 'accident_threshold': 107, 'clean_title_threshold': 884, 'body_style_threshold': 457, 'engine_threshold': 71, 'fuel_type_threshold': 719, 'int_col_threshold': 747, 'brand_threshold': 827}. Best is trial 79 with value: 80603.61828831786.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:56:59] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:57:14,370] Trial 89 finished with value: 80606.81442486073 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 889, 'eta': 0.00969985418957354, 'max_depth': 5, 'min_child_weight': 0.2104583527757778, 'subsample': 0.860649889884557, 'colsample_bytree': 0.28280056053753627, 'lambda': 60.554416620992384, 'alpha': 0.8984576291587287, 'model_threshold': 445, 'ext_col_threshold': 537, 'accident_threshold': 107, 'clean_title_threshold': 957, 'body_style_threshold': 481, 'engine_threshold': 82, 'fuel_type_threshold': 805, 'int_col_threshold': 803, 'brand_threshold': 824}. Best is trial 79 with value: 80603.61828831786.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:57:14] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:57:22,386] Trial 90 finished with value: 80770.13781839584 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1034, 'eta': 0.010942800907582154, 'max_depth': 5, 'min_child_weight': 0.46511382950973057, 'subsample': 0.8855301637301867, 'colsample_bytree': 0.8912578124889531, 'lambda': 67.32507139119052, 'alpha': 1.5262679830937902, 'model_threshold': 449, 'ext_col_threshold': 542, 'accident_threshold': 93, 'clean_title_threshold': 942, 'body_style_threshold': 458, 'engine_threshold': 63, 'fuel_type_threshold': 803, 'int_col_threshold': 815, 'brand_threshold': 841}. Best is trial 79 with value: 80603.61828831786.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:57:22] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:57:28,115] Trial 91 finished with value: 80603.53857078736 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 897, 'eta': 0.031978780152676835, 'max_depth': 5, 'min_child_weight': 0.20982150132117733, 'subsample': 0.8484423570422006, 'colsample_bytree': 0.281786729773395, 'lambda': 50.542865932297715, 'alpha': 0.8208682761556839, 'model_threshold': 515, 'ext_col_threshold': 676, 'accident_threshold': 117, 'clean_title_threshold': 888, 'body_style_threshold': 481, 'engine_threshold': 81, 'fuel_type_threshold': 694, 'int_col_threshold': 759, 'brand_threshold': 941}. Best is trial 91 with value: 80603.53857078736.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:57:28] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:57:33,511] Trial 92 finished with value: 80621.89298820302 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 884, 'eta': 0.032710556425053064, 'max_depth': 5, 'min_child_weight': 0.11042954058551475, 'subsample': 0.9477231375384925, 'colsample_bytree': 0.27919322093778454, 'lambda': 29.475273204697114, 'alpha': 0.8294288985006524, 'model_threshold': 540, 'ext_col_threshold': 676, 'accident_threshold': 166, 'clean_title_threshold': 970, 'body_style_threshold': 479, 'engine_threshold': 86, 'fuel_type_threshold': 809, 'int_col_threshold': 755, 'brand_threshold': 959}. Best is trial 91 with value: 80603.53857078736.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:57:33] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:57:41,224] Trial 93 finished with value: 80663.10383975724 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 877, 'eta': 0.03278645144678183, 'max_depth': 4, 'min_child_weight': 0.09110229385397803, 'subsample': 0.9509173353608151, 'colsample_bytree': 0.27009854862467136, 'lambda': 18.932512177796497, 'alpha': 0.8369906821756263, 'model_threshold': 578, 'ext_col_threshold': 687, 'accident_threshold': 177, 'clean_title_threshold': 975, 'body_style_threshold': 488, 'engine_threshold': 137, 'fuel_type_threshold': 798, 'int_col_threshold': 786, 'brand_threshold': 895}. Best is trial 91 with value: 80603.53857078736.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:57:41] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:57:46,118] Trial 94 finished with value: 81237.46285106451 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 951, 'eta': 0.024794022471256658, 'max_depth': 5, 'min_child_weight': 0.1330487131145397, 'subsample': 0.8548073669481051, 'colsample_bytree': 0.2782915989886056, 'lambda': 32.17422915762693, 'alpha': 0.34126970041046506, 'model_threshold': 534, 'ext_col_threshold': 637, 'accident_threshold': 144, 'clean_title_threshold': 953, 'body_style_threshold': 522, 'engine_threshold': 26, 'fuel_type_threshold': 835, 'int_col_threshold': 762, 'brand_threshold': 938}. Best is trial 91 with value: 80603.53857078736.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:57:46] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:58:01,893] Trial 95 finished with value: 80638.84748870043 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 898, 'eta': 0.009541952554248698, 'max_depth': 5, 'min_child_weight': 0.03286581095556724, 'subsample': 0.9087410556027075, 'colsample_bytree': 0.2332328061894169, 'lambda': 27.47092239674699, 'alpha': 1.7502313948518546, 'model_threshold': 638, 'ext_col_threshold': 740, 'accident_threshold': 107, 'clean_title_threshold': 913, 'body_style_threshold': 476, 'engine_threshold': 86, 'fuel_type_threshold': 920, 'int_col_threshold': 799, 'brand_threshold': 970}. Best is trial 91 with value: 80603.53857078736.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:58:02] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:58:06,327] Trial 96 finished with value: 80696.13105769648 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 853, 'eta': 0.02432202306523842, 'max_depth': 5, 'min_child_weight': 0.17765596464630037, 'subsample': 0.8128464732005528, 'colsample_bytree': 0.3532906696721788, 'lambda': 12.568553860962162, 'alpha': 0.2440689393412222, 'model_threshold': 520, 'ext_col_threshold': 662, 'accident_threshold': 78, 'clean_title_threshold': 850, 'body_style_threshold': 574, 'engine_threshold': 140, 'fuel_type_threshold': 749, 'int_col_threshold': 673, 'brand_threshold': 824}. Best is trial 91 with value: 80603.53857078736.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:58:06] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:58:12,991] Trial 97 finished with value: 80657.44153701575 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 975, 'eta': 0.03256774163393581, 'max_depth': 5, 'min_child_weight': 0.3412574582971535, 'subsample': 0.8720119725102271, 'colsample_bytree': 0.2946039227648208, 'lambda': 64.21529675308349, 'alpha': 4.652569514487831, 'model_threshold': 447, 'ext_col_threshold': 571, 'accident_threshold': 149, 'clean_title_threshold': 820, 'body_style_threshold': 430, 'engine_threshold': 190, 'fuel_type_threshold': 712, 'int_col_threshold': 830, 'brand_threshold': 911}. Best is trial 91 with value: 80603.53857078736.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:58:13] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:58:18,878] Trial 98 finished with value: 80765.43754145925 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 935, 'eta': 0.016296742324526686, 'max_depth': 5, 'min_child_weight': 0.05358017270466696, 'subsample': 0.993534396052894, 'colsample_bytree': 0.69875837380826, 'lambda': 36.46951789249214, 'alpha': 0.9095107983586576, 'model_threshold': 574, 'ext_col_threshold': 537, 'accident_threshold': 59, 'clean_title_threshold': 879, 'body_style_threshold': 552, 'engine_threshold': 86, 'fuel_type_threshold': 768, 'int_col_threshold': 644, 'brand_threshold': 887}. Best is trial 91 with value: 80603.53857078736.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:58:19] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:58:23,656] Trial 99 finished with value: 80742.13626044925 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 902, 'eta': 0.05287927821366588, 'max_depth': 5, 'min_child_weight': 0.1101000788641894, 'subsample': 0.8439390500472758, 'colsample_bytree': 0.28127027456232245, 'lambda': 93.64473950626864, 'alpha': 0.5026275519914355, 'model_threshold': 530, 'ext_col_threshold': 750, 'accident_threshold': 170, 'clean_title_threshold': 970, 'body_style_threshold': 442, 'engine_threshold': 117, 'fuel_type_threshold': 827, 'int_col_threshold': 600, 'brand_threshold': 930}. Best is trial 91 with value: 80603.53857078736.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:58:23] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:58:27,355] Trial 100 finished with value: 80755.80303919368 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1017, 'eta': 0.030682801622469467, 'max_depth': 4, 'min_child_weight': 0.6939524501426912, 'subsample': 0.9427436238849326, 'colsample_bytree': 0.41884581760805034, 'lambda': 14.98739141185247, 'alpha': 11.744793657912188, 'model_threshold': 613, 'ext_col_threshold': 698, 'accident_threshold': 29, 'clean_title_threshold': 925, 'body_style_threshold': 516, 'engine_threshold': 163, 'fuel_type_threshold': 703, 'int_col_threshold': 717, 'brand_threshold': 976}. Best is trial 91 with value: 80603.53857078736.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:58:27] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:58:34,080] Trial 101 finished with value: 80586.68993611912 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 856, 'eta': 0.022894639908677353, 'max_depth': 5, 'min_child_weight': 0.2322716442581635, 'subsample': 0.8959878713507597, 'colsample_bytree': 0.3367506804636125, 'lambda': 48.41556500128672, 'alpha': 3.099202142653374, 'model_threshold': 507, 'ext_col_threshold': 519, 'accident_threshold': 127, 'clean_title_threshold': 842, 'body_style_threshold': 455, 'engine_threshold': 54, 'fuel_type_threshold': 653, 'int_col_threshold': 743, 'brand_threshold': 956}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:58:34] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:58:37,955] Trial 102 finished with value: 81558.46367392039 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 866, 'eta': 0.023296384658564054, 'max_depth': 5, 'min_child_weight': 0.23078081774235262, 'subsample': 0.8925162368013726, 'colsample_bytree': 0.29696262708284266, 'lambda': 52.77494394745996, 'alpha': 1.2450685563935782, 'model_threshold': 548, 'ext_col_threshold': 627, 'accident_threshold': 99, 'clean_title_threshold': 848, 'body_style_threshold': 489, 'engine_threshold': 20, 'fuel_type_threshold': 666, 'int_col_threshold': 777, 'brand_threshold': 957}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:58:38] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:58:46,508] Trial 103 finished with value: 80631.94201338757 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 834, 'eta': 0.012688769702420704, 'max_depth': 5, 'min_child_weight': 0.4347104319338901, 'subsample': 0.7583014975359238, 'colsample_bytree': 0.342802208240752, 'lambda': 22.276481229663673, 'alpha': 1.9526849191817721, 'model_threshold': 663, 'ext_col_threshold': 544, 'accident_threshold': 74, 'clean_title_threshold': 898, 'body_style_threshold': 413, 'engine_threshold': 54, 'fuel_type_threshold': 723, 'int_col_threshold': 722, 'brand_threshold': 875}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:58:46] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:58:52,552] Trial 104 finished with value: 81465.64049900103 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 825, 'eta': 0.0113502793577199, 'max_depth': 5, 'min_child_weight': 0.4221728801899132, 'subsample': 0.8230305303798536, 'colsample_bytree': 0.34499655300229354, 'lambda': 73.21106058625237, 'alpha': 2.864711728526243, 'model_threshold': 766, 'ext_col_threshold': 585, 'accident_threshold': 72, 'clean_title_threshold': 900, 'body_style_threshold': 408, 'engine_threshold': 1, 'fuel_type_threshold': 722, 'int_col_threshold': 723, 'brand_threshold': 859}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:58:52] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:59:01,057] Trial 105 finished with value: 80638.16025499633 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 775, 'eta': 0.014883354565142145, 'max_depth': 5, 'min_child_weight': 0.15791894762175437, 'subsample': 0.8684728695728384, 'colsample_bytree': 0.24414226457132243, 'lambda': 21.7950523700009, 'alpha': 1.9178196090496766, 'model_threshold': 713, 'ext_col_threshold': 553, 'accident_threshold': 142, 'clean_title_threshold': 992, 'body_style_threshold': 577, 'engine_threshold': 66, 'fuel_type_threshold': 854, 'int_col_threshold': 753, 'brand_threshold': 878}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:59:01] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:59:13,907] Trial 106 finished with value: 80626.63037482006 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 932, 'eta': 0.008801873426449289, 'max_depth': 5, 'min_child_weight': 0.07621854291706279, 'subsample': 0.7576412147895062, 'colsample_bytree': 0.36581380372589106, 'lambda': 27.224095864692384, 'alpha': 4.402501792384139, 'model_threshold': 679, 'ext_col_threshold': 489, 'accident_threshold': 15, 'clean_title_threshold': 940, 'body_style_threshold': 537, 'engine_threshold': 90, 'fuel_type_threshold': 778, 'int_col_threshold': 689, 'brand_threshold': 948}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:59:14] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:59:24,954] Trial 107 finished with value: 80688.7160368957 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 930, 'eta': 0.0078116471075792525, 'max_depth': 5, 'min_child_weight': 0.0608209778856033, 'subsample': 0.9654473775364772, 'colsample_bytree': 0.377710888218876, 'lambda': 10.56904683098269, 'alpha': 4.556605291496704, 'model_threshold': 581, 'ext_col_threshold': 489, 'accident_threshold': 8, 'clean_title_threshold': 826, 'body_style_threshold': 535, 'engine_threshold': 91, 'fuel_type_threshold': 774, 'int_col_threshold': 803, 'brand_threshold': 949}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:59:25] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:59:33,216] Trial 108 finished with value: 80650.1329377894 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 970, 'eta': 0.01929759451949638, 'max_depth': 5, 'min_child_weight': 0.023134468427808703, 'subsample': 0.9263601849483671, 'colsample_bytree': 0.21652494321562926, 'lambda': 31.09906725342539, 'alpha': 17.590021032963808, 'model_threshold': 785, 'ext_col_threshold': 447, 'accident_threshold': 51, 'clean_title_threshold': 949, 'body_style_threshold': 605, 'engine_threshold': 110, 'fuel_type_threshold': 935, 'int_col_threshold': 687, 'brand_threshold': 803}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:59:33] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 19:59:47,886] Trial 109 finished with value: 80675.88717163987 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 870, 'eta': 0.008974491244455353, 'max_depth': 5, 'min_child_weight': 0.09828168084585401, 'subsample': 0.8960527118444013, 'colsample_bytree': 0.2618550160047348, 'lambda': 27.58548818040888, 'alpha': 5.588231980132919, 'model_threshold': 512, 'ext_col_threshold': 603, 'accident_threshold': 88, 'clean_title_threshold': 871, 'body_style_threshold': 496, 'engine_threshold': 150, 'fuel_type_threshold': 690, 'int_col_threshold': 656, 'brand_threshold': 744}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:59:48] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:00:09,872] Trial 110 finished with value: 80835.13727757016 and parameters: {'include_mileage': 1, 'include_msrp': 0, 'n_estimators': 939, 'eta': 0.004558689941623876, 'max_depth': 5, 'min_child_weight': 0.03767173511706561, 'subsample': 0.745148654561049, 'colsample_bytree': 0.3048670772401297, 'lambda': 15.739273571689116, 'alpha': 9.403064087017334, 'model_threshold': 469, 'ext_col_threshold': 665, 'accident_threshold': 23, 'clean_title_threshold': 932, 'body_style_threshold': 446, 'engine_threshold': 209, 'fuel_type_threshold': 748, 'int_col_threshold': 777, 'brand_threshold': 912}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:00:10] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:00:15,946] Trial 111 finished with value: 81396.13891092423 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 841, 'eta': 0.012360526566713655, 'max_depth': 5, 'min_child_weight': 0.23453912679183214, 'subsample': 0.7623020193054585, 'colsample_bytree': 0.34898060120823493, 'lambda': 34.953222857966196, 'alpha': 1.0716811558380204, 'model_threshold': 680, 'ext_col_threshold': 491, 'accident_threshold': 128, 'clean_title_threshold': 910, 'body_style_threshold': 411, 'engine_threshold': 25, 'fuel_type_threshold': 688, 'int_col_threshold': 836, 'brand_threshold': 993}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:00:16] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:00:19,490] Trial 112 finished with value: 80626.24913605399 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 905, 'eta': 0.03583446262168458, 'max_depth': 5, 'min_child_weight': 0.072939998199552, 'subsample': 0.812498270968933, 'colsample_bytree': 0.3649137739091013, 'lambda': 20.366669329915272, 'alpha': 0.4782778417946312, 'model_threshold': 673, 'ext_col_threshold': 579, 'accident_threshold': 64, 'clean_title_threshold': 839, 'body_style_threshold': 542, 'engine_threshold': 76, 'fuel_type_threshold': 647, 'int_col_threshold': 740, 'brand_threshold': 872}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:00:19] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:00:26,228] Trial 113 finished with value: 80630.22618087135 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 917, 'eta': 0.021497979227848876, 'max_depth': 5, 'min_child_weight': 0.08213941265611963, 'subsample': 0.853839036257331, 'colsample_bytree': 0.4090174653416926, 'lambda': 57.696110083113616, 'alpha': 3.5998911155071904, 'model_threshold': 719, 'ext_col_threshold': 576, 'accident_threshold': 53, 'clean_title_threshold': 804, 'body_style_threshold': 534, 'engine_threshold': 84, 'fuel_type_threshold': 645, 'int_col_threshold': 772, 'brand_threshold': 853}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:00:26] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:00:29,494] Trial 114 finished with value: 80747.00967591995 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 884, 'eta': 0.038032340397905415, 'max_depth': 5, 'min_child_weight': 0.0852278771718962, 'subsample': 0.8537340200938643, 'colsample_bytree': 0.3999067320221371, 'lambda': 60.82558235343855, 'alpha': 0.46148220311316046, 'model_threshold': 793, 'ext_col_threshold': 620, 'accident_threshold': 20, 'clean_title_threshold': 793, 'body_style_threshold': 543, 'engine_threshold': 124, 'fuel_type_threshold': 639, 'int_col_threshold': 750, 'brand_threshold': 823}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:00:29] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:00:32,768] Trial 115 finished with value: 80641.12133786062 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1012, 'eta': 0.04717000901765485, 'max_depth': 5, 'min_child_weight': 0.01901183018832864, 'subsample': 0.8139189398443006, 'colsample_bytree': 0.36587864313364804, 'lambda': 48.44181659601885, 'alpha': 4.502226742451805, 'model_threshold': 724, 'ext_col_threshold': 577, 'accident_threshold': 92, 'clean_title_threshold': 857, 'body_style_threshold': 588, 'engine_threshold': 84, 'fuel_type_threshold': 662, 'int_col_threshold': 804, 'brand_threshold': 853}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:00:33] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:00:40,452] Trial 116 finished with value: 80823.87856491802 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 914, 'eta': 0.028145946760063132, 'max_depth': 5, 'min_child_weight': 0.06335272255726668, 'subsample': 0.8379097822449119, 'colsample_bytree': 0.2706780229859443, 'lambda': 103.1822124555198, 'alpha': 1.2961163199202164, 'model_threshold': 674, 'ext_col_threshold': 661, 'accident_threshold': 53, 'clean_title_threshold': 810, 'body_style_threshold': 517, 'engine_threshold': 478, 'fuel_type_threshold': 618, 'int_col_threshold': 775, 'brand_threshold': 931}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:00:40] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:00:43,595] Trial 117 finished with value: 80729.49073977464 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 167, 'eta': 0.03541399310321957, 'max_depth': 5, 'min_child_weight': 0.2796889879743957, 'subsample': 0.9614620328363687, 'colsample_bytree': 0.4257888389277341, 'lambda': 25.827517969131215, 'alpha': 8.668215463771524, 'model_threshold': 857, 'ext_col_threshold': 556, 'accident_threshold': 154, 'clean_title_threshold': 836, 'body_style_threshold': 480, 'engine_threshold': 110, 'fuel_type_threshold': 759, 'int_col_threshold': 761, 'brand_threshold': 776}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:00:43] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:00:51,721] Trial 118 finished with value: 80897.5968116019 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 1052, 'eta': 0.0170221169293463, 'max_depth': 5, 'min_child_weight': 0.17286598350875296, 'subsample': 0.8800032662629522, 'colsample_bytree': 0.3276174520592827, 'lambda': 76.90904975605613, 'alpha': 2.730123771805931, 'model_threshold': 652, 'ext_col_threshold': 604, 'accident_threshold': 180, 'clean_title_threshold': 958, 'body_style_threshold': 643, 'engine_threshold': 921, 'fuel_type_threshold': 656, 'int_col_threshold': 679, 'brand_threshold': 970}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:00:52] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:00:59,860] Trial 119 finished with value: 80608.91856857194 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 866, 'eta': 0.023393939676587077, 'max_depth': 5, 'min_child_weight': 0.13411249921432505, 'subsample': 0.9092668120665828, 'colsample_bytree': 0.30407269222858707, 'lambda': 40.82086897638197, 'alpha': 34.03065555043042, 'model_threshold': 736, 'ext_col_threshold': 522, 'accident_threshold': 49, 'clean_title_threshold': 878, 'body_style_threshold': 558, 'engine_threshold': 60, 'fuel_type_threshold': 790, 'int_col_threshold': 706, 'brand_threshold': 836}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:01:00] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:01:17,486] Trial 120 finished with value: 80652.88208543009 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 808, 'eta': 0.006760073571283049, 'max_depth': 5, 'min_child_weight': 0.04683780535781977, 'subsample': 0.9070661876639499, 'colsample_bytree': 0.30380965096541684, 'lambda': 41.406147217219285, 'alpha': 35.32657315623991, 'model_threshold': 425, 'ext_col_threshold': 450, 'accident_threshold': 106, 'clean_title_threshold': 891, 'body_style_threshold': 565, 'engine_threshold': 70, 'fuel_type_threshold': 792, 'int_col_threshold': 707, 'brand_threshold': 905}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:01:17] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:01:25,538] Trial 121 finished with value: 80634.8117596733 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 865, 'eta': 0.022096809697412324, 'max_depth': 5, 'min_child_weight': 0.13966085599046543, 'subsample': 0.8087221024958542, 'colsample_bytree': 0.28792590313106503, 'lambda': 61.45826389794279, 'alpha': 0.6892770332324513, 'model_threshold': 704, 'ext_col_threshold': 502, 'accident_threshold': 47, 'clean_title_threshold': 874, 'body_style_threshold': 508, 'engine_threshold': 93, 'fuel_type_threshold': 812, 'int_col_threshold': 741, 'brand_threshold': 831}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:01:25] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:01:32,387] Trial 122 finished with value: 80649.38377147912 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 948, 'eta': 0.027964268903044143, 'max_depth': 5, 'min_child_weight': 0.1055532255412598, 'subsample': 0.9292207132598573, 'colsample_bytree': 0.24321807533442397, 'lambda': 51.96402638719699, 'alpha': 3.5656871159880104, 'model_threshold': 740, 'ext_col_threshold': 522, 'accident_threshold': 77, 'clean_title_threshold': 923, 'body_style_threshold': 537, 'engine_threshold': 32, 'fuel_type_threshold': 567, 'int_col_threshold': 732, 'brand_threshold': 803}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:01:32] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:01:39,145] Trial 123 finished with value: 80625.59111377975 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 901, 'eta': 0.01903454335759937, 'max_depth': 5, 'min_child_weight': 0.06977396845289688, 'subsample': 0.8413329985414362, 'colsample_bytree': 0.3685760051314004, 'lambda': 18.541845811895833, 'alpha': 40.246332105284665, 'model_threshold': 509, 'ext_col_threshold': 541, 'accident_threshold': 2, 'clean_title_threshold': 781, 'body_style_threshold': 469, 'engine_threshold': 61, 'fuel_type_threshold': 871, 'int_col_threshold': 633, 'brand_threshold': 776}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:01:39] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:01:44,471] Trial 124 finished with value: 80787.60821737236 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 885, 'eta': 0.017243067435827302, 'max_depth': 5, 'min_child_weight': 0.33518459263751493, 'subsample': 0.8373615222056845, 'colsample_bytree': 0.37397179384425216, 'lambda': 0.20262132441925304, 'alpha': 16.842285844731926, 'model_threshold': 827, 'ext_col_threshold': 487, 'accident_threshold': 2, 'clean_title_threshold': 841, 'body_style_threshold': 470, 'engine_threshold': 58, 'fuel_type_threshold': 874, 'int_col_threshold': 695, 'brand_threshold': 769}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:01:44] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:01:49,403] Trial 125 finished with value: 80737.98917642154 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 975, 'eta': 0.025450745562589774, 'max_depth': 5, 'min_child_weight': 0.20019519802233146, 'subsample': 0.8778685856671192, 'colsample_bytree': 0.33424882345913937, 'lambda': 8.875877719814902, 'alpha': 36.41663694046886, 'model_threshold': 535, 'ext_col_threshold': 533, 'accident_threshold': 128, 'clean_title_threshold': 777, 'body_style_threshold': 495, 'engine_threshold': 136, 'fuel_type_threshold': 827, 'int_col_threshold': 635, 'brand_threshold': 713}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:01:49] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:01:57,185] Trial 126 finished with value: 81313.91682926384 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 848, 'eta': 0.009575705880043132, 'max_depth': 5, 'min_child_weight': 0.5422251830732483, 'subsample': 0.8195251932651658, 'colsample_bytree': 0.3074366082072006, 'lambda': 20.634125088846854, 'alpha': 49.45046664189157, 'model_threshold': 504, 'ext_col_threshold': 557, 'accident_threshold': 19, 'clean_title_threshold': 965, 'body_style_threshold': 443, 'engine_threshold': 25, 'fuel_type_threshold': 917, 'int_col_threshold': 592, 'brand_threshold': 949}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:01:57] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:02:07,814] Trial 127 finished with value: 80616.327385665 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 783, 'eta': 0.014086839325992351, 'max_depth': 5, 'min_child_weight': 0.02912580871063576, 'subsample': 0.7827313547605804, 'colsample_bytree': 0.2790493950788424, 'lambda': 17.14239218904283, 'alpha': 23.939432667085367, 'model_threshold': 601, 'ext_col_threshold': 648, 'accident_threshold': 66, 'clean_title_threshold': 996, 'body_style_threshold': 584, 'engine_threshold': 65, 'fuel_type_threshold': 849, 'int_col_threshold': 664, 'brand_threshold': 997}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:02:08] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:02:20,152] Trial 128 finished with value: 80647.34429300495 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 782, 'eta': 0.014292777728656624, 'max_depth': 5, 'min_child_weight': 0.028432782031184087, 'subsample': 0.7846385613555936, 'colsample_bytree': 0.22544107439498132, 'lambda': 17.008880854556775, 'alpha': 25.122747808281094, 'model_threshold': 581, 'ext_col_threshold': 687, 'accident_threshold': 29, 'clean_title_threshold': 985, 'body_style_threshold': 597, 'engine_threshold': 110, 'fuel_type_threshold': 850, 'int_col_threshold': 663, 'brand_threshold': 997}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:02:20] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:02:23,963] Trial 129 finished with value: 80629.75168205741 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 896, 'eta': 0.0445958867990418, 'max_depth': 5, 'min_child_weight': 0.040494112560248596, 'subsample': 0.7392659226060098, 'colsample_bytree': 0.2520738203454407, 'lambda': 27.745023422524778, 'alpha': 57.780420925470374, 'model_threshold': 467, 'ext_col_threshold': 717, 'accident_threshold': 59, 'clean_title_threshold': 940, 'body_style_threshold': 563, 'engine_threshold': 42, 'fuel_type_threshold': 890, 'int_col_threshold': 616, 'brand_threshold': 917}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:02:24] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:02:27,458] Trial 130 finished with value: 80895.63335579 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 825, 'eta': 0.056632592206222014, 'max_depth': 4, 'min_child_weight': 0.017772963702225753, 'subsample': 0.689308223585194, 'colsample_bytree': 0.35415138261790546, 'lambda': 12.11366804029386, 'alpha': 82.76879953306604, 'model_threshold': 595, 'ext_col_threshold': 646, 'accident_threshold': 76, 'clean_title_threshold': 919, 'body_style_threshold': 677, 'engine_threshold': 377, 'fuel_type_threshold': 781, 'int_col_threshold': 713, 'brand_threshold': 963}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:02:27] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:02:35,913] Trial 131 finished with value: 80612.22790539189 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 871, 'eta': 0.019450740478593895, 'max_depth': 5, 'min_child_weight': 0.06816771101824126, 'subsample': 0.8648233371438996, 'colsample_bytree': 0.27888772581391197, 'lambda': 36.937557222039835, 'alpha': 13.539384948518261, 'model_threshold': 613, 'ext_col_threshold': 510, 'accident_threshold': 101, 'clean_title_threshold': 863, 'body_style_threshold': 516, 'engine_threshold': 66, 'fuel_type_threshold': 730, 'int_col_threshold': 819, 'brand_threshold': 889}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:02:36] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:02:40,009] Trial 132 finished with value: 80622.79856229911 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 869, 'eta': 0.03659699043771892, 'max_depth': 5, 'min_child_weight': 0.06703469506496906, 'subsample': 0.8007448798841748, 'colsample_bytree': 0.3186173601663751, 'lambda': 35.36770953157857, 'alpha': 21.009527794569753, 'model_threshold': 618, 'ext_col_threshold': 619, 'accident_threshold': 127, 'clean_title_threshold': 829, 'body_style_threshold': 513, 'engine_threshold': 57, 'fuel_type_threshold': 859, 'int_col_threshold': 806, 'brand_threshold': 891}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:02:40] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:02:42,851] Trial 133 finished with value: 81326.7743496384 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 920, 'eta': 0.037463407131800096, 'max_depth': 5, 'min_child_weight': 0.06455760743419384, 'subsample': 0.7971628896417909, 'colsample_bytree': 0.271844490756923, 'lambda': 34.48989704698678, 'alpha': 20.167527307240196, 'model_threshold': 633, 'ext_col_threshold': 591, 'accident_threshold': 91, 'clean_title_threshold': 995, 'body_style_threshold': 578, 'engine_threshold': 10, 'fuel_type_threshold': 961, 'int_col_threshold': 822, 'brand_threshold': 873}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:02:43] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:02:52,716] Trial 134 finished with value: 80651.1638743946 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 802, 'eta': 0.01082541865382681, 'max_depth': 5, 'min_child_weight': 0.026401385711138356, 'subsample': 0.9153101833550074, 'colsample_bytree': 0.33053140597260194, 'lambda': 18.122096462034154, 'alpha': 13.83218916575951, 'model_threshold': 697, 'ext_col_threshold': 543, 'accident_threshold': 39, 'clean_title_threshold': 833, 'body_style_threshold': 635, 'engine_threshold': 69, 'fuel_type_threshold': 863, 'int_col_threshold': 798, 'brand_threshold': 895}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:02:53] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:03:02,171] Trial 135 finished with value: 80638.98491523093 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 864, 'eta': 0.014379168010140993, 'max_depth': 5, 'min_child_weight': 0.057698819228427296, 'subsample': 0.8982719576494335, 'colsample_bytree': 0.29532919318152756, 'lambda': 24.28688609638092, 'alpha': 39.88853717622098, 'model_threshold': 606, 'ext_col_threshold': 618, 'accident_threshold': 130, 'clean_title_threshold': 858, 'body_style_threshold': 519, 'engine_threshold': 100, 'fuel_type_threshold': 818, 'int_col_threshold': 858, 'brand_threshold': 923}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:03:02] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:03:07,419] Trial 136 finished with value: 80641.23250884165 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 939, 'eta': 0.02467830825156511, 'max_depth': 5, 'min_child_weight': 0.12213002990119966, 'subsample': 0.8742248107455193, 'colsample_bytree': 0.3186306835166737, 'lambda': 36.098341650140604, 'alpha': 21.385839730614418, 'model_threshold': 561, 'ext_col_threshold': 651, 'accident_threshold': 161, 'clean_title_threshold': 953, 'body_style_threshold': 559, 'engine_threshold': 37, 'fuel_type_threshold': 893, 'int_col_threshold': 839, 'brand_threshold': 946}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:03:07] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:03:14,294] Trial 137 finished with value: 80705.0175315889 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 833, 'eta': 0.019896684219565915, 'max_depth': 5, 'min_child_weight': 0.03850883337040751, 'subsample': 0.8203067423461053, 'colsample_bytree': 0.38950264984365873, 'lambda': 28.995680343828276, 'alpha': 7.59333375351394, 'model_threshold': 620, 'ext_col_threshold': 473, 'accident_threshold': 193, 'clean_title_threshold': 813, 'body_style_threshold': 481, 'engine_threshold': 120, 'fuel_type_threshold': 837, 'int_col_threshold': 787, 'brand_threshold': 975}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:03:14] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:03:21,704] Trial 138 finished with value: 80698.21454993743 and parameters: {'include_mileage': 0, 'include_msrp': 0, 'n_estimators': 901, 'eta': 0.0349342102749911, 'max_depth': 5, 'min_child_weight': 0.06869362269765139, 'subsample': 0.9748927112191869, 'colsample_bytree': 0.1728081277027544, 'lambda': 14.198059406746431, 'alpha': 11.226506951846535, 'model_threshold': 655, 'ext_col_threshold': 684, 'accident_threshold': 79, 'clean_title_threshold': 781, 'body_style_threshold': 538, 'engine_threshold': 166, 'fuel_type_threshold': 785, 'int_col_threshold': 563, 'brand_threshold': 890}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:03:22] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:03:30,026] Trial 139 finished with value: 80599.22660603606 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 960, 'eta': 0.01666753816841048, 'max_depth': 5, 'min_child_weight': 0.18230771709303517, 'subsample': 0.9459136132134236, 'colsample_bytree': 0.370279379765818, 'lambda': 41.29172698192844, 'alpha': 26.278802613589743, 'model_threshold': 536, 'ext_col_threshold': 505, 'accident_threshold': 65, 'clean_title_threshold': 893, 'body_style_threshold': 500, 'engine_threshold': 58, 'fuel_type_threshold': 736, 'int_col_threshold': 881, 'brand_threshold': 935}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:03:30] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:03:34,454] Trial 140 finished with value: 81551.64252683287 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 957, 'eta': 0.016797669884607746, 'max_depth': 5, 'min_child_weight': 0.008608375930145951, 'subsample': 0.945677146290408, 'colsample_bytree': 0.3616444214733361, 'lambda': 41.09534935851882, 'alpha': 29.930063679091365, 'model_threshold': 644, 'ext_col_threshold': 503, 'accident_threshold': 16, 'clean_title_threshold': 999, 'body_style_threshold': 466, 'engine_threshold': 1, 'fuel_type_threshold': 741, 'int_col_threshold': 870, 'brand_threshold': 1000}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:03:34] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:03:40,713] Trial 141 finished with value: 80610.72671752574 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 992, 'eta': 0.021193765343718408, 'max_depth': 5, 'min_child_weight': 0.16426707874894986, 'subsample': 0.9307305155178174, 'colsample_bytree': 0.3395818137700576, 'lambda': 39.06342189906111, 'alpha': 43.46394328330151, 'model_threshold': 541, 'ext_col_threshold': 523, 'accident_threshold': 42, 'clean_title_threshold': 913, 'body_style_threshold': 501, 'engine_threshold': 54, 'fuel_type_threshold': 681, 'int_col_threshold': 820, 'brand_threshold': 934}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:03:41] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:03:57,833] Trial 142 finished with value: 80610.47343565745 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1002, 'eta': 0.013618762480586273, 'max_depth': 5, 'min_child_weight': 0.10092065856713556, 'subsample': 0.9952641932321609, 'colsample_bytree': 0.3383067807548797, 'lambda': 42.32327832236189, 'alpha': 44.60110860055675, 'model_threshold': 546, 'ext_col_threshold': 527, 'accident_threshold': 66, 'clean_title_threshold': 906, 'body_style_threshold': 525, 'engine_threshold': 82, 'fuel_type_threshold': 682, 'int_col_threshold': 882, 'brand_threshold': 941}. Best is trial 101 with value: 80586.68993611912.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:03:58] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:04:08,963] Trial 143 finished with value: 80586.1269103969 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 992, 'eta': 0.012872271172318784, 'max_depth': 5, 'min_child_weight': 0.17540352088047473, 'subsample': 0.9817966850328268, 'colsample_bytree': 0.33421711161547984, 'lambda': 73.99825676676099, 'alpha': 44.59254551042461, 'model_threshold': 555, 'ext_col_threshold': 530, 'accident_threshold': 58, 'clean_title_threshold': 912, 'body_style_threshold': 485, 'engine_threshold': 61, 'fuel_type_threshold': 689, 'int_col_threshold': 880, 'brand_threshold': 929}. Best is trial 143 with value: 80586.1269103969.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:04:09] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:04:16,268] Trial 144 finished with value: 81345.70619139733 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1073, 'eta': 0.012701386652303942, 'max_depth': 5, 'min_child_weight': 0.16742105305720115, 'subsample': 0.996071898681234, 'colsample_bytree': 0.2723209875858909, 'lambda': 81.76145376114881, 'alpha': 58.89580440519239, 'model_threshold': 541, 'ext_col_threshold': 524, 'accident_threshold': 48, 'clean_title_threshold': 907, 'body_style_threshold': 428, 'engine_threshold': 23, 'fuel_type_threshold': 682, 'int_col_threshold': 890, 'brand_threshold': 926}. Best is trial 143 with value: 80586.1269103969.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:04:16] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:04:25,411] Trial 145 finished with value: 80576.69742565531 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 994, 'eta': 0.015373037895620294, 'max_depth': 5, 'min_child_weight': 0.11357559673815384, 'subsample': 0.9793735367721236, 'colsample_bytree': 0.3377000630669105, 'lambda': 43.146286704054816, 'alpha': 46.88655118854743, 'model_threshold': 573, 'ext_col_threshold': 454, 'accident_threshold': 94, 'clean_title_threshold': 1, 'body_style_threshold': 485, 'engine_threshold': 56, 'fuel_type_threshold': 741, 'int_col_threshold': 886, 'brand_threshold': 909}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:04:25] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:04:36,121] Trial 146 finished with value: 80583.27904679158 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1036, 'eta': 0.015445126018260941, 'max_depth': 5, 'min_child_weight': 0.11640454434788343, 'subsample': 0.9779992416669064, 'colsample_bytree': 0.33824234292442223, 'lambda': 45.31813146518048, 'alpha': 89.51524881309943, 'model_threshold': 569, 'ext_col_threshold': 454, 'accident_threshold': 94, 'clean_title_threshold': 388, 'body_style_threshold': 509, 'engine_threshold': 49, 'fuel_type_threshold': 733, 'int_col_threshold': 845, 'brand_threshold': 980}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:04:36] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:04:49,523] Trial 147 finished with value: 80611.27791472893 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1034, 'eta': 0.011116267253993202, 'max_depth': 5, 'min_child_weight': 0.11046477468529939, 'subsample': 0.9795117717285959, 'colsample_bytree': 0.3387256880458679, 'lambda': 43.79835814516388, 'alpha': 92.8284572966663, 'model_threshold': 558, 'ext_col_threshold': 456, 'accident_threshold': 92, 'clean_title_threshold': 129, 'body_style_threshold': 491, 'engine_threshold': 43, 'fuel_type_threshold': 733, 'int_col_threshold': 881, 'brand_threshold': 978}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:04:49] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:05:00,746] Trial 148 finished with value: 80621.21811654852 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1130, 'eta': 0.011198096532501483, 'max_depth': 5, 'min_child_weight': 0.1844173486849349, 'subsample': 0.9763662616612971, 'colsample_bytree': 0.337637110167616, 'lambda': 67.07073165062967, 'alpha': 88.64251855010296, 'model_threshold': 559, 'ext_col_threshold': 421, 'accident_threshold': 91, 'clean_title_threshold': 54, 'body_style_threshold': 495, 'engine_threshold': 40, 'fuel_type_threshold': 728, 'int_col_threshold': 875, 'brand_threshold': 976}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:05:01] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:05:05,658] Trial 149 finished with value: 81488.72688515844 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1051, 'eta': 0.015210110452073676, 'max_depth': 5, 'min_child_weight': 0.1299370305572597, 'subsample': 0.9597143520715538, 'colsample_bytree': 0.3365660835671373, 'lambda': 45.861888181623215, 'alpha': 48.87380035914918, 'model_threshold': 574, 'ext_col_threshold': 450, 'accident_threshold': 64, 'clean_title_threshold': 122, 'body_style_threshold': 446, 'engine_threshold': 18, 'fuel_type_threshold': 699, 'int_col_threshold': 891, 'brand_threshold': 931}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:05:05] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:05:27,391] Trial 150 finished with value: 80620.55533775863 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1028, 'eta': 0.005527909519699455, 'max_depth': 5, 'min_child_weight': 0.3637867662891697, 'subsample': 0.9996241674544467, 'colsample_bytree': 0.34565877706135956, 'lambda': 130.71022862741376, 'alpha': 95.28247729523049, 'model_threshold': 595, 'ext_col_threshold': 459, 'accident_threshold': 100, 'clean_title_threshold': 176, 'body_style_threshold': 593, 'engine_threshold': 40, 'fuel_type_threshold': 751, 'int_col_threshold': 849, 'brand_threshold': 987}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:05:27] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:05:47,446] Trial 151 finished with value: 80598.13476533034 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1026, 'eta': 0.007360191524210754, 'max_depth': 5, 'min_child_weight': 0.32225162008580466, 'subsample': 0.9979400237757456, 'colsample_bytree': 0.3936314538857439, 'lambda': 97.29340968087504, 'alpha': 70.12834948187096, 'model_threshold': 590, 'ext_col_threshold': 458, 'accident_threshold': 103, 'clean_title_threshold': 220, 'body_style_threshold': 598, 'engine_threshold': 40, 'fuel_type_threshold': 755, 'int_col_threshold': 843, 'brand_threshold': 984}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:05:47] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:06:08,299] Trial 152 finished with value: 80586.1498497683 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 991, 'eta': 0.007550668039411288, 'max_depth': 5, 'min_child_weight': 0.20361033419954017, 'subsample': 0.9840008015301926, 'colsample_bytree': 0.3855404043222129, 'lambda': 96.66939065660054, 'alpha': 61.431194732153905, 'model_threshold': 526, 'ext_col_threshold': 430, 'accident_threshold': 146, 'clean_title_threshold': 373, 'body_style_threshold': 514, 'engine_threshold': 63, 'fuel_type_threshold': 710, 'int_col_threshold': 824, 'brand_threshold': 953}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:06:08] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:06:26,892] Trial 153 finished with value: 80612.59075203234 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1000, 'eta': 0.008273313276430737, 'max_depth': 5, 'min_child_weight': 0.21874388762764396, 'subsample': 0.9748827354017873, 'colsample_bytree': 0.3950082493931749, 'lambda': 81.48772501115273, 'alpha': 60.3795367789254, 'model_threshold': 563, 'ext_col_threshold': 481, 'accident_threshold': 78, 'clean_title_threshold': 228, 'body_style_threshold': 622, 'engine_threshold': 101, 'fuel_type_threshold': 714, 'int_col_threshold': 853, 'brand_threshold': 958}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:06:27] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:06:44,737] Trial 154 finished with value: 80633.22940620872 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1001, 'eta': 0.007098285858156066, 'max_depth': 5, 'min_child_weight': 0.22063759228916394, 'subsample': 0.9838919583787672, 'colsample_bytree': 0.3904812829292469, 'lambda': 89.96504536255944, 'alpha': 65.062831604414, 'model_threshold': 559, 'ext_col_threshold': 429, 'accident_threshold': 139, 'clean_title_threshold': 358, 'body_style_threshold': 515, 'engine_threshold': 103, 'fuel_type_threshold': 704, 'int_col_threshold': 913, 'brand_threshold': 909}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:06:45] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:07:00,685] Trial 155 finished with value: 80614.54096572135 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1088, 'eta': 0.008162008447454261, 'max_depth': 5, 'min_child_weight': 0.30658145515384005, 'subsample': 0.934845073897915, 'colsample_bytree': 0.43727395069160024, 'lambda': 118.84296574138645, 'alpha': 53.72838583562459, 'model_threshold': 520, 'ext_col_threshold': 471, 'accident_threshold': 87, 'clean_title_threshold': 209, 'body_style_threshold': 491, 'engine_threshold': 86, 'fuel_type_threshold': 727, 'int_col_threshold': 878, 'brand_threshold': 954}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:07:01] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:07:07,004] Trial 156 finished with value: 81556.16925486927 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 995, 'eta': 0.009825172586964897, 'max_depth': 5, 'min_child_weight': 0.1484510754829762, 'subsample': 0.9779749755110486, 'colsample_bytree': 0.3931692157588987, 'lambda': 74.62919512611117, 'alpha': 72.81701352626865, 'model_threshold': 572, 'ext_col_threshold': 435, 'accident_threshold': 37, 'clean_title_threshold': 418, 'body_style_threshold': 608, 'engine_threshold': 22, 'fuel_type_threshold': 679, 'int_col_threshold': 837, 'brand_threshold': 938}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:07:07] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:07:25,275] Trial 157 finished with value: 80699.46527065248 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1033, 'eta': 0.0059328074160569875, 'max_depth': 5, 'min_child_weight': 0.20037017041507088, 'subsample': 0.9690911264578326, 'colsample_bytree': 0.452416108664014, 'lambda': 70.54766973100456, 'alpha': 39.243933522278134, 'model_threshold': 933, 'ext_col_threshold': 415, 'accident_threshold': 102, 'clean_title_threshold': 13, 'body_style_threshold': 660, 'engine_threshold': 135, 'fuel_type_threshold': 740, 'int_col_threshold': 854, 'brand_threshold': 967}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:07:25] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:07:45,770] Trial 158 finished with value: 80646.94240662376 and parameters: {'include_mileage': 1, 'include_msrp': 1, 'n_estimators': 1067, 'eta': 0.007681506975368525, 'max_depth': 5, 'min_child_weight': 0.09747130772976029, 'subsample': 0.9485580108250794, 'colsample_bytree': 0.40608658796745273, 'lambda': 99.37214288748379, 'alpha': 31.204441530032444, 'model_threshold': 532, 'ext_col_threshold': 380, 'accident_threshold': 149, 'clean_title_threshold': 251, 'body_style_threshold': 628, 'engine_threshold': 65, 'fuel_type_threshold': 766, 'int_col_threshold': 914, 'brand_threshold': 919}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:07:46] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:08:02,093] Trial 159 finished with value: 80593.38245229717 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 986, 'eta': 0.010645622196362737, 'max_depth': 5, 'min_child_weight': 0.3723286575100471, 'subsample': 0.9969478633465904, 'colsample_bytree': 0.34971139900555426, 'lambda': 163.49401467108268, 'alpha': 50.44536923318251, 'model_threshold': 555, 'ext_col_threshold': 483, 'accident_threshold': 67, 'clean_title_threshold': 271, 'body_style_threshold': 714, 'engine_threshold': 39, 'fuel_type_threshold': 713, 'int_col_threshold': 821, 'brand_threshold': 978}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:08:02] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:08:14,843] Trial 160 finished with value: 80890.22658971684 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 981, 'eta': 0.011764077751964981, 'max_depth': 5, 'min_child_weight': 0.476426477979616, 'subsample': 0.994994383952549, 'colsample_bytree': 0.34322247943760714, 'lambda': 161.1194552289924, 'alpha': 96.84299351230268, 'model_threshold': 543, 'ext_col_threshold': 442, 'accident_threshold': 40, 'clean_title_threshold': 271, 'body_style_threshold': 458, 'engine_threshold': 708, 'fuel_type_threshold': 699, 'int_col_threshold': 824, 'brand_threshold': 982}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:08:15] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:08:25,469] Trial 161 finished with value: 80618.23970115975 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1016, 'eta': 0.009386772342418762, 'max_depth': 5, 'min_child_weight': 0.246602009500523, 'subsample': 0.9625479090075435, 'colsample_bytree': 0.37804580973462865, 'lambda': 56.83932453445295, 'alpha': 46.36285755453065, 'model_threshold': 584, 'ext_col_threshold': 475, 'accident_threshold': 76, 'clean_title_threshold': 223, 'body_style_threshold': 694, 'engine_threshold': 37, 'fuel_type_threshold': 716, 'int_col_threshold': 890, 'brand_threshold': 949}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:08:25] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:08:44,835] Trial 162 finished with value: 80627.09713354749 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1003, 'eta': 0.00513089015521999, 'max_depth': 5, 'min_child_weight': 0.346842887596784, 'subsample': 0.9304958019270754, 'colsample_bytree': 0.4239001032421291, 'lambda': 45.89505367177232, 'alpha': 69.47353839674496, 'model_threshold': 551, 'ext_col_threshold': 498, 'accident_threshold': 125, 'clean_title_threshold': 87, 'body_style_threshold': 557, 'engine_threshold': 76, 'fuel_type_threshold': 759, 'int_col_threshold': 860, 'brand_threshold': 963}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:08:45] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:09:03,765] Trial 163 finished with value: 81448.96051424423 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1039, 'eta': 0.003840839340558995, 'max_depth': 5, 'min_child_weight': 0.14003155787700228, 'subsample': 0.9815411850144563, 'colsample_bytree': 0.3520947556031596, 'lambda': 135.49693150805294, 'alpha': 30.234280033713425, 'model_threshold': 520, 'ext_col_threshold': 485, 'accident_threshold': 63, 'clean_title_threshold': 324, 'body_style_threshold': 786, 'engine_threshold': 1, 'fuel_type_threshold': 673, 'int_col_threshold': 827, 'brand_threshold': 904}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:09:04] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:09:23,664] Trial 164 finished with value: 80629.90618956104 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 978, 'eta': 0.006638441853398969, 'max_depth': 5, 'min_child_weight': 0.10753341504208715, 'subsample': 0.950564395260386, 'colsample_bytree': 0.3050131924793917, 'lambda': 184.8565174138476, 'alpha': 50.371298241180256, 'model_threshold': 559, 'ext_col_threshold': 460, 'accident_threshold': 99, 'clean_title_threshold': 178, 'body_style_threshold': 728, 'engine_threshold': 49, 'fuel_type_threshold': 737, 'int_col_threshold': 846, 'brand_threshold': 939}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:09:23] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:09:38,109] Trial 165 finished with value: 80614.03906691047 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1122, 'eta': 0.010608643232204267, 'max_depth': 5, 'min_child_weight': 0.18897797958053478, 'subsample': 0.9981344022579749, 'colsample_bytree': 0.3270732425287854, 'lambda': 85.66158089518602, 'alpha': 60.83583998922465, 'model_threshold': 506, 'ext_col_threshold': 519, 'accident_threshold': 88, 'clean_title_threshold': 285, 'body_style_threshold': 757, 'engine_threshold': 104, 'fuel_type_threshold': 710, 'int_col_threshold': 924, 'brand_threshold': 981}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:09:38] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:09:47,171] Trial 166 finished with value: 80622.36012522351 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1069, 'eta': 0.012612691070767472, 'max_depth': 5, 'min_child_weight': 0.2954912926633631, 'subsample': 0.9177656835106556, 'colsample_bytree': 0.3750719545087137, 'lambda': 57.29746270482917, 'alpha': 98.22463296242617, 'model_threshold': 574, 'ext_col_threshold': 503, 'accident_threshold': 114, 'clean_title_threshold': 315, 'body_style_threshold': 518, 'engine_threshold': 82, 'fuel_type_threshold': 680, 'int_col_threshold': 875, 'brand_threshold': 927}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:09:47] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:09:51,286] Trial 167 finished with value: 81483.58115379002 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1013, 'eta': 0.01637175316371862, 'max_depth': 5, 'min_child_weight': 0.4610172321512411, 'subsample': 0.963403299564782, 'colsample_bytree': 0.3928279900655788, 'lambda': 109.69207447875348, 'alpha': 39.01973853581534, 'model_threshold': 528, 'ext_col_threshold': 457, 'accident_threshold': 44, 'clean_title_threshold': 462, 'body_style_threshold': 484, 'engine_threshold': 21, 'fuel_type_threshold': 750, 'int_col_threshold': 900, 'brand_threshold': 965}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:09:51] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:10:08,071] Trial 168 finished with value: 80597.06393518235 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1101, 'eta': 0.007381332424832391, 'max_depth': 5, 'min_child_weight': 0.14892402225618498, 'subsample': 0.9352702324384664, 'colsample_bytree': 0.351554000325555, 'lambda': 68.59965934038641, 'alpha': 73.2577848494472, 'model_threshold': 594, 'ext_col_threshold': 401, 'accident_threshold': 70, 'clean_title_threshold': 224, 'body_style_threshold': 880, 'engine_threshold': 55, 'fuel_type_threshold': 691, 'int_col_threshold': 813, 'brand_threshold': 904}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:10:08] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:10:17,598] Trial 169 finished with value: 80613.8379958273 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1149, 'eta': 0.013141187258398752, 'max_depth': 5, 'min_child_weight': 0.1509398259874268, 'subsample': 0.9306898576022046, 'colsample_bytree': 0.31404629575289517, 'lambda': 39.84279782434993, 'alpha': 78.6483826849533, 'model_threshold': 592, 'ext_col_threshold': 407, 'accident_threshold': 29, 'clean_title_threshold': 190, 'body_style_threshold': 869, 'engine_threshold': 56, 'fuel_type_threshold': 631, 'int_col_threshold': 816, 'brand_threshold': 900}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:10:17] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:10:28,276] Trial 170 finished with value: 80637.03659091689 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1112, 'eta': 0.010154617731337665, 'max_depth': 5, 'min_child_weight': 0.10398679589733108, 'subsample': 0.9083641555367268, 'colsample_bytree': 0.3524383379393821, 'lambda': 63.22418258386271, 'alpha': 26.895671510074337, 'model_threshold': 616, 'ext_col_threshold': 377, 'accident_threshold': 139, 'clean_title_threshold': 378, 'body_style_threshold': 431, 'engine_threshold': 37, 'fuel_type_threshold': 663, 'int_col_threshold': 796, 'brand_threshold': 850}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:10:28] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:10:43,774] Trial 171 finished with value: 80627.73570307271 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1095, 'eta': 0.00844028547167303, 'max_depth': 5, 'min_child_weight': 0.2344976361431462, 'subsample': 0.9753076508129754, 'colsample_bytree': 0.3371356924756491, 'lambda': 73.2655543481502, 'alpha': 65.64582269686858, 'model_threshold': 547, 'ext_col_threshold': 435, 'accident_threshold': 68, 'clean_title_threshold': 228, 'body_style_threshold': 495, 'engine_threshold': 74, 'fuel_type_threshold': 721, 'int_col_threshold': 846, 'brand_threshold': 946}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:10:44] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:10:59,693] Trial 172 finished with value: 80629.60716351286 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 968, 'eta': 0.007906177265658808, 'max_depth': 5, 'min_child_weight': 0.19096479321287224, 'subsample': 0.947435712009744, 'colsample_bytree': 0.3598590256398064, 'lambda': 49.961250326489036, 'alpha': 48.54359015504486, 'model_threshold': 492, 'ext_col_threshold': 480, 'accident_threshold': 81, 'clean_title_threshold': 159, 'body_style_threshold': 521, 'engine_threshold': 101, 'fuel_type_threshold': 693, 'int_col_threshold': 862, 'brand_threshold': 877}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:10:59] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:11:13,699] Trial 173 finished with value: 80617.9422890768 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1045, 'eta': 0.006667605563807366, 'max_depth': 5, 'min_child_weight': 0.31875721949850727, 'subsample': 0.9885045292546653, 'colsample_bytree': 0.4709360910025039, 'lambda': 55.76338922112635, 'alpha': 34.28349686907577, 'model_threshold': 566, 'ext_col_threshold': 518, 'accident_threshold': 54, 'clean_title_threshold': 345, 'body_style_threshold': 951, 'engine_threshold': 60, 'fuel_type_threshold': 734, 'int_col_threshold': 823, 'brand_threshold': 919}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:11:13] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:11:35,885] Trial 174 finished with value: 84823.8166067547 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1002, 'eta': 0.00017622877692253223, 'max_depth': 5, 'min_child_weight': 0.12954268777062153, 'subsample': 0.9668977957313725, 'colsample_bytree': 0.293629228648576, 'lambda': 95.96698490103056, 'alpha': 68.14300032172669, 'model_threshold': 600, 'ext_col_threshold': 536, 'accident_threshold': 112, 'clean_title_threshold': 229, 'body_style_threshold': 794, 'engine_threshold': 33, 'fuel_type_threshold': 771, 'int_col_threshold': 788, 'brand_threshold': 981}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:11:36] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:11:49,926] Trial 175 finished with value: 80587.43665324237 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1169, 'eta': 0.011386472309570725, 'max_depth': 5, 'min_child_weight': 0.1618315538530713, 'subsample': 0.999504471086415, 'colsample_bytree': 0.40892222339003614, 'lambda': 43.21282471202102, 'alpha': 46.053315498191175, 'model_threshold': 529, 'ext_col_threshold': 395, 'accident_threshold': 98, 'clean_title_threshold': 303, 'body_style_threshold': 848, 'engine_threshold': 85, 'fuel_type_threshold': 701, 'int_col_threshold': 877, 'brand_threshold': 937}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:11:50] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:12:00,010] Trial 176 finished with value: 80674.09869065993 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1085, 'eta': 0.01614002619901997, 'max_depth': 5, 'min_child_weight': 0.09535583794413428, 'subsample': 0.9400099854700322, 'colsample_bytree': 0.324188864586065, 'lambda': 41.05888277394152, 'alpha': 44.994613047658525, 'model_threshold': 531, 'ext_col_threshold': 403, 'accident_threshold': 97, 'clean_title_threshold': 400, 'body_style_threshold': 934, 'engine_threshold': 123, 'fuel_type_threshold': 695, 'int_col_threshold': 875, 'brand_threshold': 934}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:12:00] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:12:08,117] Trial 177 finished with value: 80614.03342381846 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1153, 'eta': 0.021822273035616103, 'max_depth': 5, 'min_child_weight': 0.157567372774559, 'subsample': 0.9987143337847376, 'colsample_bytree': 0.3696254049045757, 'lambda': 34.43098425685763, 'alpha': 22.874121637804404, 'model_threshold': 468, 'ext_col_threshold': 420, 'accident_threshold': 126, 'clean_title_threshold': 309, 'body_style_threshold': 841, 'engine_threshold': 82, 'fuel_type_threshold': 657, 'int_col_threshold': 900, 'brand_threshold': 902}. Best is trial 145 with value: 80576.69742565531.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:12:08] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"include_mileage\", \"include_msrp\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n[I 2024-09-26 20:12:19,708] Trial 178 finished with value: 80625.54414651144 and parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1171, 'eta': 0.010680827054115624, 'max_depth': 5, 'min_child_weight': 0.7421733529360942, 'subsample': 0.9249878364697512, 'colsample_bytree': 0.30611144870129153, 'lambda': 50.066369102151825, 'alpha': 16.316629922686328, 'model_threshold': 506, 'ext_col_threshold': 392, 'accident_threshold': 57, 'clean_title_threshold': 271, 'body_style_threshold': 912, 'engine_threshold': 48, 'fuel_type_threshold': 794, 'int_col_threshold': 811, 'brand_threshold': 871}. Best is trial 145 with value: 80576.69742565531.\n[W 2024-09-26 20:12:19,829] Trial 179 failed with parameters: {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 1199, 'eta': 0.013024558731012516, 'max_depth': 5, 'min_child_weight': 0.40315117469660994, 'subsample': 0.954679846339879, 'colsample_bytree': 0.3415226682036055, 'lambda': 62.795363885918015, 'alpha': 29.69018574039017, 'model_threshold': 537, 'ext_col_threshold': 450, 'accident_threshold': 29} because of the following error: KeyboardInterrupt().\nTraceback (most recent call last):\n  File \"/root/venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/tmp/ipykernel_76/1520605179.py\", line 29, in objective\n    threshold = {cat:trial.suggest_int(f'{cat}_threshold', 1, 1000) for cat in threshold_opt_cats}\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_76/1520605179.py\", line 29, in <dictcomp>\n    threshold = {cat:trial.suggest_int(f'{cat}_threshold', 1, 1000) for cat in threshold_opt_cats}\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/optuna/_convert_positional_args.py\", line 83, in converter_wrapper\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 324, in suggest_int\n    suggested_value = int(self._suggest(name, distribution))\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 631, in _suggest\n    param_value = self.study.sampler.sample_independent(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py\", line 424, in sample_independent\n    return self._sample(study, trial, {param_name: param_distribution})[param_name]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py\", line 465, in _sample\n    acq_func_vals = self._compute_acquisition_func(samples_below, mpe_below, mpe_above)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py\", line 511, in _compute_acquisition_func\n    log_likelihoods_above = mpe_above.log_pdf(samples)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/parzen_estimator.py\", line 84, in log_pdf\n    return self._mixture_distribution.log_pdf(transformed_samples)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/probability_distributions.py\", line 105, in log_pdf\n    log_gauss_mass = _truncnorm._log_gauss_mass(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/_truncnorm.py\", line 143, in _log_gauss_mass\n    out[case_left] = mass_case_left(a[case_left], b[case_left])\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/_truncnorm.py\", line 122, in mass_case_left\n    return _log_diff(_log_ndtr(b), _log_ndtr(a))\n                                   ^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/_truncnorm.py\", line 105, in _log_ndtr\n    return np.frompyfunc(_log_ndtr_single, 1, 1)(a).astype(float)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/_truncnorm.py\", line 93, in _log_ndtr_single\n    while abs(last_total - right_hand_side) > sys.float_info.epsilon:\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\n[W 2024-09-26 20:12:19,852] Trial 179 failed with value None.\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 69\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rmse\n\u001b[1;32m     68\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[2], line 29\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(trial):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Suggest hyperparameters for tuning\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_mileage\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_mileage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_msrp\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_msrp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m     }\n\u001b[0;32m---> 29\u001b[0m     threshold \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m:\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest_int\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcat\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_threshold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mthreshold_opt_cats\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     32\u001b[0m     X_train, X_valid, y_train, y_valid \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1219\u001b[39m)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m cat_types:\n","Cell \u001b[0;32mIn[2], line 29\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(trial):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Suggest hyperparameters for tuning\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_mileage\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_mileage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_msrp\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_msrp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m     }\n\u001b[0;32m---> 29\u001b[0m     threshold \u001b[38;5;241m=\u001b[39m {cat:\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest_int\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcat\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_threshold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m threshold_opt_cats}\n\u001b[1;32m     32\u001b[0m     X_train, X_valid, y_train, y_valid \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1219\u001b[39m)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m cat_types:\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/_convert_positional_args.py:83\u001b[0m, in \u001b[0;36mconvert_positional_args.<locals>.converter_decorator.<locals>.converter_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() got multiple values for arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduplicated_kwds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     81\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(inferred_kwargs)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/trial/_trial.py:324\u001b[0m, in \u001b[0;36mTrial.suggest_int\u001b[0;34m(self, name, low, high, step, log)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Suggest a value for the integer parameter.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03mThe value is sampled from the integers in :math:`[\\\\mathsf{low}, \\\\mathsf{high}]`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    :ref:`configurations` tutorial describes more details and flexible usages.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    323\u001b[0m distribution \u001b[38;5;241m=\u001b[39m IntDistribution(low\u001b[38;5;241m=\u001b[39mlow, high\u001b[38;5;241m=\u001b[39mhigh, log\u001b[38;5;241m=\u001b[39mlog, step\u001b[38;5;241m=\u001b[39mstep)\n\u001b[0;32m--> 324\u001b[0m suggested_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_suggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistribution\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_distribution(name, distribution)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m suggested_value\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/trial/_trial.py:631\u001b[0m, in \u001b[0;36mTrial._suggest\u001b[0;34m(self, name, distribution)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    630\u001b[0m     study \u001b[38;5;241m=\u001b[39m pruners\u001b[38;5;241m.\u001b[39m_filter_study(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy, trial)\n\u001b[0;32m--> 631\u001b[0m     param_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_independent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistribution\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;66;03m# `param_value` is validated here (invalid value like `np.nan` raises ValueError).\u001b[39;00m\n\u001b[1;32m    636\u001b[0m param_value_in_internal_repr \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mto_internal_repr(param_value)\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:424\u001b[0m, in \u001b[0;36mTPESampler.sample_independent\u001b[0;34m(self, study, trial, param_name, param_distribution)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(param_name \u001b[38;5;129;01min\u001b[39;00m trial\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m trials):\n\u001b[1;32m    415\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    416\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in trial#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is sampled \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindependently instead of being sampled by multivariate TPE sampler. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif this independent sampling is intended behavior.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m         )\n\u001b[0;32m--> 424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_distribution\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[param_name]\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:465\u001b[0m, in \u001b[0;36mTPESampler._sample\u001b[0;34m(self, study, trial, search_space)\u001b[0m\n\u001b[1;32m    460\u001b[0m mpe_above \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_parzen_estimator(\n\u001b[1;32m    461\u001b[0m     study, search_space, above_trials, handle_below\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    462\u001b[0m )\n\u001b[1;32m    464\u001b[0m samples_below \u001b[38;5;241m=\u001b[39m mpe_below\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39mrng, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_ei_candidates)\n\u001b[0;32m--> 465\u001b[0m acq_func_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_acquisition_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_below\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmpe_below\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmpe_above\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m ret \u001b[38;5;241m=\u001b[39m TPESampler\u001b[38;5;241m.\u001b[39m_compare(samples_below, acq_func_vals)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_name, dist \u001b[38;5;129;01min\u001b[39;00m search_space\u001b[38;5;241m.\u001b[39mitems():\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/sampler.py:511\u001b[0m, in \u001b[0;36mTPESampler._compute_acquisition_func\u001b[0;34m(self, samples, mpe_below, mpe_above)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_acquisition_func\u001b[39m(\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    506\u001b[0m     samples: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m    507\u001b[0m     mpe_below: _ParzenEstimator,\n\u001b[1;32m    508\u001b[0m     mpe_above: _ParzenEstimator,\n\u001b[1;32m    509\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    510\u001b[0m     log_likelihoods_below \u001b[38;5;241m=\u001b[39m mpe_below\u001b[38;5;241m.\u001b[39mlog_pdf(samples)\n\u001b[0;32m--> 511\u001b[0m     log_likelihoods_above \u001b[38;5;241m=\u001b[39m \u001b[43mmpe_above\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m     acq_func_vals \u001b[38;5;241m=\u001b[39m log_likelihoods_below \u001b[38;5;241m-\u001b[39m log_likelihoods_above\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m acq_func_vals\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/parzen_estimator.py:84\u001b[0m, in \u001b[0;36m_ParzenEstimator.log_pdf\u001b[0;34m(self, samples_dict)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_pdf\u001b[39m(\u001b[38;5;28mself\u001b[39m, samples_dict: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     83\u001b[0m     transformed_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(samples_dict)\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mixture_distribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_samples\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/probability_distributions.py:105\u001b[0m, in \u001b[0;36m_MixtureOfProductDistribution.log_pdf\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    103\u001b[0m x_lower \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(xi \u001b[38;5;241m-\u001b[39m d\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, lower_limit)\n\u001b[1;32m    104\u001b[0m x_upper \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mminimum(xi \u001b[38;5;241m+\u001b[39m d\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, upper_limit)\n\u001b[0;32m--> 105\u001b[0m log_gauss_mass \u001b[38;5;241m=\u001b[39m \u001b[43m_truncnorm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_gauss_mass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_lower\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_upper\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m log_p_accept \u001b[38;5;241m=\u001b[39m _truncnorm\u001b[38;5;241m.\u001b[39m_log_gauss_mass(\n\u001b[1;32m    110\u001b[0m     (d\u001b[38;5;241m.\u001b[39mlow \u001b[38;5;241m-\u001b[39m d\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m d\u001b[38;5;241m.\u001b[39mmu[\u001b[38;5;28;01mNone\u001b[39;00m, :]) \u001b[38;5;241m/\u001b[39m d\u001b[38;5;241m.\u001b[39msigma[\u001b[38;5;28;01mNone\u001b[39;00m, :],\n\u001b[1;32m    111\u001b[0m     (d\u001b[38;5;241m.\u001b[39mhigh \u001b[38;5;241m+\u001b[39m d\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m d\u001b[38;5;241m.\u001b[39mmu[\u001b[38;5;28;01mNone\u001b[39;00m, :]) \u001b[38;5;241m/\u001b[39m d\u001b[38;5;241m.\u001b[39msigma[\u001b[38;5;28;01mNone\u001b[39;00m, :],\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    113\u001b[0m log_pdfs[:, :, i] \u001b[38;5;241m=\u001b[39m log_gauss_mass \u001b[38;5;241m-\u001b[39m log_p_accept\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/_truncnorm.py:143\u001b[0m, in \u001b[0;36m_log_gauss_mass\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    141\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull_like(a, fill_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mcomplex128)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a[case_left]\u001b[38;5;241m.\u001b[39msize:\n\u001b[0;32m--> 143\u001b[0m     out[case_left] \u001b[38;5;241m=\u001b[39m \u001b[43mmass_case_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcase_left\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcase_left\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a[case_right]\u001b[38;5;241m.\u001b[39msize:\n\u001b[1;32m    145\u001b[0m     out[case_right] \u001b[38;5;241m=\u001b[39m mass_case_right(a[case_right], b[case_right])\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/_truncnorm.py:122\u001b[0m, in \u001b[0;36m_log_gauss_mass.<locals>.mass_case_left\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmass_case_left\u001b[39m(a: np\u001b[38;5;241m.\u001b[39mndarray, b: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _log_diff(_log_ndtr(b), \u001b[43m_log_ndtr\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/_truncnorm.py:105\u001b[0m, in \u001b[0;36m_log_ndtr\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_log_ndtr\u001b[39m(a: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrompyfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_log_ndtr_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/samplers/_tpe/_truncnorm.py:93\u001b[0m, in \u001b[0;36m_log_ndtr_single\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     90\u001b[0m sign \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     91\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(last_total \u001b[38;5;241m-\u001b[39m right_hand_side) \u001b[38;5;241m>\u001b[39m sys\u001b[38;5;241m.\u001b[39mfloat_info\u001b[38;5;241m.\u001b[39mepsilon:\n\u001b[1;32m     94\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     95\u001b[0m     last_total \u001b[38;5;241m=\u001b[39m right_hand_side\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"outputs_reference":"s3:deepnote-cell-outputs-production/cbb7ea69-bb05-41ef-ac4d-e7a64e9ce0e0","content_dependencies":null},{"cellId":"1640b514edaa4e80b3b55596eb124512","cell_type":"code","metadata":{"source_hash":null,"execution_start":1727037256696,"execution_millis":2840951,"deepnote_to_be_reexecuted":false,"cell_id":"1640b514edaa4e80b3b55596eb124512","deepnote_cell_type":"code"},"source":"def objective(trial):\n    # Suggest hyperparameters for tuning\n    params = {\n        'objective': 'reg:squarederror',\n        'eval_metric': 'rmse',\n        'booster': 'gbtree',\n        'n_estimators': trial.suggest_int('n_estimators', 50, 1200),\n        'eta': trial.suggest_float('eta', 0.0001, 0.5, log = True),  # learning rate\n        'max_depth': 7,\n        'min_child_weight': 6.375,\n        'subsample': 0.15,\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.05, 1.0),\n        'lambda': trial.suggest_float('lambda', 0.1, 50, log = True),\n        'alpha': trial.suggest_float('alpha', 1e-4, 10, log = True),\n        'tree_method': 'hist',  \n        'device':'cpu'\n    }\n    threshold = trial.suggest_int('threshold', 1, 500)\n\n    y = df['price']\n    X = df.drop(['price'], axis=1)\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=1219)\n    \n\n    for cat in cat_types:\n        value_counts = X_train[cat].value_counts().to_dict()\n        X_train[cat] = X_train[cat].apply(lambda x: x if value_counts[x] > threshold else \"unknown\")\n        X_valid[cat] = X_valid[cat].apply(lambda x: x if (x in value_counts) and (value_counts[x] > threshold) else \"unknown\")\n\n    X_train = X_train.astype({col: \"category\" for col in cat_types})\n    X_valid = X_valid.astype({col: \"category\" for col in cat_types})\n    dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n    dvalid = xgb.DMatrix(X_valid, label=y_valid, enable_categorical=True)\n    \n    # Train the model\n    model = xgb.train(params, dtrain, evals=[(dvalid, 'validation')], num_boost_round=params['n_estimators'], early_stopping_rounds=35, verbose_eval=False)\n    \n    # Predict on the validation set\n    y_pred_valid = model.predict(dvalid)\n    \n    # Calculate RMSE on the validation set\n    rmse = mean_squared_error(y_valid, y_pred_valid, squared=False)\n    \n    return rmse\n\n\n\nstudy = optuna.create_study(sampler = optuna.samplers.GPSampler(), direction='minimize')\nstudy.optimize(objective, n_trials=250)\n\n\nbest_params = study.best_params\nprint(f\"Best hyperparameters: {best_params}\")","block_group":"ec53a5ff3c9944119b2fcc5cde3d3744","execution_count":null,"outputs":[{"name":"stderr","text":"\n\n[I 2024-09-22 20:48:21,679] Trial 63 finished with value: 81080.7867679816 and parameters: {'n_estimators': 1200, 'eta': 0.0044651579940966895, 'colsample_bytree': 1.0, 'lambda': 0.10000000000000002, 'alpha': 0.00010000000000000009, 'threshold': 354}. Best is trial 57 with value: 80727.7368290466.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:48:22] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:48:27,428] Trial 64 finished with value: 80949.60388861551 and parameters: {'n_estimators': 665, 'eta': 0.032942769716334114, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 277}. Best is trial 57 with value: 80727.7368290466.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:48:28] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:48:46,210] Trial 65 finished with value: 80879.47822443333 and parameters: {'n_estimators': 1200, 'eta': 0.008446401126167765, 'colsample_bytree': 0.594887052589133, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 57 with value: 80727.7368290466.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:48:47] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:48:48,311] Trial 66 finished with value: 83562.18215217025 and parameters: {'n_estimators': 50, 'eta': 0.49999999999999994, 'colsample_bytree': 0.05, 'lambda': 0.10000000000000002, 'alpha': 0.00010000000000000009, 'threshold': 1}. Best is trial 57 with value: 80727.7368290466.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:48:49] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:49:16,590] Trial 67 finished with value: 80699.4496160999 and parameters: {'n_estimators': 1133, 'eta': 0.004556315580680272, 'colsample_bytree': 0.5510341833529052, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 69}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:49:17] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:49:45,252] Trial 68 finished with value: 80787.11462353253 and parameters: {'n_estimators': 1070, 'eta': 0.003218543295364733, 'colsample_bytree': 0.56887148216366, 'lambda': 49.99999999999995, 'alpha': 0.00010000000000000009, 'threshold': 62}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:49:46] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:49:55,297] Trial 69 finished with value: 81000.5964636439 and parameters: {'n_estimators': 618, 'eta': 0.007911142357991612, 'colsample_bytree': 1.0, 'lambda': 1.819207144222306, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:49:56] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:50:29,150] Trial 70 finished with value: 81610.00863866351 and parameters: {'n_estimators': 1200, 'eta': 0.003668324014821522, 'colsample_bytree': 0.5179688457707132, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 1}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:50:31] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:50:36,412] Trial 71 finished with value: 80830.80542413918 and parameters: {'n_estimators': 1200, 'eta': 0.04484707879883084, 'colsample_bytree': 0.30399734733401057, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 122}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:50:38] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:51:00,512] Trial 72 finished with value: 80765.87966349711 and parameters: {'n_estimators': 996, 'eta': 0.0054490929418436985, 'colsample_bytree': 0.3850158141275445, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 82}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:51:01] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:51:05,311] Trial 73 finished with value: 80842.47155641687 and parameters: {'n_estimators': 1006, 'eta': 0.06020937393859147, 'colsample_bytree': 0.4345636758125459, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 156}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:51:06] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:51:14,667] Trial 74 finished with value: 81015.82421073156 and parameters: {'n_estimators': 1200, 'eta': 0.00952686619452158, 'colsample_bytree': 0.6322103122649008, 'lambda': 2.5825132726365103, 'alpha': 0.2667845161019572, 'threshold': 265}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:51:15] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:51:19,091] Trial 75 finished with value: 81321.83334147125 and parameters: {'n_estimators': 614, 'eta': 0.021980617395119896, 'colsample_bytree': 1.0, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 238}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:51:20] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:51:21,923] Trial 76 finished with value: 81574.52862382922 and parameters: {'n_estimators': 1121, 'eta': 0.06692156884223749, 'colsample_bytree': 0.48034585174552685, 'lambda': 0.11751103213633644, 'alpha': 0.00010000000000000009, 'threshold': 151}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:51:23] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:51:28,536] Trial 77 finished with value: 80883.76481241782 and parameters: {'n_estimators': 1200, 'eta': 0.03171470499170088, 'colsample_bytree': 0.857447370196661, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:51:30] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:51:52,523] Trial 78 finished with value: 80761.98195333079 and parameters: {'n_estimators': 1109, 'eta': 0.003994723658923874, 'colsample_bytree': 0.5070170345940846, 'lambda': 17.8198054609425, 'alpha': 0.00010000000000000009, 'threshold': 87}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:51:53] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:51:59,512] Trial 79 finished with value: 81117.60435320357 and parameters: {'n_estimators': 905, 'eta': 0.05402763509348469, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 120}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:52:00] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:52:07,145] Trial 80 finished with value: 80839.4823713231 and parameters: {'n_estimators': 791, 'eta': 0.027019833130289408, 'colsample_bytree': 0.7891891060104796, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 225}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:52:08] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:52:13,401] Trial 81 finished with value: 81158.58902402148 and parameters: {'n_estimators': 664, 'eta': 0.01149799596695304, 'colsample_bytree': 0.9999999999999999, 'lambda': 0.21939216289525568, 'alpha': 0.00010000000000000009, 'threshold': 380}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:52:14] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:52:36,061] Trial 82 finished with value: 80699.56620669822 and parameters: {'n_estimators': 1151, 'eta': 0.005882741713659451, 'colsample_bytree': 0.5590751949130961, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 87}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:52:37] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:52:55,728] Trial 83 finished with value: 81317.42290166154 and parameters: {'n_estimators': 1200, 'eta': 0.010390398010459356, 'colsample_bytree': 0.05, 'lambda': 0.10000000000000002, 'alpha': 0.00010000000000000009, 'threshold': 338}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:52:57] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:53:02,514] Trial 84 finished with value: 81272.10514934138 and parameters: {'n_estimators': 1200, 'eta': 0.07123206816512986, 'colsample_bytree': 0.05, 'lambda': 49.99999999999995, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:53:03] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:53:17,235] Trial 85 finished with value: 80872.75824762949 and parameters: {'n_estimators': 1200, 'eta': 0.028696946113762365, 'colsample_bytree': 0.1631119322035721, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 165}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:53:18] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:53:43,094] Trial 86 finished with value: 80734.71379955899 and parameters: {'n_estimators': 1200, 'eta': 0.0057545684080186925, 'colsample_bytree': 0.3886395505191921, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 82}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:53:44] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:53:56,385] Trial 87 finished with value: 80965.26457588843 and parameters: {'n_estimators': 1200, 'eta': 0.01957138298976434, 'colsample_bytree': 0.21207358065797266, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 416}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:53:58] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:54:12,571] Trial 88 finished with value: 80849.95890441109 and parameters: {'n_estimators': 911, 'eta': 0.008604501582316902, 'colsample_bytree': 0.9501035770270584, 'lambda': 32.250790189004825, 'alpha': 0.00010000000000000009, 'threshold': 118}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:54:13] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:54:35,600] Trial 89 finished with value: 80719.1635631383 and parameters: {'n_estimators': 1151, 'eta': 0.005268021163249208, 'colsample_bytree': 0.6181227867696738, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 84}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:54:36] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:54:40,335] Trial 90 finished with value: 81029.52785041032 and parameters: {'n_estimators': 1200, 'eta': 0.022821610456279708, 'colsample_bytree': 0.5963201034109895, 'lambda': 0.10000000000000002, 'alpha': 0.00010000000000000009, 'threshold': 500}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:54:41] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:54:42,479] Trial 91 finished with value: 86337.5594766068 and parameters: {'n_estimators': 50, 'eta': 0.00010000000000000009, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 1}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:54:44] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:55:09,803] Trial 92 finished with value: 80708.83015632548 and parameters: {'n_estimators': 1117, 'eta': 0.0047742404078257635, 'colsample_bytree': 0.5196827016432561, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 83}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:55:10] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:55:11,996] Trial 93 finished with value: 83654.14201776378 and parameters: {'n_estimators': 50, 'eta': 0.49999999999999994, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999975, 'threshold': 228}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:55:13] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:55:31,154] Trial 94 finished with value: 80732.06132890409 and parameters: {'n_estimators': 987, 'eta': 0.007472836181694425, 'colsample_bytree': 0.676400417006062, 'lambda': 49.99999999999995, 'alpha': 9.999999999999993, 'threshold': 108}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:55:32] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:55:38,096] Trial 95 finished with value: 80921.40011309218 and parameters: {'n_estimators': 1200, 'eta': 0.029569848118629515, 'colsample_bytree': 0.623877740174508, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 500}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:55:39] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:55:50,358] Trial 96 finished with value: 80750.47869407154 and parameters: {'n_estimators': 1145, 'eta': 0.016761626732557336, 'colsample_bytree': 0.6472190564166658, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 108}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:55:52] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:56:01,400] Trial 97 finished with value: 80811.4012688947 and parameters: {'n_estimators': 1024, 'eta': 0.01781891698483681, 'colsample_bytree': 0.6563883972261829, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 147}. Best is trial 67 with value: 80699.4496160999.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:56:02] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:56:22,971] Trial 98 finished with value: 80681.45368594286 and parameters: {'n_estimators': 1105, 'eta': 0.006698707441801676, 'colsample_bytree': 0.5362016329562652, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 80}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:56:24] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:56:44,192] Trial 99 finished with value: 80683.29957939468 and parameters: {'n_estimators': 1200, 'eta': 0.006893122772252773, 'colsample_bytree': 0.7255700433684702, 'lambda': 49.99999999999999, 'alpha': 9.999999999999975, 'threshold': 82}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:56:45] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:57:04,234] Trial 100 finished with value: 80705.48271613686 and parameters: {'n_estimators': 1101, 'eta': 0.006746654317927812, 'colsample_bytree': 0.6919251349625419, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 79}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:57:05] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:57:25,444] Trial 101 finished with value: 80690.30422649372 and parameters: {'n_estimators': 1200, 'eta': 0.00735896746790729, 'colsample_bytree': 0.5808643702279868, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 88}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:57:27] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:57:57,113] Trial 102 finished with value: 80696.03920516491 and parameters: {'n_estimators': 1188, 'eta': 0.004810272139153012, 'colsample_bytree': 0.5563794614677979, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 76}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:57:58] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:58:05,349] Trial 103 finished with value: 81023.96728266079 and parameters: {'n_estimators': 851, 'eta': 0.016731832560504378, 'colsample_bytree': 0.6977632605125887, 'lambda': 4.257347682698446, 'alpha': 0.00010000000000000009, 'threshold': 245}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:58:06] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:58:26,823] Trial 104 finished with value: 80692.04009322786 and parameters: {'n_estimators': 1200, 'eta': 0.0064386947105162465, 'colsample_bytree': 0.5881095853040998, 'lambda': 49.99999999999995, 'alpha': 0.18337793682987696, 'threshold': 76}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:58:28] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:58:53,603] Trial 105 finished with value: 80922.29328983735 and parameters: {'n_estimators': 1200, 'eta': 0.004449935799756781, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 377}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:58:55] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:59:05,791] Trial 106 finished with value: 80738.1743702297 and parameters: {'n_estimators': 1200, 'eta': 0.012388182340725954, 'colsample_bytree': 0.8200487080329989, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 91}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:59:07] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:59:30,977] Trial 107 finished with value: 80750.72314732328 and parameters: {'n_estimators': 1040, 'eta': 0.004582897587998337, 'colsample_bytree': 0.43480239110039465, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 75}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:59:32] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 20:59:48,589] Trial 108 finished with value: 80710.61117848991 and parameters: {'n_estimators': 1200, 'eta': 0.009534521492171436, 'colsample_bytree': 0.6267351765809911, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 78}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[20:59:49] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:00:10,909] Trial 109 finished with value: 80715.46915220973 and parameters: {'n_estimators': 1160, 'eta': 0.006592204783580637, 'colsample_bytree': 0.6315653068577106, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 89}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:00:12] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:00:26,058] Trial 110 finished with value: 80893.59750032706 and parameters: {'n_estimators': 992, 'eta': 0.007309942364265707, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 344}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:00:27] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:00:45,522] Trial 111 finished with value: 80701.7213969452 and parameters: {'n_estimators': 1121, 'eta': 0.008482740541541463, 'colsample_bytree': 0.6348834088644196, 'lambda': 49.99999999999999, 'alpha': 0.061994431032180636, 'threshold': 87}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:00:46] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:00:52,646] Trial 112 finished with value: 81043.15945478897 and parameters: {'n_estimators': 1200, 'eta': 0.01255930952769319, 'colsample_bytree': 1.0, 'lambda': 2.035146436887697, 'alpha': 9.999999999999975, 'threshold': 500}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:00:54] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:01:08,137] Trial 113 finished with value: 81021.29678477188 and parameters: {'n_estimators': 1200, 'eta': 0.010328145737025429, 'colsample_bytree': 0.2098170417203168, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:01:09] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:01:29,399] Trial 114 finished with value: 80826.56367887865 and parameters: {'n_estimators': 1200, 'eta': 0.005733280714818264, 'colsample_bytree': 0.9999999999999999, 'lambda': 49.99999999999995, 'alpha': 9.999999999999993, 'threshold': 230}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:01:30] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:01:36,447] Trial 115 finished with value: 81079.34364169033 and parameters: {'n_estimators': 1200, 'eta': 0.056511074991591276, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 85}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:01:37] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:01:42,042] Trial 116 finished with value: 81398.0551170347 and parameters: {'n_estimators': 240, 'eta': 0.027097018467461924, 'colsample_bytree': 0.05, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 151}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:01:43] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:01:44,917] Trial 117 finished with value: 83062.65781052606 and parameters: {'n_estimators': 50, 'eta': 0.009920377426540746, 'colsample_bytree': 1.0, 'lambda': 0.10000000000000002, 'alpha': 0.00010000000000000009, 'threshold': 156}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:01:46] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:01:52,312] Trial 118 finished with value: 81122.60655876872 and parameters: {'n_estimators': 630, 'eta': 0.06057198005835296, 'colsample_bytree': 0.05, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 159}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:01:53] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:02:05,047] Trial 119 finished with value: 80807.75113089474 and parameters: {'n_estimators': 1200, 'eta': 0.012147707404670376, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 90}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:02:06] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:02:17,629] Trial 120 finished with value: 80887.5500141299 and parameters: {'n_estimators': 939, 'eta': 0.019958534656780862, 'colsample_bytree': 0.5949886411666078, 'lambda': 49.99999999999995, 'alpha': 9.999999999999993, 'threshold': 478}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:02:19] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:02:29,997] Trial 121 finished with value: 80905.64130062242 and parameters: {'n_estimators': 916, 'eta': 0.011011546809050417, 'colsample_bytree': 0.9999999999999999, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 288}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:02:31] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:02:41,588] Trial 122 finished with value: 80710.90088947122 and parameters: {'n_estimators': 1200, 'eta': 0.015937818254241107, 'colsample_bytree': 0.4933279774722766, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 91}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:02:42] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:03:01,795] Trial 123 finished with value: 80849.29347603477 and parameters: {'n_estimators': 973, 'eta': 0.00665981460135474, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 187}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:03:03] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:03:19,815] Trial 124 finished with value: 80940.4614077932 and parameters: {'n_estimators': 747, 'eta': 0.0051657840449750355, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 431}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:03:21] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:03:43,953] Trial 125 finished with value: 80909.438018698 and parameters: {'n_estimators': 1200, 'eta': 0.005507966994571048, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 253}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:03:45] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:04:03,729] Trial 126 finished with value: 80803.78001731918 and parameters: {'n_estimators': 1200, 'eta': 0.007593998287619166, 'colsample_bytree': 0.6116784166155375, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 195}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:04:05] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:04:32,048] Trial 127 finished with value: 81015.64946413615 and parameters: {'n_estimators': 1200, 'eta': 0.0022105494928279486, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 500}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:04:33] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:04:43,435] Trial 128 finished with value: 81115.0532087067 and parameters: {'n_estimators': 632, 'eta': 0.0219877514861573, 'colsample_bytree': 0.05, 'lambda': 0.10000000000000002, 'alpha': 0.00010000000000000009, 'threshold': 83}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:04:45] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:04:47,885] Trial 129 finished with value: 80970.58917001789 and parameters: {'n_estimators': 802, 'eta': 0.06156723648410668, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 209}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:04:49] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:04:59,960] Trial 130 finished with value: 80712.63860305172 and parameters: {'n_estimators': 1062, 'eta': 0.015196829534734885, 'colsample_bytree': 0.6007408575517607, 'lambda': 49.99999999999995, 'alpha': 0.00010000000000000009, 'threshold': 97}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:05:01] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:05:30,237] Trial 131 finished with value: 80720.98325482514 and parameters: {'n_estimators': 1200, 'eta': 0.004239249422588517, 'colsample_bytree': 0.7438223844208306, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 80}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:05:31] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:05:42,073] Trial 132 finished with value: 80804.87935702989 and parameters: {'n_estimators': 916, 'eta': 0.011425997095372528, 'colsample_bytree': 0.46879097647517476, 'lambda': 10.775969785538239, 'alpha': 9.999999999999993, 'threshold': 85}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:05:43] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:05:59,822] Trial 133 finished with value: 80949.97843199484 and parameters: {'n_estimators': 744, 'eta': 0.0046512935858127125, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 500}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:06:01] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:06:20,812] Trial 134 finished with value: 80980.35104625605 and parameters: {'n_estimators': 1200, 'eta': 0.002653939078111104, 'colsample_bytree': 1.0, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 220}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:06:22] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:06:53,476] Trial 135 finished with value: 81307.73814708323 and parameters: {'n_estimators': 1200, 'eta': 0.0011246821424155244, 'colsample_bytree': 1.0, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 108}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:06:54] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:07:00,396] Trial 136 finished with value: 80790.54350741408 and parameters: {'n_estimators': 1200, 'eta': 0.026910527336522078, 'colsample_bytree': 0.6852707873380128, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 101}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:07:01] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:07:18,770] Trial 137 finished with value: 80706.89529358252 and parameters: {'n_estimators': 1102, 'eta': 0.009981113589898158, 'colsample_bytree': 0.4684452386326871, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 87}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:07:20] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:07:42,275] Trial 138 finished with value: 80693.33036418677 and parameters: {'n_estimators': 1200, 'eta': 0.006163244549034614, 'colsample_bytree': 0.590230814654818, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 75}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:07:43] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:08:00,424] Trial 139 finished with value: 80699.50333300013 and parameters: {'n_estimators': 1132, 'eta': 0.00990751024643593, 'colsample_bytree': 0.5597840024326282, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 80}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:08:01] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:08:28,388] Trial 140 finished with value: 80694.64460310493 and parameters: {'n_estimators': 1165, 'eta': 0.0058088325751401515, 'colsample_bytree': 0.5725232079948106, 'lambda': 49.99999999999995, 'alpha': 0.07690108822280685, 'threshold': 75}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:08:29] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:08:47,812] Trial 141 finished with value: 80831.78011564838 and parameters: {'n_estimators': 1200, 'eta': 0.013123266619571387, 'colsample_bytree': 0.26579643796136476, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 220}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:08:49] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:08:51,931] Trial 142 finished with value: 81263.94000689387 and parameters: {'n_estimators': 677, 'eta': 0.036891000978012005, 'colsample_bytree': 1.0, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:08:53] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:09:12,843] Trial 143 finished with value: 80908.93748218527 and parameters: {'n_estimators': 1200, 'eta': 0.005912921963300383, 'colsample_bytree': 0.6448262511396549, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 398}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:09:14] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:09:18,018] Trial 144 finished with value: 80878.58647563636 and parameters: {'n_estimators': 669, 'eta': 0.04431820882202776, 'colsample_bytree': 0.6320401027566319, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 163}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:09:19] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:09:29,722] Trial 145 finished with value: 80730.16447658806 and parameters: {'n_estimators': 1039, 'eta': 0.012116905635523837, 'colsample_bytree': 0.6409544781744645, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 84}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:09:31] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:09:34,465] Trial 146 finished with value: 81033.97889430464 and parameters: {'n_estimators': 749, 'eta': 0.043284107506172634, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 393}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:09:35] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:09:53,181] Trial 147 finished with value: 80867.72991885745 and parameters: {'n_estimators': 1057, 'eta': 0.008595453420240016, 'colsample_bytree': 0.602868751143265, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 363}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:09:54] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:10:03,321] Trial 148 finished with value: 80830.8126423857 and parameters: {'n_estimators': 621, 'eta': 0.02031952399214782, 'colsample_bytree': 0.649886741993214, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 320}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:10:04] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:10:12,539] Trial 149 finished with value: 80945.70313737205 and parameters: {'n_estimators': 1200, 'eta': 0.022752961617717792, 'colsample_bytree': 0.31798224040123757, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 238}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:10:13] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:10:19,431] Trial 150 finished with value: 80900.74574416874 and parameters: {'n_estimators': 386, 'eta': 0.02208935353027796, 'colsample_bytree': 0.9999999999999999, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 336}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:10:21] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:10:24,911] Trial 151 finished with value: 80906.41287876906 and parameters: {'n_estimators': 613, 'eta': 0.035611800046058906, 'colsample_bytree': 0.9999999999999999, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 315}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:10:26] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:10:35,700] Trial 152 finished with value: 81400.77824078448 and parameters: {'n_estimators': 573, 'eta': 0.016420678051082382, 'colsample_bytree': 0.11334677930336372, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 252}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:10:37] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:10:46,974] Trial 153 finished with value: 80860.08772416277 and parameters: {'n_estimators': 583, 'eta': 0.015373224368229767, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 348}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:10:48] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:10:52,850] Trial 154 finished with value: 81033.89209310769 and parameters: {'n_estimators': 1200, 'eta': 0.028523149087177558, 'colsample_bytree': 0.4216505395608233, 'lambda': 4.576581765837815, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:10:54] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:11:07,271] Trial 155 finished with value: 80698.97575537013 and parameters: {'n_estimators': 1140, 'eta': 0.011008416935782785, 'colsample_bytree': 0.5703474034202914, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 98}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:11:08] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:11:10,125] Trial 156 finished with value: 86304.54880648969 and parameters: {'n_estimators': 50, 'eta': 0.00010000000000000009, 'colsample_bytree': 1.0, 'lambda': 49.99999999999995, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:11:11] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:11:22,052] Trial 157 finished with value: 81002.94141066671 and parameters: {'n_estimators': 905, 'eta': 0.006540113917781633, 'colsample_bytree': 0.6246187952903999, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 450}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:11:23] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:11:50,296] Trial 158 finished with value: 80909.20589647256 and parameters: {'n_estimators': 1200, 'eta': 0.003904456292438364, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 456}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:11:51] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:12:13,568] Trial 159 finished with value: 80686.85934534093 and parameters: {'n_estimators': 1151, 'eta': 0.006729290125835895, 'colsample_bytree': 0.5720259827041694, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 78}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:12:15] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:12:22,656] Trial 160 finished with value: 81123.04772567544 and parameters: {'n_estimators': 656, 'eta': 0.03399709490738231, 'colsample_bytree': 0.05, 'lambda': 1.3130844482353883, 'alpha': 9.999999999999993, 'threshold': 101}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:12:24] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:12:34,539] Trial 161 finished with value: 80931.52391633336 and parameters: {'n_estimators': 514, 'eta': 0.01321575670918354, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 295}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:12:36] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:12:56,544] Trial 162 finished with value: 80694.76165426474 and parameters: {'n_estimators': 1200, 'eta': 0.006721199816311202, 'colsample_bytree': 0.4992230882564123, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 77}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:12:58] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:13:05,985] Trial 163 finished with value: 80874.61553489245 and parameters: {'n_estimators': 625, 'eta': 0.025115773133433578, 'colsample_bytree': 0.9999999999999999, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:13:07] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:13:11,815] Trial 164 finished with value: 81153.02198431759 and parameters: {'n_estimators': 1200, 'eta': 0.19055698722665518, 'colsample_bytree': 0.05, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 162}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:13:13] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:13:14,831] Trial 165 finished with value: 82309.62427601757 and parameters: {'n_estimators': 1200, 'eta': 0.27022865772560695, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 135}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:13:16] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:13:25,967] Trial 166 finished with value: 80845.98836683709 and parameters: {'n_estimators': 857, 'eta': 0.018859221017453222, 'colsample_bytree': 0.6217407369706054, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 374}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:13:27] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:13:57,955] Trial 167 finished with value: 80946.17324229328 and parameters: {'n_estimators': 1200, 'eta': 0.002329308918152703, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 183}. Best is trial 98 with value: 80681.45368594286.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:13:59] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:14:19,713] Trial 168 finished with value: 80677.60406316868 and parameters: {'n_estimators': 1139, 'eta': 0.006930099639506947, 'colsample_bytree': 0.5722692849731709, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 79}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:14:21] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:15:03,881] Trial 169 finished with value: 85538.3117318514 and parameters: {'n_estimators': 1200, 'eta': 0.00010000000000000009, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 2}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:15:05] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:15:09,824] Trial 170 finished with value: 80974.16127981553 and parameters: {'n_estimators': 1200, 'eta': 0.030809300218342103, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 398}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:15:11] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:15:15,407] Trial 171 finished with value: 80985.69013424468 and parameters: {'n_estimators': 495, 'eta': 0.048535655461037074, 'colsample_bytree': 0.6486073159811321, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 239}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:15:16] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:15:34,636] Trial 172 finished with value: 81048.60252001397 and parameters: {'n_estimators': 943, 'eta': 0.003048963382501375, 'colsample_bytree': 0.9999999999999999, 'lambda': 0.5988686118507922, 'alpha': 9.999999999999993, 'threshold': 151}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:15:36] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:15:51,698] Trial 173 finished with value: 80833.4411448964 and parameters: {'n_estimators': 910, 'eta': 0.007061523051346132, 'colsample_bytree': 0.5495414583883739, 'lambda': 8.190088516292546, 'alpha': 0.00010000000000000009, 'threshold': 80}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:15:53] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:15:59,930] Trial 174 finished with value: 80892.20495995633 and parameters: {'n_estimators': 896, 'eta': 0.02551090697745661, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 123}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:16:01] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:16:03,077] Trial 175 finished with value: 81531.71688271275 and parameters: {'n_estimators': 50, 'eta': 0.027458978889831696, 'colsample_bytree': 1.0, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 397}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:16:05] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:16:29,436] Trial 176 finished with value: 80781.36800553069 and parameters: {'n_estimators': 1200, 'eta': 0.005454676062605367, 'colsample_bytree': 0.575110428964958, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 201}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:16:30] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:16:35,262] Trial 177 finished with value: 81024.61412114381 and parameters: {'n_estimators': 531, 'eta': 0.01808005025055645, 'colsample_bytree': 0.7423293379051586, 'lambda': 2.1927175908825074, 'alpha': 9.999999999999993, 'threshold': 338}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:16:36] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:16:42,276] Trial 178 finished with value: 80967.7946213403 and parameters: {'n_estimators': 413, 'eta': 0.022376413301807282, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 425}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:16:44] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:17:12,942] Trial 179 finished with value: 80840.2064330708 and parameters: {'n_estimators': 1200, 'eta': 0.0026935459665874454, 'colsample_bytree': 0.5607610840587786, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 105}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:17:14] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:17:41,424] Trial 180 finished with value: 80956.83730513956 and parameters: {'n_estimators': 1200, 'eta': 0.0029085438798916647, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 420}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:17:42] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:18:08,971] Trial 181 finished with value: 81036.32631960213 and parameters: {'n_estimators': 1200, 'eta': 0.0021554538745283468, 'colsample_bytree': 0.9999999999999999, 'lambda': 0.10000000000000002, 'alpha': 0.00010000000000000009, 'threshold': 164}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:18:10] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:18:11,863] Trial 182 finished with value: 81124.45664100206 and parameters: {'n_estimators': 50, 'eta': 0.1202746631228459, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:18:13] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:18:14,289] Trial 183 finished with value: 89503.64576503383 and parameters: {'n_estimators': 50, 'eta': 0.49999999999999906, 'colsample_bytree': 0.9999999999999999, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:18:15] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:18:28,589] Trial 184 finished with value: 81140.50802842228 and parameters: {'n_estimators': 1200, 'eta': 0.014046407139150613, 'colsample_bytree': 0.05, 'lambda': 2.7656631981520263, 'alpha': 0.00010000000000000009, 'threshold': 95}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:18:30] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:18:32,645] Trial 185 finished with value: 80973.19936620767 and parameters: {'n_estimators': 558, 'eta': 0.07437094734650183, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:18:34] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:18:38,359] Trial 186 finished with value: 81125.23941645194 and parameters: {'n_estimators': 799, 'eta': 0.01431368208381518, 'colsample_bytree': 1.0, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:18:39] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:18:58,760] Trial 187 finished with value: 80978.74463120801 and parameters: {'n_estimators': 1200, 'eta': 0.003650423128871891, 'colsample_bytree': 0.45213400194789966, 'lambda': 0.10000000000000002, 'alpha': 0.00010000000000000009, 'threshold': 500}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:19:00] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:19:03,268] Trial 188 finished with value: 80971.9222339457 and parameters: {'n_estimators': 105, 'eta': 0.05736656755955257, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 500}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:19:04] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:19:05,773] Trial 189 finished with value: 81097.70125241426 and parameters: {'n_estimators': 50, 'eta': 0.050340430795097264, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:19:07] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:19:27,701] Trial 190 finished with value: 81008.24434581633 and parameters: {'n_estimators': 1200, 'eta': 0.003023447371747155, 'colsample_bytree': 0.8020536005060447, 'lambda': 2.218185892622636, 'alpha': 9.999999999999975, 'threshold': 262}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:19:29] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:19:33,295] Trial 191 finished with value: 81079.35025384117 and parameters: {'n_estimators': 553, 'eta': 0.025070634592849365, 'colsample_bytree': 1.0, 'lambda': 1.5632280633286864, 'alpha': 0.00010000000000000009, 'threshold': 500}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:19:35] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:19:53,547] Trial 192 finished with value: 80949.85757176526 and parameters: {'n_estimators': 982, 'eta': 0.0035927476394184503, 'colsample_bytree': 1.0, 'lambda': 3.321081184264218, 'alpha': 0.00010000000000000009, 'threshold': 500}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:19:55] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:19:56,808] Trial 193 finished with value: 80963.17378778078 and parameters: {'n_estimators': 50, 'eta': 0.07539314746228104, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 411}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:19:58] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:20:04,519] Trial 194 finished with value: 81102.30246074573 and parameters: {'n_estimators': 1200, 'eta': 0.07216563087754939, 'colsample_bytree': 0.05, 'lambda': 7.305412417645184, 'alpha': 0.00010000000000000009, 'threshold': 168}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:20:05] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:20:09,061] Trial 195 finished with value: 82178.7136439464 and parameters: {'n_estimators': 1200, 'eta': 0.10095310788469866, 'colsample_bytree': 0.05, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 1}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:20:10] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:20:35,799] Trial 196 finished with value: 80882.15530686898 and parameters: {'n_estimators': 1200, 'eta': 0.002833752920906834, 'colsample_bytree': 0.6893309241809392, 'lambda': 1.6708276774220012, 'alpha': 9.999999999999993, 'threshold': 88}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:20:37] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:20:40,134] Trial 197 finished with value: 83019.91941047194 and parameters: {'n_estimators': 116, 'eta': 0.004439083181740619, 'colsample_bytree': 1.0, 'lambda': 0.10000000000000002, 'alpha': 9.999999999999993, 'threshold': 500}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:20:42] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:20:44,896] Trial 198 finished with value: 81297.68458522928 and parameters: {'n_estimators': 576, 'eta': 0.04966561144999826, 'colsample_bytree': 0.3947905194939975, 'lambda': 0.7245430070385647, 'alpha': 0.00010000000000000009, 'threshold': 156}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:20:47] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:20:49,897] Trial 199 finished with value: 80977.76538295986 and parameters: {'n_estimators': 241, 'eta': 0.07023747708686265, 'colsample_bytree': 0.9999999999999999, 'lambda': 49.99999999999999, 'alpha': 9.999999999999993, 'threshold': 441}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:20:51] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:21:04,023] Trial 200 finished with value: 80916.18613888563 and parameters: {'n_estimators': 1200, 'eta': 0.0054705765324791445, 'colsample_bytree': 0.6256278978370517, 'lambda': 0.10000000000000002, 'alpha': 0.00010000000000000009, 'threshold': 217}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:21:06] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:21:31,086] Trial 201 finished with value: 85269.07314915607 and parameters: {'n_estimators': 1200, 'eta': 0.00010000000000000009, 'colsample_bytree': 1.0, 'lambda': 0.10000000000000002, 'alpha': 0.00010000000000000009, 'threshold': 500}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:21:33] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[I 2024-09-22 21:21:34,607] Trial 202 finished with value: 81073.53987529833 and parameters: {'n_estimators': 50, 'eta': 0.04913393610964042, 'colsample_bytree': 1.0, 'lambda': 49.99999999999999, 'alpha': 9.999999999999975, 'threshold': 303}. Best is trial 168 with value: 80677.60406316868.\n/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning:\n\n[21:21:36] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\" } are not used.\n\n\n[W 2024-09-22 21:21:37,529] Trial 203 failed with parameters: {'n_estimators': 1200, 'eta': 0.020686361283137354, 'colsample_bytree': 0.46345666765638616, 'lambda': 49.99999999999999, 'alpha': 0.00010000000000000009, 'threshold': 132} because of the following error: KeyboardInterrupt().\nTraceback (most recent call last):\n  File \"/root/venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/tmp/ipykernel_196/901226497.py\", line 36, in objective\n    model = xgb.train(params, dtrain, evals=[(dvalid, 'validation')], num_boost_round=params['n_estimators'], early_stopping_rounds=35, verbose_eval=False)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/root/venv/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n    bst.update(dtrain, iteration=i, fobj=obj)\n  File \"/root/venv/lib/python3.11/site-packages/xgboost/core.py\", line 2101, in update\n    _LIB.XGBoosterUpdateOneIter(\nKeyboardInterrupt\n[W 2024-09-22 21:21:37,530] Trial 203 failed with value None.\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 49\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rmse\n\u001b[1;32m     48\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(sampler \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mGPSampler(), direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[15], line 36\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     33\u001b[0m dvalid \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_valid, label\u001b[38;5;241m=\u001b[39my_valid, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_estimators\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Predict on the validation set\u001b[39;00m\n\u001b[1;32m     39\u001b[0m y_pred_valid \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(dvalid)\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"outputs_reference":"s3:deepnote-cell-outputs-production/28ff8610-a319-4560-8f84-6b5b27a43fab","content_dependencies":null},{"cellId":"3139cac3b1674bc5873fca6bdf344cf0","cell_type":"code","metadata":{"source_hash":"c4b5cd1e","execution_start":1727382368874,"execution_millis":22164,"execution_context_id":"8355a963-0fdd-46c0-8b7b-84608fc2838b","deepnote_to_be_reexecuted":false,"cell_id":"3139cac3b1674bc5873fca6bdf344cf0","deepnote_cell_type":"code"},"source":"import xgboost as xgb\nbest_params = {'include_mileage': 0, 'include_msrp': 1, 'n_estimators': 994, 'eta': 0.015373037895620294, 'max_depth': 5, 'min_child_weight': 0.11357559673815384, 'subsample': 0.9793735367721236, 'colsample_bytree': 0.3377000630669105, 'lambda': 43.146286704054816, 'alpha': 46.88655118854743, 'model_threshold': 573, 'ext_col_threshold': 454, 'accident_threshold': 94, 'clean_title_threshold': 1, 'body_style_threshold': 485, 'engine_threshold': 56, 'fuel_type_threshold': 741, 'int_col_threshold': 886, 'brand_threshold': 909}\nbest_params['objective'] = 'reg:squarederror'\nbest_params['eval_metric'] = 'rmse'\nbest_params['device'] = 'cpu'\n\ndrop_cols = ['id', 'price_diff', 'adjusted_price_diff', 'transmission', 'full_name', 'brand_model', 'msrp']\ny = df['price']\nX = df.drop(['price'], axis=1).drop(drop_cols, axis=1)\n\n\ndrop_cols_test = ['transmission', 'full_name', 'brand_model', 'msrp']\ndt = pd.read_csv('cars_test_enriched_acc_noassumption.csv')\ndt['miles_per_year'] = dt['milage']\ndt['miles_per_year'] = dt.apply(lambda x: x['miles_per_year'] / x['age'] if x['age']>0 else 0, axis=1)\ndt = dt.astype({col: \"category\" for col in cat_types})\ndt.drop(drop_cols_test, axis=1, inplace=True)\n\nfor cat in cat_types:\n        value_counts = X[cat].value_counts().to_dict()\n        X[cat] = X[cat].apply(lambda x: x if value_counts[x] > best_params[f'{cat}_threshold'] else \"unknown\")\n        dt[cat] = dt[cat].apply(lambda x: x if (x in value_counts) and (value_counts[x] > best_params[f'{cat}_threshold']) else \"unknown\")\n\nX = X.astype({col: \"category\" for col in cat_types})\n\ndtrain = xgb.DMatrix(X, label=y, enable_categorical=True)\nmodel = xgb.train(best_params, dtrain, num_boost_round=best_params['n_estimators'])","block_group":"841c9bc1cb75438499afbb0a9b519256","execution_count":12,"outputs":[{"name":"stderr","text":"/root/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [20:26:10] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"accident_threshold\", \"body_style_threshold\", \"brand_threshold\", \"clean_title_threshold\", \"engine_threshold\", \"ext_col_threshold\", \"fuel_type_threshold\", \"include_mileage\", \"include_msrp\", \"int_col_threshold\", \"model_threshold\", \"n_estimators\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/bc5011fd-3b28-42d4-a2bf-56f19dcb120b","content_dependencies":null},{"cellId":"548401d762114f9babb32d8dff8df147","cell_type":"code","metadata":{"source_hash":"be4dc3f1","execution_start":1727382493440,"execution_millis":6386,"execution_context_id":"8355a963-0fdd-46c0-8b7b-84608fc2838b","deepnote_to_be_reexecuted":false,"cell_id":"548401d762114f9babb32d8dff8df147","deepnote_cell_type":"code"},"source":"\nids = dt.pop('id')\ndt = dt.astype({col: \"category\" for col in cat_types})\ndtest = xgb.DMatrix(dt, enable_categorical=True)  \npred = model.predict(dtest)\n\n\n\n# Create a submission DataFrame\nsubmission_df = pd.DataFrame({\n    'id': ids,\n    'price': pred\n})\n\n# Save the submission DataFrame to a CSV file\nsubmission_df.to_csv('submission11.csv', index=False)\n","block_group":"264f8c1ff89d4d2ca52887799baef68e","execution_count":15,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"69e7de46d4aa4c01b91c4d95e848969d","cell_type":"code","metadata":{"source_hash":"b623e53d","execution_start":1727382391570,"execution_millis":1,"execution_context_id":"8355a963-0fdd-46c0-8b7b-84608fc2838b","cell_id":"69e7de46d4aa4c01b91c4d95e848969d","deepnote_cell_type":"code"},"source":"","block_group":"81691885710c42189a7eb39f82aa85f5","execution_count":14,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cellId":"753136efbfa8444591513a539c79f2ac","cell_type":"code","metadata":{"cell_id":"753136efbfa8444591513a539c79f2ac","deepnote_cell_type":"code"},"source":"","block_group":"4a983e35d91a40d9889dd5b04e4b6c3a","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null}],
        "metadata": {"deepnote_persisted_session":{"createdAt":"2024-09-26T17:04:43.329Z"},"deepnote_notebook_id":"93ffcd54a8864811b5734084b9dd3c01"},
        "nbformat": "4",
        "nbformat_minor": "0",
        "version": "0"
      }